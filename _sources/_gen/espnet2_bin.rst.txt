.. _aggregate_stats_dirs.py:

aggregate_stats_dirs.py
~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: none

    usage: aggregate_stats_dirs.py [-h]
                                   [--log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}]
                                   [--skip_sum_stats] [--input_dir INPUT_DIR]
                                   --output_dir OUTPUT_DIR
    
    Aggregate statistics directories into one directory
    
    optional arguments:
      --log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}
                            The verbose level of logging (default: INFO)
      --skip_sum_stats      Skip computing the sum of statistics. (default: False)
      --input_dir INPUT_DIR
                            Input directories (default: None)
      --output_dir OUTPUT_DIR
                            Output directory (default: None)
.. _enh_scoring.py:

enh_scoring.py
~~~~~~~~~~~~~~

.. code-block:: none

    usage: enh_scoring.py [-h] [--config CONFIG]
                          [--log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}]
                          --output_dir OUTPUT_DIR
                          [--dtype {float16,float32,float64}] --ref_scp REF_SCP
                          --inf_scp INF_SCP [--key_file KEY_FILE]
                          [--ref_channel REF_CHANNEL]
    
    Frontend inference
    
    optional arguments:
      --config CONFIG       Give config file in yaml format (default: None)
      --log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}
                            The verbose level of logging (default: INFO)
      --output_dir OUTPUT_DIR
      --dtype {float16,float32,float64}
                            Data type (default: float32)
    
    Input data related:
      --ref_scp REF_SCP
      --inf_scp INF_SCP
      --key_file KEY_FILE
      --ref_channel REF_CHANNEL
.. _launch.py:

launch.py
~~~~~~~~~

.. code-block:: none

    
     ********* Inside  bin/launch.py  *********  
    
    usage: launch.py [-h] [--cmd CMD] [--log LOG]
                     [--max_num_log_files MAX_NUM_LOG_FILES] [--ngpu NGPU]
                     [--num_nodes NUM_NODES | --host HOST] [--envfile ENVFILE]
                     [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                     [--master_port MASTER_PORT] [--master_addr MASTER_ADDR]
                     [--init_file_prefix INIT_FILE_PREFIX]
                     args [args ...]
    
    Launch distributed process with appropriate options.
    
    positional arguments:
      args
    
    optional arguments:
      --cmd CMD             The path of cmd script of Kaldi: run.pl. queue.pl, or
                            slurm.pl (default: utils/run.pl)
      --log LOG             The path of log file used by cmd (default: run.log)
      --max_num_log_files MAX_NUM_LOG_FILES
                            The maximum number of log-files to be kept (default:
                            1000)
      --ngpu NGPU           The number of GPUs per node (default: 1)
      --num_nodes NUM_NODES
                            The number of nodes (default: 1)
      --host HOST           Directly specify the host names. The job are submitted
                            via SSH. Multiple host names can be specified by
                            splitting by comma. e.g. host1,host2 You can also the
                            device id after the host name with ':'. e.g.
                            host1:0:2:3,host2:0:2. If the device ids are specified
                            in this way, the value of --ngpu is ignored. (default:
                            None)
      --envfile ENVFILE     Source the shell script before executing command. This
                            option is used when --host is specified. (default:
                            path.sh)
      --multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED
                            Distributed method is used when single-node mode.
                            (default: True)
      --master_port MASTER_PORT
                            Specify the port number of masterMaster is a host
                            machine has RANK0 process. (default: None)
      --master_addr MASTER_ADDR
                            Specify the address s of master. Master is a host
                            machine has RANK0 process. (default: None)
      --init_file_prefix INIT_FILE_PREFIX
                            The file name prefix for init_file, which is used for
                            'Shared-file system initialization'. This option is
                            used when --port is not specified (default:
                            .dist_init_)
.. _pack.py:

pack.py
~~~~~~~

.. code-block:: none

    usage: pack.py [-h] {asr,st,tts,enh,diar,enh_s2t} ...
    
    Pack input files to archive format
    
    positional arguments:
      {asr,st,tts,enh,diar,enh_s2t}
    
    optional arguments:
.. _split_scps.py:

split_scps.py
~~~~~~~~~~~~~

.. code-block:: none

    usage: split_scps.py [-h]
                         [--log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}]
                         --scps SCPS [SCPS ...] [--names NAMES [NAMES ...]]
                         [--num_splits NUM_SPLITS] --output_dir OUTPUT_DIR
    
    Split scp files
    
    optional arguments:
      --log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}
                            The verbose level of logging (default: INFO)
      --scps SCPS [SCPS ...]
                            Input texts (default: None)
      --names NAMES [NAMES ...]
                            Output names for each files (default: None)
      --num_splits NUM_SPLITS
                            Split number (default: None)
      --output_dir OUTPUT_DIR
                            Output directory (default: None)
.. _tokenize_text.py:

tokenize_text.py
~~~~~~~~~~~~~~~~

.. code-block:: none

    [nltk_data] Downloading package averaged_perceptron_tagger to
    [nltk_data]     /home/runner/nltk_data...
    [nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.
    [nltk_data] Downloading package cmudict to /home/runner/nltk_data...
    [nltk_data]   Unzipping corpora/cmudict.zip.
    usage: tokenize_text.py [-h]
                            [--log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}]
                            --input INPUT --output OUTPUT [--field FIELD]
                            [--token_type {char,bpe,word,phn}]
                            [--delimiter DELIMITER] [--space_symbol SPACE_SYMBOL]
                            [--bpemodel BPEMODEL]
                            [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                            [--remove_non_linguistic_symbols REMOVE_NON_LINGUISTIC_SYMBOLS]
                            [--cleaner {None,tacotron,jaconv,vietnamese,korean_cleaner}]
                            [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_english_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                            [--write_vocabulary WRITE_VOCABULARY]
                            [--vocabulary_size VOCABULARY_SIZE] [--cutoff CUTOFF]
                            [--add_symbol ADD_SYMBOL]
    
    Tokenize texts
    
    optional arguments:
      --log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}
                            The verbose level of logging (default: INFO)
      --input INPUT, -i INPUT
                            Input text. - indicates sys.stdin (default: None)
      --output OUTPUT, -o OUTPUT
                            Output text. - indicates sys.stdout (default: None)
      --field FIELD, -f FIELD
                            The target columns of the input text as 1-based
                            integer. e.g 2- (default: None)
      --token_type {char,bpe,word,phn}, -t {char,bpe,word,phn}
                            Token type (default: char)
      --delimiter DELIMITER, -d DELIMITER
                            The delimiter (default: None)
      --space_symbol SPACE_SYMBOL
                            The space symbol (default: <space>)
      --bpemodel BPEMODEL   The bpemodel file path (default: None)
      --non_linguistic_symbols NON_LINGUISTIC_SYMBOLS
                            non_linguistic_symbols file path (default: None)
      --remove_non_linguistic_symbols REMOVE_NON_LINGUISTIC_SYMBOLS
                            Remove non-language-symbols from tokens (default:
                            False)
      --cleaner {None,tacotron,jaconv,vietnamese,korean_cleaner}
                            Apply text cleaning (default: None)
      --g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_english_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}
                            Specify g2p method if --token_type=phn (default: None)
    
    write_vocabulary mode related:
      --write_vocabulary WRITE_VOCABULARY
                            Write tokens list instead of tokenized text per line
                            (default: False)
      --vocabulary_size VOCABULARY_SIZE
                            Vocabulary size (default: 0)
      --cutoff CUTOFF       cut-off frequency used for write-vocabulary mode
                            (default: 0)
      --add_symbol ADD_SYMBOL
                            Append symbol e.g. --add_symbol '<blank>:0'
                            --add_symbol '<unk>:1' (default: [])
