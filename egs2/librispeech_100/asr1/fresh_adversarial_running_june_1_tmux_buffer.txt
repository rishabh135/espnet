(pyt) rgupta@chifflot-7:~/dev/espnet/egs2/librispeech_100/asr1$ bash run.sh
\n******************************\n
/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump
/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp
********\n Important setting data direcotry  *********** \n
\n data directory : /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data  \n
\n****************************\n
2022-06-01T11:06:53 (asr.sh:283:main) ./asr.sh --skip_data_prep false --skip_train false --skip_eval false --lang en --ngpu 2 --nj 32 --inference_nj 32 --nbpe 5000 --max_wav_dura
tion 30 --speed_perturb_factors 0.9 1.0 1.1 --audio_format flac.ark --feats_type raw --use_lm false --asr_tag conformer_lr2e-3_warmup15k_amp_nondeterministic --asr_config /home/r
gupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --inference_config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/decod
e_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other dev_clean dev_other --data_dd /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/data --lm_train_text /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_c
lean_100/text --bpe_train_text /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100/text
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
2022-06-01T11:06:53 (asr.sh:477:main) Stage 1: Data preparation for /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/tra
in_clean_100, /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev, etc.
\n
****** Inside data.sh and checking first argument /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data **********\n
\n
 \n
2022-06-01T11:06:53 (data.sh:24:main) local/data.sh /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
2022-06-01T11:06:54 (data.sh:49:main) stage 1: /srv/storage/magnet@storage1.lille.grid5000.fr/brij/asr_data//LibriSpeech/LICENSE.TXT is already existing. Skip data downloading
2022-06-01T11:06:54 (data.sh:54:main) stage 2: Data Preparation
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev_c
lean
local/data_prep.sh: successfully prepared data in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev_clean
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/test_
clean
local/data_prep.sh: successfully prepared data in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/test_clean
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev_o
ther
local/data_prep.sh: successfully prepared data in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev_other
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/test_
other
local/data_prep.sh: successfully prepared data in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/test_other
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train
_clean_100
local/data_prep.sh: successfully prepared data in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100
2022-06-01T11:09:12 (data.sh:62:main) stage 3: combine all training and development sets
utils/combine_data.sh --extra_files utt2num_frames /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev /srv/storage/tal
c2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev_clean /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_lib
ri_100/pyt_adversarial_1/data/dev_other
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
utils/combine_data.sh [info]: not combining utt2uniq as it does not exist
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh [info]: not combining utt2dur as it does not exist
utils/combine_data.sh [info]: not combining utt2num_frames as it does not exist
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh [info]: not combining feats.scp as it does not exist
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
utils/combine_data.sh [info]: not combining utt2num_frames as it does not exist
fix_data_dir.sh: kept all 5567 utterances.
fix_data_dir.sh: old files are kept in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev/.backup
2022-06-01T11:09:14 (data.sh:69:main) stage 4: prepare external text data from http://www.openslr.org/resources/11/librispeech-lm-norm.txt.gz
--2022-06-01 11:09:14--  http://www.openslr.org/resources/11/librispeech-lm-norm.txt.gz
Resolving www.openslr.org (www.openslr.org)... 46.101.158.64
Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1507274412 (1.4G) [application/x-gzip]
Saving to: '/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/local/other_text/librispeech-lm-norm.txt.gz'

librispeech-lm-norm.txt.gz                   100%[============================================================================================>]   1.40G   480MB/s    in 3.0s

2022-06-01 11:09:19 (480 MB/s) - '/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/local/other_text/librispeech-lm-norm.
txt.gz' saved [1507274412/1507274412]

2022-06-01T11:10:38 (data.sh:80:main) Successfully finished. [elapsed=225s]
2022-06-01T11:10:38 (asr.sh:484:main) Stage 2: Speed perturbation: /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/trai
n_clean_100 -> /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100_sp
text
utt2lang
/home/rgupta/dev/espnet/egs2/librispeech/asr1//scripts/utils/perturb_data_dir_speed.sh: generated speed-perturbed version of data in /srv/storage/talc2@talc-data2.nancy/multispee
ch/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100, in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversar
ial_1/data/train_clean_100_sp0.9
fix_data_dir.sh: kept all 28539 utterances.
fix_data_dir.sh: old files are kept in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100_sp0.9/.backup
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train
_clean_100_sp0.9
text
utt2lang
/home/rgupta/dev/espnet/egs2/librispeech/asr1//scripts/utils/perturb_data_dir_speed.sh: generated speed-perturbed version of data in /srv/storage/talc2@talc-data2.nancy/multispee
ch/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100, in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversar
ial_1/data/train_clean_100_sp1.1
fix_data_dir.sh: kept all 28539 utterances.
fix_data_dir.sh: old files are kept in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100_sp1.1/.backup
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train
_clean_100_sp1.1
utils/combine_data.sh /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100_sp /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100_sp0.9 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri
_100/pyt_adversarial_1/data/train_clean_100 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100_sp1.1
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
utils/combine_data.sh: combined utt2uniq
utils/combine_data.sh [info]: not combining segments as it does not exist
utils/combine_data.sh: combined utt2spk
utils/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/combine_data.sh [info]: not combining utt2dur as it does not exist
utils/combine_data.sh [info]: not combining utt2num_frames as it does not exist
utils/combine_data.sh [info]: not combining reco2dur as it does not exist
utils/combine_data.sh [info]: not combining feats.scp as it does not exist
utils/combine_data.sh: combined text
utils/combine_data.sh [info]: not combining cmvn.scp as it does not exist
utils/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/combine_data.sh: combined wav.scp
utils/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 85617 utterances.
fix_data_dir.sh: old files are kept in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100_sp/.backup
2022-06-01T11:10:53 (asr.sh:506:main) Stage 3: Format wav.scp: /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/ -> /srv
/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw
/home/rgupta/dev/espnet/egs2/librispeech/asr1//utils/copy_data_dir.sh: copied data from /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_ad
versarial_1/data/train_clean_100_sp to /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/org/train_clean_100_sp
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/o
rg/train_clean_100_sp
2022-06-01T11:10:57 (format_wav_scp.sh:42:main) /home/rgupta/dev/espnet/egs2/librispeech/asr1//scripts/audio/format_wav_scp.sh --nj 32 --cmd run.pl --audio-format flac.ark --fs 1
6k /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/train_clean_100_sp/wav.scp /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/org/train_clean_100_sp
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
2022-06-01T11:10:57 (format_wav_scp.sh:110:main) [info]: without segments
2022-06-01T11:13:19 (format_wav_scp.sh:142:main) Successfully finished. [elapsed=142s]
/home/rgupta/dev/espnet/egs2/librispeech/asr1//utils/copy_data_dir.sh: copied data from /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_ad
versarial_1/data/dev to /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/org/dev
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/o
rg/dev
2022-06-01T11:13:21 (format_wav_scp.sh:42:main) /home/rgupta/dev/espnet/egs2/librispeech/asr1//scripts/audio/format_wav_scp.sh --nj 32 --cmd run.pl --audio-format flac.ark --fs 1
6k /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev/wav.scp /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/u
sers/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/org/dev
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
2022-06-01T11:13:21 (format_wav_scp.sh:110:main) [info]: without segments
2022-06-01T11:13:29 (format_wav_scp.sh:142:main) Successfully finished. [elapsed=8s]
/home/rgupta/dev/espnet/egs2/librispeech/asr1//utils/copy_data_dir.sh: copied data from /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_ad
versarial_1/data/test_clean to /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/test_clean
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/t
est_clean
2022-06-01T11:13:30 (format_wav_scp.sh:42:main) /home/rgupta/dev/espnet/egs2/librispeech/asr1//scripts/audio/format_wav_scp.sh --nj 32 --cmd run.pl --audio-format flac.ark --fs 1
6k /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/test_clean/wav.scp /srv/storage/talc2@talc-data2.nancy/multispeech/c
alcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/test_clean
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
2022-06-01T11:13:30 (format_wav_scp.sh:110:main) [info]: without segments
2022-06-01T11:13:37 (format_wav_scp.sh:142:main) Successfully finished. [elapsed=7s]
/home/rgupta/dev/espnet/egs2/librispeech/asr1//utils/copy_data_dir.sh: copied data from /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_ad
versarial_1/data/test_other to /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/test_other
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/t
est_other
2022-06-01T11:13:38 (format_wav_scp.sh:42:main) /home/rgupta/dev/espnet/egs2/librispeech/asr1//scripts/audio/format_wav_scp.sh --nj 32 --cmd run.pl --audio-format flac.ark --fs 1
6k /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/test_other/wav.scp /srv/storage/talc2@talc-data2.nancy/multispeech/c
alcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/test_other
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
2022-06-01T11:13:38 (format_wav_scp.sh:110:main) [info]: without segments
2022-06-01T11:13:45 (format_wav_scp.sh:142:main) Successfully finished. [elapsed=7s]
/home/rgupta/dev/espnet/egs2/librispeech/asr1//utils/copy_data_dir.sh: copied data from /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_ad
versarial_1/data/dev_clean to /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev_clean
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/d
ev_clean
2022-06-01T11:13:46 (format_wav_scp.sh:42:main) /home/rgupta/dev/espnet/egs2/librispeech/asr1//scripts/audio/format_wav_scp.sh --nj 32 --cmd run.pl --audio-format flac.ark --fs 1
6k /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev_clean/wav.scp /srv/storage/talc2@talc-data2.nancy/multispeech/ca
lcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev_clean
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
2022-06-01T11:13:47 (format_wav_scp.sh:110:main) [info]: without segments
2022-06-01T11:13:53 (format_wav_scp.sh:142:main) Successfully finished. [elapsed=7s]
/home/rgupta/dev/espnet/egs2/librispeech/asr1//utils/copy_data_dir.sh: copied data from /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_ad
versarial_1/data/dev_other to /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev_other
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/d
ev_other
2022-06-01T11:13:55 (format_wav_scp.sh:42:main) /home/rgupta/dev/espnet/egs2/librispeech/asr1//scripts/audio/format_wav_scp.sh --nj 32 --cmd run.pl --audio-format flac.ark --fs 1
6k /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/dev_other/wav.scp /srv/storage/talc2@talc-data2.nancy/multispeech/ca
lcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev_other
./path.sh: line 9: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/../../../tools/activate_python.sh: No such file or directory
2022-06-01T11:13:55 (format_wav_scp.sh:110:main) [info]: without segments
2022-06-01T11:14:02 (format_wav_scp.sh:142:main) Successfully finished. [elapsed=7s]
2022-06-01T11:14:02 (asr.sh:608:main) Stage 4: Remove long/short /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data: /srv/
storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/org -> /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgup
ta/fresh_libri_100/pyt_adversarial_1/dump/raw
utils/copy_data_dir.sh: copied data from /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/org/train_clean_100_sp to
/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/t
rain_clean_100_sp
fix_data_dir.sh: kept all 85617 utterances.
fix_data_dir.sh: old files are kept in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/.backup
utils/copy_data_dir.sh: copied data from /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/org/dev to /srv/storage/ta
lc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev
utils/validate_data_dir.sh: Successfully validated data-directory /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/d
ev
fix_data_dir.sh: kept 5551 utterances out of 5567
fix_data_dir.sh: old files are kept in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/.backup
2022-06-01T11:14:15 (asr.sh:673:main) Stage 5: Generate token_list from /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data
/train_clean_100/text using BPE
sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_tok
en_list/bpe_unigram5000/train.txt --vocab_size=5000 --model_type=unigram --model_prefix=/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_ad
versarial_1/data/en_token_list/bpe_unigram5000/bpe --character_coverage=1.0 --input_sentence_size=100000000
sentencepiece_trainer.cc(77) LOG(INFO) Starts training with :
trainer_spec {
  input: /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/train.txt
  input_format:
  model_prefix: /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe
  model_type: UNIGRAM
  vocab_size: 5000
  self_test_sample_size: 0
  character_coverage: 1
  input_sentence_size: 100000000
  shuffle_input_sentence: 1
  seed_sentencepiece_size: 1000000
  shrinking_factor: 0.75
  max_sentence_length: 4192
  num_threads: 16
  num_sub_iterations: 2
  max_sentencepiece_length: 16
  split_by_unicode_script: 1
  split_by_number: 1
  split_by_whitespace: 1
  split_digits: 0
  treat_whitespace_as_suffix: 0
  allow_whitespace_only_pieces: 0
  required_chars:
  byte_fallback: 0
  vocabulary_output_piece_score: 1
  train_extremely_large_corpus: 0
  hard_vocab_limit: 1
  use_all_vocab: 0
  unk_id: 0
  bos_id: 1
  eos_id: 2
  pad_id: -1
  unk_piece: <unk>
  bos_piece: <s>
  eos_piece: </s>
  pad_piece: <pad>
  unk_surface:  ⁇
}
normalizer_spec {
  name: nmt_nfkc
  add_dummy_prefix: 1
  remove_extra_whitespaces: 1
  escape_whitespaces: 1
  normalization_rule_tsv:
}
denormalizer_spec {}
trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.
trainer_interface.cc(178) LOG(INFO) Loading corpus: /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_u
nigram5000/train.txt
trainer_interface.cc(385) LOG(INFO) Loaded all 28539 sentences
trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>
trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>
trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>
trainer_interface.cc(405) LOG(INFO) Normalizing sentences...
trainer_interface.cc(466) LOG(INFO) all chars count=5298357
trainer_interface.cc(487) LOG(INFO) Alphabet size=28
trainer_interface.cc(488) LOG(INFO) Final character coverage=1
trainer_interface.cc(520) LOG(INFO) Done! preprocessed 28539 sentences.
unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...
unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...
unigram_model_trainer.cc(194) LOG(INFO) Initialized 81579 seed sentencepieces
trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 28539
trainer_interface.cc(537) LOG(INFO) Done! 33798
unigram_model_trainer.cc(489) LOG(INFO) Using 33798 sentences for EM training
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=28479 obj=9.30792 num_tokens=58684 num_tokens/piece=2.06061
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21986 obj=7.5261 num_tokens=59016 num_tokens/piece=2.68425
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=16486 obj=7.47478 num_tokens=63635 num_tokens/piece=3.85994
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=16476 obj=7.4571 num_tokens=63651 num_tokens/piece=3.86326
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=12357 obj=7.55663 num_tokens=71878 num_tokens/piece=5.81678
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=12357 obj=7.53205 num_tokens=71878 num_tokens/piece=5.81678
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=9267 obj=7.68822 num_tokens=81233 num_tokens/piece=8.76584
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=9267 obj=7.65521 num_tokens=81229 num_tokens/piece=8.7654
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=6950 obj=7.8591 num_tokens=90152 num_tokens/piece=12.9715
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=6950 obj=7.81882 num_tokens=90155 num_tokens/piece=12.9719
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=5500 obj=8.01837 num_tokens=97243 num_tokens/piece=17.6805
unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=5500 obj=7.98145 num_tokens=97257 num_tokens/piece=17.6831
trainer_interface.cc(615) LOG(INFO) Saving model: /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_uni
gram5000/bpe.model
trainer_interface.cc(626) LOG(INFO) Saving vocabs: /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_un
igram5000/bpe.vocab
2022-06-01T11:14:19 (asr.sh:924:main) Stage 6-8: Skip lm-related stages: use_lm=false
2022-06-01T11:14:19 (asr.sh:937:main) Stage 9: Skip ngram stages: use_ngram=false
2022-06-01T11:14:19 (asr.sh:945:main) Stage 10: ASR collect stats: train_set=/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1
/dump/raw/train_clean_100_sp, valid_set=/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev
2022-06-01T11:14:21 (asr.sh:995:main) Generate '/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000
_sp/run.sh'. You can resume the process from stage 10 using this script
2022-06-01T11:14:21 (asr.sh:999:main) ASR collect-stats started... log: '/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp
/asr_stats_raw_en_bpe5000_sp/logdir/stats.*.log'
2022-06-01T11:14:21 (asr.sh:1005:main)
 *********************** changing directories **************************

run.pl: 32 / 32 failed, log is in /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/sta
ts.*.log
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.1.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech
/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.1.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.1 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_
asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:21 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.1.scp --valid_
shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.1.scp --output_dir /
srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.1 --config /home/rgupta/dev/espn
et/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=6 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 6 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.10.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.10.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.10 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.10.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.10.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.10 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.11.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.11.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.11 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.11.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.11.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.11 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.12.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.12.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.12 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.12.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.12.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.12 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.13.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.13.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.13 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.13.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.13.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.13 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.14.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.14.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.14 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.14.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.14.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.14 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.15.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.15.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.15 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.15.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.15.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.15 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.16.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.16.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.16 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.16.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.16.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.16 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.17.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.17.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.17 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.17.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.17.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.17 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.18.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.18.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.18 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.18.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.18.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.18 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.19.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.19.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.19 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.19.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.19.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.19 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.2.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech
/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.2.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.2 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_
asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:21 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.2.scp --valid_
shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.2.scp --output_dir /
srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.2 --config /home/rgupta/dev/espn
et/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=6 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 6 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.20.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.20.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.20 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.20.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.20.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.20 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.21.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.21.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.21 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.21.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.21.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.21 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.22.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.22.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.22 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.22.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.22.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.22 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.23.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.23.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.23 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.23.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.23.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.23 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.24.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.24.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.24 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.24.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.24.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.24 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.25.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.25.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.25 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.25.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.25.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.25 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.26.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.26.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.26 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.26.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.26.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.26 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.27.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.27.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.27 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.27.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.27.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.27 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.28.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.28.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.28 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.28.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.28.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.28 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.29.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.29.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.29 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.29.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.29.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.29 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.3.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech
/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.3.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.3 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_
asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:21 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.3.scp --valid_
shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.3.scp --output_dir /
srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.3 --config /home/rgupta/dev/espn
et/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=6 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 6 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.30.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.30.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.30 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.30.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.30.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.30 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.31.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.31.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.31 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.31.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.31.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.31 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.32.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeec
h/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.32.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/us
ers/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.32 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/tra
in_asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.32.scp --valid
_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.32.scp --output_dir
 /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.32 --config /home/rgupta/dev/e
spnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.4.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech
/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.4.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.4 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_
asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:21 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.4.scp --valid_
shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.4.scp --output_dir /
srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.4 --config /home/rgupta/dev/espn
et/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=6 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 6 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.5.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech
/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.5.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.5 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_
asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:21 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.5.scp --valid_
shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.5.scp --output_dir /
srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.5 --config /home/rgupta/dev/espn
et/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=6 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 6 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.6.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech
/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.6.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.6 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_
asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:21 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.6.scp --valid_
shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.6.scp --output_dir /
srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.6 --config /home/rgupta/dev/espn
et/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=6 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 6 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.7.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech
/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.7.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.7 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_
asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:21 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.7.scp --valid_
shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.7.scp --output_dir /
srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.7 --config /home/rgupta/dev/espn
et/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.8.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech
/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.8.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.8 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_
asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.8.scp --valid_
shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.8.scp --output_dir /
srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.8 --config /home/rgupta/dev/espn
et/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt
_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_
adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type /srv/storage/talc2@talc-da
ta2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_data_path_and_name_and_type /srv/storage/
talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/text,text,text --valid_data_path_and_name_and_type /srv/stora
ge/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,kaldi_ark --valid_data_path_and_name_and_type /srv/storage
/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --train_shape_file /srv/storage/talc2@talc-data2.nancy/multi
speech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.9.scp --valid_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech
/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.9.scp --output_dir /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/user
s/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.9 --config /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_
asr.yaml --frontend_conf fs=16k
# Started at Wed Jun  1 11:14:22 CEST 2022
#
/home/rgupta/anaconda3/envs/pyt/bin/python3 /home/rgupta/dev/espnet/espnet2/bin/asr_train.py --collect_stats true --use_preprocessor true --bpemodel /srv/storage/talc2@talc-data2
.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/bpe.model --token_type bpe --token_list /srv/storage/talc2@talc-data2.
nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/data/en_token_list/bpe_unigram5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --tr
ain_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/wav.scp,speech,k
aldi_ark --train_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/train_clean_100_sp/tex
t,text,text --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/wav.scp,speech,
kaldi_ark --valid_data_path_and_name_and_type /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/dump/raw/dev/text,text,text --
train_shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/train.9.scp --valid_
shape_file /srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/valid.9.scp --output_dir /
srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/rgupta/fresh_libri_100/pyt_adversarial_1/exp/asr_stats_raw_en_bpe5000_sp/logdir/stats.9 --config /home/rgupta/dev/espn
et/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml --frontend_conf fs=16k
usage: asr_train.py [-h] [--config CONFIG] [--print_config]
                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]
                    [--dry_run DRY_RUN]
                    [--iterator_type {sequence,chunk,task,none}]
                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]
                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]
                    [--dist_backend DIST_BACKEND]
                    [--dist_init_method DIST_INIT_METHOD]
                    [--dist_world_size DIST_WORLD_SIZE]
                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]
                    [--dist_master_addr DIST_MASTER_ADDR]
                    [--dist_master_port DIST_MASTER_PORT]
                    [--dist_launcher {slurm,mpi,None}]
                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]
                    [--unused_parameters UNUSED_PARAMETERS]
                    [--sharded_ddp SHARDED_DDP]
                    [--cudnn_enabled CUDNN_ENABLED]
                    [--cudnn_benchmark CUDNN_BENCHMARK]
                    [--cudnn_deterministic CUDNN_DETERMINISTIC]
                    [--collect_stats COLLECT_STATS]
                    [--write_collected_feats WRITE_COLLECTED_FEATS]
                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]
                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]
                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]
                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]
                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]
                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]
                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]
                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]
                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]
                    [--train_dtype {float16,float32,float64}]
                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]
                    [--use_matplotlib USE_MATPLOTLIB]
                    [--use_tensorboard USE_TENSORBOARD]
                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]
                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]
                    [--wandb_name WANDB_NAME]
                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]
                    [--detect_anomaly DETECT_ANOMALY]
                    [--pretrain_path PRETRAIN_PATH]
                    [--init_param [INIT_PARAM ...]]
                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]
                    [--freeze_param [FREEZE_PARAM ...]]
                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]
                    [--batch_size BATCH_SIZE]
                    [--valid_batch_size VALID_BATCH_SIZE]
                    [--batch_bins BATCH_BINS]
                    [--valid_batch_bins VALID_BATCH_BINS]
                    [--train_shape_file TRAIN_SHAPE_FILE]
                    [--valid_shape_file VALID_SHAPE_FILE]
                    [--batch_type {unsorted,sorted,folded,length,numel}]
                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]
                    [--fold_length FOLD_LENGTH]
                    [--sort_in_batch {descending,ascending}]
                    [--sort_batch {descending,ascending}]
                    [--multiple_iterator MULTIPLE_ITERATOR]
                    [--chunk_length CHUNK_LENGTH]
                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]
                    [--num_cache_chunks NUM_CACHE_CHUNKS]
                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]
                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]
                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]
                    [--max_cache_size MAX_CACHE_SIZE]
                    [--max_cache_fd MAX_CACHE_FD]
                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]
                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,radam}]
                    [--optim_conf OPTIM_CONF]
                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,No
ne}]
                    [--scheduler_conf SCHEDULER_CONF]
                    [--token_list TOKEN_LIST]
                    [--init {chainer,xavier_uniform,xavier_normal,kaiming_uniform,kaiming_normal,None}]
                    [--input_size INPUT_SIZE] [--ctc_conf CTC_CONF]
                    [--joint_net_conf JOINT_NET_CONF]
                    [--use_preprocessor USE_PREPROCESSOR]
                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]
                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]
                    [--cleaner {None,tacotron,jaconv,vietnamese}]
                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2
p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_eng
lish_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]
                    [--speech_volume_normalize SPEECH_VOLUME_NORMALIZE]
                    [--rir_scp RIR_SCP] [--rir_apply_prob RIR_APPLY_PROB]
                    [--noise_scp NOISE_SCP]
                    [--noise_apply_prob NOISE_APPLY_PROB]
                    [--noise_db_range NOISE_DB_RANGE]
                    [--frontend {default,sliding_window,s3prl,fused}]
                    [--frontend_conf FRONTEND_CONF] [--specaug {specaug,None}]
                    [--specaug_conf SPECAUG_CONF]
                    [--normalize {global_mvn,utterance_mvn,None}]
                    [--normalize_conf NORMALIZE_CONF]
                    [--model {espnet,maskctc}] [--model_conf MODEL_CONF]
                    [--preencoder {sinc,linear,None}]
                    [--preencoder_conf PREENCODER_CONF]
                    [--encoder {conformer,transformer,contextual_block_transformer,contextual_block_conformer,vgg_rnn,rnn,wav2vec2,hubert,hubert_pretrain,longformer}]
                    [--encoder_conf ENCODER_CONF]
                    [--postencoder {hugging_face_transformers,None}]
                    [--postencoder_conf POSTENCODER_CONF]
                    [--decoder {transformer,lightweight_conv,lightweight_conv2d,dynamic_conv,dynamic_conv2d,rnn,transducer,mlm}]
                    [--decoder_conf DECODER_CONF]
asr_train.py: error: No such file: /home/rgupta/dev/espnet/egs2/librispeech_100/asr1/conf/pyt_adversarial_1/train_asr.yaml
# Accounting: time=5 threads=1
# Ended (code 2) at Wed Jun  1 11:14:27 CEST 2022, elapsed time 5 seconds
(pyt) rgupta@chifflot-7:~/dev/espnet/egs2/librispeech_100/asr1$
