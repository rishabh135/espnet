<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>espnet2.gan_tts package &mdash; ESPnet 202205 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="espnet2.asr package" href="espnet2.asr.html" />
    <link rel="prev" title="espnet2.torch_utils package" href="espnet2.torch_utils.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> ESPnet
          </a>
              <div class="version">
                202205
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelization.html">Using Job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">espnet2.gan_tts package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-abs-gan-tts">espnet2.gan_tts.abs_gan_tts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-init">espnet2.gan_tts.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-espnet-model">espnet2.gan_tts.espnet_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-utils-get-random-segments">espnet2.gan_tts.utils.get_random_segments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-utils-init">espnet2.gan_tts.utils.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-melgan-pqmf">espnet2.gan_tts.melgan.pqmf</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-melgan-residual-stack">espnet2.gan_tts.melgan.residual_stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-melgan-init">espnet2.gan_tts.melgan.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-melgan-melgan">espnet2.gan_tts.melgan.melgan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-parallel-wavegan-upsample">espnet2.gan_tts.parallel_wavegan.upsample</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-parallel-wavegan-parallel-wavegan">espnet2.gan_tts.parallel_wavegan.parallel_wavegan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-parallel-wavegan-init">espnet2.gan_tts.parallel_wavegan.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-text-encoder">espnet2.gan_tts.vits.text_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-vits">espnet2.gan_tts.vits.vits</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-residual-coupling">espnet2.gan_tts.vits.residual_coupling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-loss">espnet2.gan_tts.vits.loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-transform">espnet2.gan_tts.vits.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-duration-predictor">espnet2.gan_tts.vits.duration_predictor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-flow">espnet2.gan_tts.vits.flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-posterior-encoder">espnet2.gan_tts.vits.posterior_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-generator">espnet2.gan_tts.vits.generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-init">espnet2.gan_tts.vits.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-monotonic-align-setup">espnet2.gan_tts.vits.monotonic_align.setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-vits-monotonic-align-init">espnet2.gan_tts.vits.monotonic_align.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-style-melgan-style-melgan">espnet2.gan_tts.style_melgan.style_melgan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-style-melgan-tade-res-block">espnet2.gan_tts.style_melgan.tade_res_block</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-style-melgan-init">espnet2.gan_tts.style_melgan.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-joint-joint-text2wav">espnet2.gan_tts.joint.joint_text2wav</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-joint-init">espnet2.gan_tts.joint.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-hifigan-loss">espnet2.gan_tts.hifigan.loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-hifigan-init">espnet2.gan_tts.hifigan.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-hifigan-hifigan">espnet2.gan_tts.hifigan.hifigan</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-hifigan-residual-block">espnet2.gan_tts.hifigan.residual_block</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-alignments">espnet2.gan_tts.jets.alignments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-length-regulator">espnet2.gan_tts.jets.length_regulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-loss">espnet2.gan_tts.jets.loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-jets">espnet2.gan_tts.jets.jets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-generator">espnet2.gan_tts.jets.generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-jets-init">espnet2.gan_tts.jets.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-wavenet-wavenet">espnet2.gan_tts.wavenet.wavenet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-wavenet-init">espnet2.gan_tts.wavenet.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-gan-tts-wavenet-residual-block">espnet2.gan_tts.wavenet.residual_block</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.diar.html">espnet2.diar package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>espnet2.gan_tts package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_gen/espnet2.gan_tts.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="espnet2-gan-tts-package">
<h1>espnet2.gan_tts package<a class="headerlink" href="#espnet2-gan-tts-package" title="Permalink to this headline">¶</a></h1>
<section id="espnet2-gan-tts-abs-gan-tts">
<span id="id1"></span><h2>espnet2.gan_tts.abs_gan_tts<a class="headerlink" href="#espnet2-gan-tts-abs-gan-tts" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.abs_gan_tts"></span><p>GAN-based TTS abstrast class.</p>
<dl class="class">
<dt id="espnet2.gan_tts.abs_gan_tts.AbsGANTTS">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.abs_gan_tts.</code><code class="sig-name descname">AbsGANTTS</code><a class="reference internal" href="../_modules/espnet2/gan_tts/abs_gan_tts.html#AbsGANTTS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.abs_gan_tts.AbsGANTTS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.tts.html#espnet2.tts.abs_tts.AbsTTS" title="espnet2.tts.abs_tts.AbsTTS"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.tts.abs_tts.AbsTTS</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>GAN-based TTS model abstract class.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.gan_tts.abs_gan_tts.AbsGANTTS.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">forward_generator</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor], int]]<a class="reference internal" href="../_modules/espnet2/gan_tts/abs_gan_tts.html#AbsGANTTS.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.abs_gan_tts.AbsGANTTS.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Return generator or discriminator loss.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-init">
<span id="id2"></span><h2>espnet2.gan_tts.__init__<a class="headerlink" href="#espnet2-gan-tts-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.__init__"></span></section>
<section id="espnet2-gan-tts-espnet-model">
<span id="id3"></span><h2>espnet2.gan_tts.espnet_model<a class="headerlink" href="#espnet2-gan-tts-espnet-model" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.espnet_model"></span><p>GAN-based text-to-speech ESPnet model.</p>
<dl class="class">
<dt id="espnet2.gan_tts.espnet_model.ESPnetGANTTSModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.espnet_model.</code><code class="sig-name descname">ESPnetGANTTSModel</code><span class="sig-paren">(</span><em class="sig-param">feats_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], normalize: Optional[espnet2.layers.inversible_interface.InversibleInterface], pitch_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], pitch_normalize: Optional[espnet2.layers.inversible_interface.InversibleInterface], energy_extract: Optional[espnet2.tts.feats_extract.abs_feats_extract.AbsFeatsExtract], energy_normalize: Optional[espnet2.layers.inversible_interface.InversibleInterface], tts: espnet2.gan_tts.abs_gan_tts.AbsGANTTS</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/espnet_model.html#ESPnetGANTTSModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.espnet_model.ESPnetGANTTSModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.train.html#espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel" title="espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.train.abs_gan_espnet_model.AbsGANESPnetModel</span></code></a></p>
<p>ESPnet model for GAN-based text-to-speech task.</p>
<p>Initialize ESPnetGANTTSModel module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.espnet_model.ESPnetGANTTSModel.collect_feats">
<code class="sig-name descname">collect_feats</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">durations: Optional[torch.Tensor] = None</em>, <em class="sig-param">durations_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/espnet_model.html#ESPnetGANTTSModel.collect_feats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.espnet_model.ESPnetGANTTSModel.collect_feats" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate features and return them as a dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</p></li>
<li><p><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B, 1).</p></li>
<li><p><strong>durations</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Duration tensor.</p></li>
<li><p><strong>durations_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Duration length tensor (B,).</p></li>
<li><p><strong>pitch</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Pitch tensor.</p></li>
<li><p><strong>pitch_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Pitch length tensor (B,).</p></li>
<li><p><strong>energy</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Energy tensor.</p></li>
<li><p><strong>energy_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em>) – Energy length tensor (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, D).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker index tensor (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language ID tensor (B, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict of features.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.espnet_model.ESPnetGANTTSModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">durations: Optional[torch.Tensor] = None</em>, <em class="sig-param">durations_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">forward_generator: bool = True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/gan_tts/espnet_model.html#ESPnetGANTTSModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.espnet_model.ESPnetGANTTSModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Return generator or discriminator loss with dict format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</p></li>
<li><p><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</p></li>
<li><p><strong>duration</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Duration tensor.</p></li>
<li><p><strong>duration_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Duration length tensor (B,).</p></li>
<li><p><strong>pitch</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Pitch tensor.</p></li>
<li><p><strong>pitch_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Pitch length tensor (B,).</p></li>
<li><p><strong>energy</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Energy tensor.</p></li>
<li><p><strong>energy_lengths</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Energy length tensor (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, D).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker ID tensor (B, 1).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language ID tensor (B, 1).</p></li>
<li><p><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</p></li>
<li><p><strong>kwargs</strong> – “utt_id” is among the input.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>loss (Tensor): Loss scalar tensor.</p></li>
<li><p>stats (Dict[str, float]): Statistics to be monitored.</p></li>
<li><p>weight (Tensor): Weight tensor to summarize losses.</p></li>
<li><p>optim_idx (int): Optimizer index (0 for G and 1 for D).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-utils-get-random-segments">
<span id="id4"></span><h2>espnet2.gan_tts.utils.get_random_segments<a class="headerlink" href="#espnet2-gan-tts-utils-get-random-segments" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.utils.get_random_segments"></span><p>Function to get random segments.</p>
<dl class="function">
<dt id="espnet2.gan_tts.utils.get_random_segments.get_random_segments">
<code class="sig-prename descclassname">espnet2.gan_tts.utils.get_random_segments.</code><code class="sig-name descname">get_random_segments</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_lengths: torch.Tensor</em>, <em class="sig-param">segment_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/utils/get_random_segments.html#get_random_segments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.utils.get_random_segments.get_random_segments" title="Permalink to this definition">¶</a></dt>
<dd><p>Get random segments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, C, T).</p></li>
<li><p><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Segmented tensor (B, C, segment_size).
Tensor: Start index tensor (B,).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.utils.get_random_segments.get_segments">
<code class="sig-prename descclassname">espnet2.gan_tts.utils.get_random_segments.</code><code class="sig-name descname">get_segments</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">start_idxs: torch.Tensor</em>, <em class="sig-param">segment_size: int</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/utils/get_random_segments.html#get_segments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.utils.get_random_segments.get_segments" title="Permalink to this definition">¶</a></dt>
<dd><p>Get segments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, C, T).</p></li>
<li><p><strong>start_idxs</strong> (<em>Tensor</em>) – Start index tensor (B,).</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Segmented tensor (B, C, segment_size).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-gan-tts-utils-init">
<span id="id5"></span><h2>espnet2.gan_tts.utils.__init__<a class="headerlink" href="#espnet2-gan-tts-utils-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.utils.__init__"></span></section>
<section id="espnet2-gan-tts-melgan-pqmf">
<span id="id6"></span><h2>espnet2.gan_tts.melgan.pqmf<a class="headerlink" href="#espnet2-gan-tts-melgan-pqmf" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.melgan.pqmf"></span><p>Pseudo QMF modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.melgan.pqmf.PQMF">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.pqmf.</code><code class="sig-name descname">PQMF</code><span class="sig-paren">(</span><em class="sig-param">subbands: int = 4</em>, <em class="sig-param">taps: int = 62</em>, <em class="sig-param">cutoff_ratio: float = 0.142</em>, <em class="sig-param">beta: float = 9.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/pqmf.html#PQMF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.pqmf.PQMF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>PQMF module.</p>
<p>This module is based on <a class="reference external" href="https://ieeexplore.ieee.org/document/258122">Near-perfect-reconstruction pseudo-QMF banks</a>.</p>
<p>Initilize PQMF module.</p>
<p>The cutoff_ratio and beta parameters are optimized for #subbands = 4.
See dicussion in <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN/issues/195">https://github.com/kan-bayashi/ParallelWaveGAN/issues/195</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>subbands</strong> (<em>int</em>) – The number of subbands.</p></li>
<li><p><strong>taps</strong> (<em>int</em>) – The number of filter taps.</p></li>
<li><p><strong>cutoff_ratio</strong> (<em>float</em>) – Cut-off frequency ratio.</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Beta coefficient for kaiser window.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.pqmf.PQMF.analysis">
<code class="sig-name descname">analysis</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/pqmf.html#PQMF.analysis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.pqmf.PQMF.analysis" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis with PQMF.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, subbands, T // subbands).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.pqmf.PQMF.synthesis">
<code class="sig-name descname">synthesis</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/pqmf.html#PQMF.synthesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.pqmf.PQMF.synthesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Synthesis with PQMF.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, subbands, T // subbands).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, 1, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.melgan.pqmf.design_prototype_filter">
<code class="sig-prename descclassname">espnet2.gan_tts.melgan.pqmf.</code><code class="sig-name descname">design_prototype_filter</code><span class="sig-paren">(</span><em class="sig-param">taps: int = 62</em>, <em class="sig-param">cutoff_ratio: float = 0.142</em>, <em class="sig-param">beta: float = 9.0</em><span class="sig-paren">)</span> &#x2192; numpy.ndarray<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/pqmf.html#design_prototype_filter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.pqmf.design_prototype_filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Design prototype filter for PQMF.</p>
<p>This method is based on <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/681427">A Kaiser window approach for the design of prototype
filters of cosine modulated filterbanks</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>taps</strong> (<em>int</em>) – The number of filter taps.</p></li>
<li><p><strong>cutoff_ratio</strong> (<em>float</em>) – Cut-off frequency ratio.</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Beta coefficient for kaiser window.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Impluse response of prototype filter (taps + 1,).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-gan-tts-melgan-residual-stack">
<span id="id7"></span><h2>espnet2.gan_tts.melgan.residual_stack<a class="headerlink" href="#espnet2-gan-tts-melgan-residual-stack" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.melgan.residual_stack"></span><p>Residual stack module in MelGAN.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.melgan.residual_stack.ResidualStack">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.residual_stack.</code><code class="sig-name descname">ResidualStack</code><span class="sig-paren">(</span><em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">channels: int = 32</em>, <em class="sig-param">dilation: int = 1</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">nonlinear_activation: str = 'LeakyReLU'</em>, <em class="sig-param">nonlinear_activation_params: Dict[str</em>, <em class="sig-param">Any] = {'negative_slope': 0.2}</em>, <em class="sig-param">pad: str = 'ReflectionPad1d'</em>, <em class="sig-param">pad_params: Dict[str</em>, <em class="sig-param">Any] = {}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/residual_stack.html#ResidualStack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.residual_stack.ResidualStack" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Residual stack module introduced in MelGAN.</p>
<p>Initialize ResidualStack module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilation convolution layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of channels of convolution layers.</p></li>
<li><p><strong>dilation</strong> (<em>int</em>) – Dilation factor.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for
activation function.</p></li>
<li><p><strong>pad</strong> (<em>str</em>) – Padding function module name before dilated convolution layer.</p></li>
<li><p><strong>pad_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for padding function.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.residual_stack.ResidualStack.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/residual_stack.html#ResidualStack.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.residual_stack.ResidualStack.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, chennels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-melgan-init">
<span id="id8"></span><h2>espnet2.gan_tts.melgan.__init__<a class="headerlink" href="#espnet2-gan-tts-melgan-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.melgan.__init__"></span></section>
<section id="espnet2-gan-tts-melgan-melgan">
<span id="id9"></span><h2>espnet2.gan_tts.melgan.melgan<a class="headerlink" href="#espnet2-gan-tts-melgan-melgan" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.melgan.melgan"></span><p>MelGAN Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.melgan.</code><code class="sig-name descname">MelGANDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, kernel_sizes: List[int] = [5, 3], channels: int = 16, max_downsample_channels: int = 1024, bias: bool = True, downsample_scales: List[int] = [4, 4, 4, 4], nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, pad: str = 'ReflectionPad1d', pad_params: Dict[str, Any] = {}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MelGAN discriminator module.</p>
<p>Initilize MelGANDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of two kernel sizes. The prod will be used
for the first conv layer, and the first and the second kernel sizes
will be used for the last two layers. For example if kernel_sizes =
[5, 3], the first layer kernel size will be 5 * 3 = 15, the last two
layers’ kernel size will be 5 and 3, respectively.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Maximum number of channels for downsampling
layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>pad</strong> (<em>str</em>) – Padding function module name before dilated convolution layer.</p></li>
<li><p><strong>pad_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for padding function.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of output tensors of each layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.melgan.</code><code class="sig-name descname">MelGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, kernel_size: int = 7, channels: int = 512, bias: bool = True, upsample_scales: List[int] = [8, 8, 2, 2], stack_kernel_size: int = 3, stacks: int = 3, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, pad: str = 'ReflectionPad1d', pad_params: Dict[str, Any] = {}, use_final_nonlinear_activation: bool = True, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MelGAN generator module.</p>
<p>Initialize MelGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>stack_kernel_size</strong> (<em>int</em>) – Kernel size of dilated conv layers in residual
stack.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks in a single residual stack.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>pad</strong> (<em>str</em>) – Padding function module name before dilated convolution layer.</p></li>
<li><p><strong>pad_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for padding function.</p></li>
<li><p><strong>use_final_nonlinear_activation</strong> (<em>torch.nn.Module</em>) – Activation function for
the final layer.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, 1, T ** prod(upsample_scales)).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (T, in_channels).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T ** prod(upsample_scales), out_channels).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows official implementation manner.
<a class="reference external" href="https://github.com/descriptinc/melgan-neurips/blob/master/mel2wav/modules.py">https://github.com/descriptinc/melgan-neurips/blob/master/mel2wav/modules.py</a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.melgan.melgan.</code><code class="sig-name descname">MelGANMultiScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, scales: int = 3, downsample_pooling: str = 'AvgPool1d', downsample_pooling_params: Dict[str, Any] = {'count_include_pad': False, 'kernel_size': 4, 'padding': 1, 'stride': 2}, kernel_sizes: List[int] = [5, 3], channels: int = 16, max_downsample_channels: int = 1024, bias: bool = True, downsample_scales: List[int] = [4, 4, 4, 4], nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, pad: str = 'ReflectionPad1d', pad_params: Dict[str, Any] = {}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MelGAN multi-scale discriminator module.</p>
<p>Initilize MelGANMultiScaleDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>downsample_pooling_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the above
pooling module.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of two kernel sizes. The sum will be used
for the first conv layer, and the first and the second kernel sizes
will be used for the last two layers.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Maximum number of channels for downsampling
layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>pad</strong> (<em>str</em>) – Padding function module name before dilated convolution layer.</p></li>
<li><p><strong>pad_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for padding function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs, which</dt><dd><p>consists of each layer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[Tensor]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/melgan/melgan.html#MelGANMultiScaleDiscriminator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.melgan.melgan.MelGANMultiScaleDiscriminator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows official implementation manner.
<a class="reference external" href="https://github.com/descriptinc/melgan-neurips/blob/master/mel2wav/modules.py">https://github.com/descriptinc/melgan-neurips/blob/master/mel2wav/modules.py</a></p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-parallel-wavegan-upsample">
<span id="id10"></span><h2>espnet2.gan_tts.parallel_wavegan.upsample<a class="headerlink" href="#espnet2-gan-tts-parallel-wavegan-upsample" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.parallel_wavegan.upsample"></span><p>Upsampling module.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.Conv2d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.upsample.</code><code class="sig-name descname">Conv2d</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#Conv2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.Conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.conv.Conv2d</span></code></p>
<p>Conv2d module with customized initialization.</p>
<p>Initialize Conv2d module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.Conv2d.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#Conv2d.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.Conv2d.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.ConvInUpsampleNetwork">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.upsample.</code><code class="sig-name descname">ConvInUpsampleNetwork</code><span class="sig-paren">(</span><em class="sig-param">upsample_scales: List[int], nonlinear_activation: Optional[str] = None, nonlinear_activation_params: Dict[str, Any] = {}, interpolate_mode: str = 'nearest', freq_axis_kernel_size: int = 1, aux_channels: int = 80, aux_context_window: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#ConvInUpsampleNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.ConvInUpsampleNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolution + upsampling network module.</p>
<p>Initialize ConvInUpsampleNetwork module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>upsample_scales</strong> (<em>list</em>) – List of upsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Activation function name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Arguments for the specified
activation function.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – Interpolation mode.</p></li>
<li><p><strong>freq_axis_kernel_size</strong> (<em>int</em>) – Kernel size in the direction of
frequency axis.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of channels of pre-conv layer.</p></li>
<li><p><strong>aux_context_window</strong> (<em>int</em>) – Context window size of the pre-conv layer.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.ConvInUpsampleNetwork.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#ConvInUpsampleNetwork.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.ConvInUpsampleNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, C, T_feats).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Upsampled tensor (B, C, T_wav),</dt><dd><p>where T_wav = T_feats * prod(upsample_scales).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.Stretch2d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.upsample.</code><code class="sig-name descname">Stretch2d</code><span class="sig-paren">(</span><em class="sig-param">x_scale: int</em>, <em class="sig-param">y_scale: int</em>, <em class="sig-param">mode: str = 'nearest'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#Stretch2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.Stretch2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Stretch2d module.</p>
<p>Initialize Stretch2d module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_scale</strong> (<em>int</em>) – X scaling factor (Time axis in spectrogram).</p></li>
<li><p><strong>y_scale</strong> (<em>int</em>) – Y scaling factor (Frequency axis in spectrogram).</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – Interpolation mode.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.Stretch2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#Stretch2d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.Stretch2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, C, F, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Interpolated tensor (B, C, F * y_scale, T * x_scale),</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.UpsampleNetwork">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.upsample.</code><code class="sig-name descname">UpsampleNetwork</code><span class="sig-paren">(</span><em class="sig-param">upsample_scales: List[int], nonlinear_activation: Optional[str] = None, nonlinear_activation_params: Dict[str, Any] = {}, interpolate_mode: str = 'nearest', freq_axis_kernel_size: int = 1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#UpsampleNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.UpsampleNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Upsampling network module.</p>
<p>Initialize UpsampleNetwork module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Activation function name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Arguments for the specified
activation function.</p></li>
<li><p><strong>interpolate_mode</strong> (<em>str</em>) – Interpolation mode.</p></li>
<li><p><strong>freq_axis_kernel_size</strong> (<em>int</em>) – Kernel size in the direction of frequency axis.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.upsample.UpsampleNetwork.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/upsample.html#UpsampleNetwork.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.upsample.UpsampleNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> – Input tensor (B, C, T_feats).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Upsampled tensor (B, C, T_wav).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-parallel-wavegan-parallel-wavegan">
<span id="id11"></span><h2>espnet2.gan_tts.parallel_wavegan.parallel_wavegan<a class="headerlink" href="#espnet2-gan-tts-parallel-wavegan-parallel-wavegan" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.parallel_wavegan.parallel_wavegan"></span><p>Parallel WaveGAN Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.parallel_wavegan.</code><code class="sig-name descname">ParallelWaveGANDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 10</em>, <em class="sig-param">conv_channels: int = 64</em>, <em class="sig-param">dilation_factor: int = 1</em>, <em class="sig-param">nonlinear_activation: str = 'LeakyReLU'</em>, <em class="sig-param">nonlinear_activation_params: Dict[str</em>, <em class="sig-param">Any] = {'negative_slope': 0.2}</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Parallel WaveGAN Discriminator module.</p>
<p>Initialize ParallelWaveGANDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of conv layers.</p></li>
<li><p><strong>conv_channels</strong> (<em>int</em>) – Number of chnn layers.</p></li>
<li><p><strong>dilation_factor</strong> (<em>int</em>) – Dilation factor. For example, if dilation_factor = 2,
the dilation will be 2, 4, 8, …, and so on.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Nonlinear function after each conv.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Nonlinear function parameters</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, 1, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANDiscriminator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.parallel_wavegan.</code><code class="sig-name descname">ParallelWaveGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 30</em>, <em class="sig-param">stacks: int = 3</em>, <em class="sig-param">residual_channels: int = 64</em>, <em class="sig-param">gate_channels: int = 128</em>, <em class="sig-param">skip_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">aux_context_window: int = 2</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em>, <em class="sig-param">upsample_conditional_features: bool = True</em>, <em class="sig-param">upsample_net: str = 'ConvInUpsampleNetwork'</em>, <em class="sig-param">upsample_params: Dict[str</em>, <em class="sig-param">Any] = {'upsample_scales': [4</em>, <em class="sig-param">4</em>, <em class="sig-param">4</em>, <em class="sig-param">4]}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Parallel WaveGAN Generator module.</p>
<p>Initialize ParallelWaveGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilated convolution.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of residual block layers.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks i.e., dilation cycles.</p></li>
<li><p><strong>residual_channels</strong> (<em>int</em>) – Number of channels in residual conv.</p></li>
<li><p><strong>gate_channels</strong> (<em>int</em>) – Number of channels in gated conv.</p></li>
<li><p><strong>skip_channels</strong> (<em>int</em>) – Number of channels in skip conv.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of channels for auxiliary feature conv.</p></li>
<li><p><strong>aux_context_window</strong> (<em>int</em>) – Context window size for auxiliary feature.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate. 0.0 means no dropout applied.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv layer.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
<li><p><strong>upsample_conditional_features</strong> (<em>bool</em>) – Whether to use upsampling network.</p></li>
<li><p><strong>upsample_net</strong> (<em>str</em>) – Upsampling network architecture.</p></li>
<li><p><strong>upsample_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Upsampling network parameters.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Local conditioning auxiliary features (B, C ,T_feats).</p></li>
<li><p><strong>z</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T_wav).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T_wav)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Local conditioning auxiliary features (T_feats ,C).</p></li>
<li><p><strong>z</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Input noise signal (T_wav, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T_wav, out_channels)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.receptive_field_size">
<em class="property">property </em><code class="sig-name descname">receptive_field_size</code><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.receptive_field_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Return receptive field size.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.parallel_wavegan.ParallelWaveGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-parallel-wavegan-init">
<span id="id12"></span><h2>espnet2.gan_tts.parallel_wavegan.__init__<a class="headerlink" href="#espnet2-gan-tts-parallel-wavegan-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.parallel_wavegan.__init__"></span><dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.__init__.</code><code class="sig-name descname">ParallelWaveGANDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 10</em>, <em class="sig-param">conv_channels: int = 64</em>, <em class="sig-param">dilation_factor: int = 1</em>, <em class="sig-param">nonlinear_activation: str = 'LeakyReLU'</em>, <em class="sig-param">nonlinear_activation_params: Dict[str</em>, <em class="sig-param">Any] = {'negative_slope': 0.2}</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Parallel WaveGAN Discriminator module.</p>
<p>Initialize ParallelWaveGANDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of conv layers.</p></li>
<li><p><strong>conv_channels</strong> (<em>int</em>) – Number of chnn layers.</p></li>
<li><p><strong>dilation_factor</strong> (<em>int</em>) – Dilation factor. For example, if dilation_factor = 2,
the dilation will be 2, 4, 8, …, and so on.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Nonlinear function after each conv.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Nonlinear function parameters</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, 1, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANDiscriminator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANDiscriminator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.parallel_wavegan.__init__.</code><code class="sig-name descname">ParallelWaveGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 30</em>, <em class="sig-param">stacks: int = 3</em>, <em class="sig-param">residual_channels: int = 64</em>, <em class="sig-param">gate_channels: int = 128</em>, <em class="sig-param">skip_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">aux_context_window: int = 2</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em>, <em class="sig-param">upsample_conditional_features: bool = True</em>, <em class="sig-param">upsample_net: str = 'ConvInUpsampleNetwork'</em>, <em class="sig-param">upsample_params: Dict[str</em>, <em class="sig-param">Any] = {'upsample_scales': [4</em>, <em class="sig-param">4</em>, <em class="sig-param">4</em>, <em class="sig-param">4]}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Parallel WaveGAN Generator module.</p>
<p>Initialize ParallelWaveGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilated convolution.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of residual block layers.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks i.e., dilation cycles.</p></li>
<li><p><strong>residual_channels</strong> (<em>int</em>) – Number of channels in residual conv.</p></li>
<li><p><strong>gate_channels</strong> (<em>int</em>) – Number of channels in gated conv.</p></li>
<li><p><strong>skip_channels</strong> (<em>int</em>) – Number of channels in skip conv.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of channels for auxiliary feature conv.</p></li>
<li><p><strong>aux_context_window</strong> (<em>int</em>) – Context window size for auxiliary feature.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate. 0.0 means no dropout applied.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv layer.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
<li><p><strong>upsample_conditional_features</strong> (<em>bool</em>) – Whether to use upsampling network.</p></li>
<li><p><strong>upsample_net</strong> (<em>str</em>) – Upsampling network architecture.</p></li>
<li><p><strong>upsample_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Upsampling network parameters.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Local conditioning auxiliary features (B, C ,T_feats).</p></li>
<li><p><strong>z</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T_wav).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T_wav)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Local conditioning auxiliary features (T_feats ,C).</p></li>
<li><p><strong>z</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Input noise signal (T_wav, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T_wav, out_channels)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.receptive_field_size">
<em class="property">property </em><code class="sig-name descname">receptive_field_size</code><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.receptive_field_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Return receptive field size.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/parallel_wavegan/parallel_wavegan.html#ParallelWaveGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.parallel_wavegan.__init__.ParallelWaveGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-text-encoder">
<span id="id13"></span><h2>espnet2.gan_tts.vits.text_encoder<a class="headerlink" href="#espnet2-gan-tts-vits-text-encoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.text_encoder"></span><p>Text encoder module in VITS.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.vits.text_encoder.TextEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.text_encoder.</code><code class="sig-name descname">TextEncoder</code><span class="sig-paren">(</span><em class="sig-param">vocabs: int</em>, <em class="sig-param">attention_dim: int = 192</em>, <em class="sig-param">attention_heads: int = 2</em>, <em class="sig-param">linear_units: int = 768</em>, <em class="sig-param">blocks: int = 6</em>, <em class="sig-param">positionwise_layer_type: str = 'conv1d'</em>, <em class="sig-param">positionwise_conv_kernel_size: int = 3</em>, <em class="sig-param">positional_encoding_layer_type: str = 'rel_pos'</em>, <em class="sig-param">self_attention_layer_type: str = 'rel_selfattn'</em>, <em class="sig-param">activation_type: str = 'swish'</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">use_macaron_style: bool = False</em>, <em class="sig-param">use_conformer_conv: bool = False</em>, <em class="sig-param">conformer_kernel_size: int = 7</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.0</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/text_encoder.html#TextEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.text_encoder.TextEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Text encoder module in VITS.</p>
<p>This is a module of text encoder described in <a class="reference external" href="https://arxiv.org/abs/2006.04558">Conditional Variational Autoencoder
with Adversarial Learning for End-to-End Text-to-Speech</a>.</p>
<p>Instead of the relative positional Transformer, we use conformer architecture as
the encoder module, which contains additional convolution layers.</p>
<p>Initialize TextEncoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocabs</strong> (<em>int</em>) – Vocabulary size.</p></li>
<li><p><strong>attention_dim</strong> (<em>int</em>) – Attention dimension.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – Number of attention heads.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – Number of linear units of positionwise layers.</p></li>
<li><p><strong>blocks</strong> (<em>int</em>) – Number of encoder blocks.</p></li>
<li><p><strong>positionwise_layer_type</strong> (<em>str</em>) – Positionwise layer type.</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – Positionwise layer’s kernel size.</p></li>
<li><p><strong>positional_encoding_layer_type</strong> (<em>str</em>) – Positional encoding layer type.</p></li>
<li><p><strong>self_attention_layer_type</strong> (<em>str</em>) – Self-attention layer type.</p></li>
<li><p><strong>activation_type</strong> (<em>str</em>) – Activation function type.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to apply LayerNorm before attention.</p></li>
<li><p><strong>use_macaron_style</strong> (<em>bool</em>) – Whether to use macaron style components.</p></li>
<li><p><strong>use_conformer_conv</strong> (<em>bool</em>) – Whether to use conformer conv layers.</p></li>
<li><p><strong>conformer_kernel_size</strong> (<em>int</em>) – Conformer’s conv kernel size.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – Dropout rate for positional encoding.</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – Dropout rate for attention.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.text_encoder.TextEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/text_encoder.html#TextEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.text_encoder.TextEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input index tensor (B, T_text).</p></li>
<li><p><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded hidden representation (B, attention_dim, T_text).
Tensor: Projected mean tensor (B, attention_dim, T_text).
Tensor: Projected scale tensor (B, attention_dim, T_text).
Tensor: Mask tensor for input tensor (B, 1, T_text).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-vits">
<span id="id14"></span><h2>espnet2.gan_tts.vits.vits<a class="headerlink" href="#espnet2-gan-tts-vits-vits" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.vits"></span><p>VITS module for GAN-TTS task.</p>
<dl class="class">
<dt id="espnet2.gan_tts.vits.vits.VITS">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.vits.</code><code class="sig-name descname">VITS</code><span class="sig-paren">(</span><em class="sig-param">idim: int, odim: int, sampling_rate: int = 22050, generator_type: str = 'vits_generator', generator_params: Dict[str, Any] = {'decoder_channels': 512, 'decoder_kernel_size': 7, 'decoder_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'decoder_resblock_kernel_sizes': [3, 7, 11], 'decoder_upsample_kernel_sizes': [16, 16, 4, 4], 'decoder_upsample_scales': [8, 8, 2, 2], 'flow_base_dilation': 1, 'flow_dropout_rate': 0.0, 'flow_flows': 4, 'flow_kernel_size': 5, 'flow_layers': 4, 'global_channels': -1, 'hidden_channels': 192, 'langs': None, 'posterior_encoder_base_dilation': 1, 'posterior_encoder_dropout_rate': 0.0, 'posterior_encoder_kernel_size': 5, 'posterior_encoder_layers': 16, 'posterior_encoder_stacks': 1, 'segment_size': 32, 'spk_embed_dim': None, 'spks': None, 'stochastic_duration_predictor_dds_conv_layers': 3, 'stochastic_duration_predictor_dropout_rate': 0.5, 'stochastic_duration_predictor_flows': 4, 'stochastic_duration_predictor_kernel_size': 3, 'text_encoder_activation_type': 'swish', 'text_encoder_attention_dropout_rate': 0.0, 'text_encoder_attention_heads': 2, 'text_encoder_blocks': 6, 'text_encoder_conformer_kernel_size': 7, 'text_encoder_dropout_rate': 0.1, 'text_encoder_ffn_expand': 4, 'text_encoder_normalize_before': True, 'text_encoder_positional_dropout_rate': 0.0, 'text_encoder_positional_encoding_layer_type': 'rel_pos', 'text_encoder_positionwise_conv_kernel_size': 1, 'text_encoder_positionwise_layer_type': 'conv1d', 'text_encoder_self_attention_layer_type': 'rel_selfattn', 'use_conformer_conv_in_text_encoder': True, 'use_macaron_style_in_text_encoder': True, 'use_only_mean_in_flow': True, 'use_weight_norm_in_decoder': True, 'use_weight_norm_in_flow': True, 'use_weight_norm_in_posterior_encoder': True}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_adv: float = 1.0, lambda_mel: float = 45.0, lambda_feat_match: float = 2.0, lambda_dur: float = 1.0, lambda_kl: float = 1.0, cache_generator_outputs: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/vits.html#VITS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.vits.VITS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.gan_tts.abs_gan_tts.AbsGANTTS" title="espnet2.gan_tts.abs_gan_tts.AbsGANTTS"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.gan_tts.abs_gan_tts.AbsGANTTS</span></code></a></p>
<p>VITS module (generator + discriminator).</p>
<p>This is a module of VITS described in <a class="reference external" href="https://arxiv.org/abs/2006.04558">Conditional Variational Autoencoder
with Adversarial Learning for End-to-End Text-to-Speech</a>.</p>
<p>Initialize VITS module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will
be 1 since VITS is the end-to-end text-to-wave model but for the
compatibility odim is used to indicate the acoustic feature dimension.</p></li>
<li><p><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will
be referred in saving waveform during the inference.</p></li>
<li><p><strong>generator_type</strong> (<em>str</em>) – Generator type.</p></li>
<li><p><strong>generator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for generator.</p></li>
<li><p><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for discriminator.</p></li>
<li><p><strong>generator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for generator
adversarial loss.</p></li>
<li><p><strong>discriminator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for
discriminator adversarial loss.</p></li>
<li><p><strong>feat_match_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for feat match loss.</p></li>
<li><p><strong>mel_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for mel loss.</p></li>
<li><p><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</p></li>
<li><p><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel spectrogram loss.</p></li>
<li><p><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</p></li>
<li><p><strong>lambda_dur</strong> (<em>float</em>) – Loss scaling coefficient for duration loss.</p></li>
<li><p><strong>lambda_kl</strong> (<em>float</em>) – Loss scaling coefficient for KL divergence loss.</p></li>
<li><p><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.vits.VITS.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_lengths: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">forward_generator: bool = True</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/vits.html#VITS.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.vits.VITS.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform generator forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, T_feats, aux_channels).</p></li>
<li><p><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
<li><p><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</p></li>
<li><p><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker index tensor (B,) or (B, 1).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, spk_embed_dim).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language index tensor (B,) or (B, 1).</p></li>
<li><p><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>loss (Tensor): Loss scalar tensor.</p></li>
<li><p>stats (Dict[str, float]): Statistics to be monitored.</p></li>
<li><p>weight (Tensor): Weight tensor to summarize losses.</p></li>
<li><p>optim_idx (int): Optimizer index (0 for G and 1 for D).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.vits.vits.VITS.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">feats: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">durations: Optional[torch.Tensor] = None</em>, <em class="sig-param">noise_scale: float = 0.667</em>, <em class="sig-param">noise_scale_dur: float = 0.8</em>, <em class="sig-param">alpha: float = 1.0</em>, <em class="sig-param">max_len: Optional[int] = None</em>, <em class="sig-param">use_teacher_forcing: bool = False</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/vits.html#VITS.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.vits.VITS.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Run inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (T_feats, aux_channels).</p></li>
<li><p><strong>sids</strong> (<em>Tensor</em>) – Speaker index tensor (1,).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (spk_embed_dim,).</p></li>
<li><p><strong>lids</strong> (<em>Tensor</em>) – Language index tensor (1,).</p></li>
<li><p><strong>durations</strong> (<em>Tensor</em>) – Ground-truth duration tensor (T_text,).</p></li>
<li><p><strong>noise_scale</strong> (<em>float</em>) – Noise scale value for flow.</p></li>
<li><p><strong>noise_scale_dur</strong> (<em>float</em>) – Noise scale value for duration predictor.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – Alpha parameter to control the speed of generated speech.</p></li>
<li><p><strong>max_len</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Maximum length.</p></li>
<li><p><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>wav (Tensor): Generated waveform tensor (T_wav,).</p></li>
<li><p>att_w (Tensor): Monotonic attention weight tensor (T_feats, T_text).</p></li>
<li><p>duration (Tensor): Predicted duration tensor (T_text,).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.vits.vits.VITS.require_raw_speech">
<em class="property">property </em><code class="sig-name descname">require_raw_speech</code><a class="headerlink" href="#espnet2.gan_tts.vits.vits.VITS.require_raw_speech" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not speech is required.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.vits.vits.VITS.require_vocoder">
<em class="property">property </em><code class="sig-name descname">require_vocoder</code><a class="headerlink" href="#espnet2.gan_tts.vits.vits.VITS.require_vocoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not vocoder is required.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-residual-coupling">
<span id="id16"></span><h2>espnet2.gan_tts.vits.residual_coupling<a class="headerlink" href="#espnet2-gan-tts-vits-residual-coupling" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.residual_coupling"></span><p>Residual affine coupling modules in VITS.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.vits.residual_coupling.ResidualAffineCouplingBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.residual_coupling.</code><code class="sig-name descname">ResidualAffineCouplingBlock</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 192</em>, <em class="sig-param">hidden_channels: int = 192</em>, <em class="sig-param">flows: int = 4</em>, <em class="sig-param">kernel_size: int = 5</em>, <em class="sig-param">base_dilation: int = 1</em>, <em class="sig-param">layers: int = 4</em>, <em class="sig-param">global_channels: int = -1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">use_weight_norm: bool = True</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_only_mean: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/residual_coupling.html#ResidualAffineCouplingBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.residual_coupling.ResidualAffineCouplingBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Residual affine coupling block module.</p>
<p>This is a module of residual affine coupling block, which used as “Flow” in
<a class="reference external" href="https://arxiv.org/abs/2006.04558">Conditional Variational Autoencoder with Adversarial Learning for End-to-End
Text-to-Speech</a>.</p>
<p>Initilize ResidualAffineCouplingBlock module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden channels.</p></li>
<li><p><strong>flows</strong> (<em>int</em>) – Number of flows.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size for WaveNet.</p></li>
<li><p><strong>base_dilation</strong> (<em>int</em>) – Base dilation factor for WaveNet.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of layers of WaveNet.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks of WaveNet.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global channels.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight normalization in WaveNet.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias paramters in WaveNet.</p></li>
<li><p><strong>use_only_mean</strong> (<em>bool</em>) – Whether to estimate only mean.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.residual_coupling.ResidualAffineCouplingBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em>, <em class="sig-param">inverse: bool = False</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/residual_coupling.html#ResidualAffineCouplingBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.residual_coupling.ResidualAffineCouplingBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
<li><p><strong>inverse</strong> (<em>bool</em>) – Whether to inverse the flow.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, in_channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.vits.residual_coupling.ResidualAffineCouplingLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.residual_coupling.</code><code class="sig-name descname">ResidualAffineCouplingLayer</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 192</em>, <em class="sig-param">hidden_channels: int = 192</em>, <em class="sig-param">kernel_size: int = 5</em>, <em class="sig-param">base_dilation: int = 1</em>, <em class="sig-param">layers: int = 5</em>, <em class="sig-param">stacks: int = 1</em>, <em class="sig-param">global_channels: int = -1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">use_weight_norm: bool = True</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_only_mean: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/residual_coupling.html#ResidualAffineCouplingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.residual_coupling.ResidualAffineCouplingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Residual affine coupling layer.</p>
<p>Initialzie ResidualAffineCouplingLayer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size for WaveNet.</p></li>
<li><p><strong>base_dilation</strong> (<em>int</em>) – Base dilation factor for WaveNet.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of layers of WaveNet.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks of WaveNet.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global channels.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight normalization in WaveNet.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias paramters in WaveNet.</p></li>
<li><p><strong>use_only_mean</strong> (<em>bool</em>) – Whether to estimate only mean.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.residual_coupling.ResidualAffineCouplingLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em>, <em class="sig-param">inverse: bool = False</em><span class="sig-paren">)</span> &#x2192; Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/residual_coupling.html#ResidualAffineCouplingLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.residual_coupling.ResidualAffineCouplingLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
<li><p><strong>inverse</strong> (<em>bool</em>) – Whether to inverse the flow.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, in_channels, T).
Tensor: Log-determinant tensor for NLL (B,) if not inverse.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-loss">
<span id="id18"></span><h2>espnet2.gan_tts.vits.loss<a class="headerlink" href="#espnet2-gan-tts-vits-loss" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.loss"></span><p>VITS-related loss modules.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.vits.loss.KLDivergenceLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.loss.</code><code class="sig-name descname">KLDivergenceLoss</code><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/loss.html#KLDivergenceLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.loss.KLDivergenceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>KL divergence loss.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.gan_tts.vits.loss.KLDivergenceLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">z_p: torch.Tensor</em>, <em class="sig-param">logs_q: torch.Tensor</em>, <em class="sig-param">m_p: torch.Tensor</em>, <em class="sig-param">logs_p: torch.Tensor</em>, <em class="sig-param">z_mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/loss.html#KLDivergenceLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.loss.KLDivergenceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate KL divergence loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z_p</strong> (<em>Tensor</em>) – Flow hidden representation (B, H, T_feats).</p></li>
<li><p><strong>logs_q</strong> (<em>Tensor</em>) – Posterior encoder projected scale (B, H, T_feats).</p></li>
<li><p><strong>m_p</strong> (<em>Tensor</em>) – Expanded text encoder projected mean (B, H, T_feats).</p></li>
<li><p><strong>logs_p</strong> (<em>Tensor</em>) – Expanded text encoder projected scale (B, H, T_feats).</p></li>
<li><p><strong>z_mask</strong> (<em>Tensor</em>) – Mask tensor (B, 1, T_feats).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>KL divergence loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-transform">
<span id="id19"></span><h2>espnet2.gan_tts.vits.transform<a class="headerlink" href="#espnet2-gan-tts-vits-transform" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.transform"></span><p>Flow-related transformation.</p>
<p>This code is derived from <a class="reference external" href="https://github.com/bayesiains/nflows">https://github.com/bayesiains/nflows</a>.</p>
<dl class="function">
<dt id="espnet2.gan_tts.vits.transform.piecewise_rational_quadratic_transform">
<code class="sig-prename descclassname">espnet2.gan_tts.vits.transform.</code><code class="sig-name descname">piecewise_rational_quadratic_transform</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">unnormalized_widths</em>, <em class="sig-param">unnormalized_heights</em>, <em class="sig-param">unnormalized_derivatives</em>, <em class="sig-param">inverse=False</em>, <em class="sig-param">tails=None</em>, <em class="sig-param">tail_bound=1.0</em>, <em class="sig-param">min_bin_width=0.001</em>, <em class="sig-param">min_bin_height=0.001</em>, <em class="sig-param">min_derivative=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/transform.html#piecewise_rational_quadratic_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.transform.piecewise_rational_quadratic_transform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.vits.transform.rational_quadratic_spline">
<code class="sig-prename descclassname">espnet2.gan_tts.vits.transform.</code><code class="sig-name descname">rational_quadratic_spline</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">unnormalized_widths</em>, <em class="sig-param">unnormalized_heights</em>, <em class="sig-param">unnormalized_derivatives</em>, <em class="sig-param">inverse=False</em>, <em class="sig-param">left=0.0</em>, <em class="sig-param">right=1.0</em>, <em class="sig-param">bottom=0.0</em>, <em class="sig-param">top=1.0</em>, <em class="sig-param">min_bin_width=0.001</em>, <em class="sig-param">min_bin_height=0.001</em>, <em class="sig-param">min_derivative=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/transform.html#rational_quadratic_spline"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.transform.rational_quadratic_spline" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.vits.transform.unconstrained_rational_quadratic_spline">
<code class="sig-prename descclassname">espnet2.gan_tts.vits.transform.</code><code class="sig-name descname">unconstrained_rational_quadratic_spline</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">unnormalized_widths</em>, <em class="sig-param">unnormalized_heights</em>, <em class="sig-param">unnormalized_derivatives</em>, <em class="sig-param">inverse=False</em>, <em class="sig-param">tails='linear'</em>, <em class="sig-param">tail_bound=1.0</em>, <em class="sig-param">min_bin_width=0.001</em>, <em class="sig-param">min_bin_height=0.001</em>, <em class="sig-param">min_derivative=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/transform.html#unconstrained_rational_quadratic_spline"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.transform.unconstrained_rational_quadratic_spline" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-gan-tts-vits-duration-predictor">
<span id="id20"></span><h2>espnet2.gan_tts.vits.duration_predictor<a class="headerlink" href="#espnet2-gan-tts-vits-duration-predictor" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.duration_predictor"></span><p>Stochastic duration predictor modules in VITS.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.vits.duration_predictor.StochasticDurationPredictor">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.duration_predictor.</code><code class="sig-name descname">StochasticDurationPredictor</code><span class="sig-paren">(</span><em class="sig-param">channels: int = 192</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">dropout_rate: float = 0.5</em>, <em class="sig-param">flows: int = 4</em>, <em class="sig-param">dds_conv_layers: int = 3</em>, <em class="sig-param">global_channels: int = -1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/duration_predictor.html#StochasticDurationPredictor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.duration_predictor.StochasticDurationPredictor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Stochastic duration predictor module.</p>
<p>This is a module of stochastic duration predictor described in <a class="reference external" href="https://arxiv.org/abs/2006.04558">Conditional
Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</a>.</p>
<p>Initialize StochasticDurationPredictor module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<em>int</em>) – Number of channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>flows</strong> (<em>int</em>) – Number of flows.</p></li>
<li><p><strong>dds_conv_layers</strong> (<em>int</em>) – Number of conv layers in DDS conv.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.duration_predictor.StochasticDurationPredictor.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: torch.Tensor</em>, <em class="sig-param">w: Optional[torch.Tensor] = None</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em>, <em class="sig-param">inverse: bool = False</em>, <em class="sig-param">noise_scale: float = 1.0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/duration_predictor.html#StochasticDurationPredictor.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.duration_predictor.StochasticDurationPredictor.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, channels, T_text).</p></li>
<li><p><strong>x_mask</strong> (<em>Tensor</em>) – Mask tensor (B, 1, T_text).</p></li>
<li><p><strong>w</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Duration tensor (B, 1, T_text).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, channels, 1)</p></li>
<li><p><strong>inverse</strong> (<em>bool</em>) – Whether to inverse the flow.</p></li>
<li><p><strong>noise_scale</strong> (<em>float</em>) – Noise scale value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>If not inverse, negative log-likelihood (NLL) tensor (B,).</dt><dd><p>If inverse, log-duration tensor (B, 1, T_text).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-flow">
<span id="id22"></span><h2>espnet2.gan_tts.vits.flow<a class="headerlink" href="#espnet2-gan-tts-vits-flow" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.flow"></span><p>Basic Flow modules used in VITS.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.vits.flow.ConvFlow">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.flow.</code><code class="sig-name descname">ConvFlow</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int</em>, <em class="sig-param">hidden_channels: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">layers: int</em>, <em class="sig-param">bins: int = 10</em>, <em class="sig-param">tail_bound: float = 5.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#ConvFlow"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.ConvFlow" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional flow module.</p>
<p>Initialize ConvFlow module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of layers.</p></li>
<li><p><strong>bins</strong> (<em>int</em>) – Number of bins.</p></li>
<li><p><strong>tail_bound</strong> (<em>float</em>) – Tail bound value.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.flow.ConvFlow.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em>, <em class="sig-param">inverse: bool = False</em><span class="sig-paren">)</span> &#x2192; Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#ConvFlow.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.ConvFlow.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p></li>
<li><p><strong>x_mask</strong> (<em>Tensor</em>) – Mask tensor (B,).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, channels, 1).</p></li>
<li><p><strong>inverse</strong> (<em>bool</em>) – Whether to inverse the flow.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, channels, T).
Tensor: Log-determinant tensor for NLL (B,) if not inverse.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.vits.flow.DilatedDepthSeparableConv">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.flow.</code><code class="sig-name descname">DilatedDepthSeparableConv</code><span class="sig-paren">(</span><em class="sig-param">channels: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">layers: int</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">eps: float = 1e-05</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#DilatedDepthSeparableConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.DilatedDepthSeparableConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Dilated depth-separable conv module.</p>
<p>Initialize DilatedDepthSeparableConv module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<em>int</em>) – Number of channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of layers.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – Epsilon for layer norm.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.flow.DilatedDepthSeparableConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#DilatedDepthSeparableConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.DilatedDepthSeparableConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>x_mask</strong> (<em>Tensor</em>) – Mask tensor (B, 1, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.vits.flow.ElementwiseAffineFlow">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.flow.</code><code class="sig-name descname">ElementwiseAffineFlow</code><span class="sig-paren">(</span><em class="sig-param">channels: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#ElementwiseAffineFlow"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.ElementwiseAffineFlow" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Elementwise affine flow module.</p>
<p>Initialize ElementwiseAffineFlow module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>channels</strong> (<em>int</em>) – Number of channels.</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.flow.ElementwiseAffineFlow.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: torch.Tensor</em>, <em class="sig-param">inverse: bool = False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#ElementwiseAffineFlow.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.ElementwiseAffineFlow.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p></li>
<li><p><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
<li><p><strong>inverse</strong> (<em>bool</em>) – Whether to inverse the flow.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, channels, T).
Tensor: Log-determinant tensor for NLL (B,) if not inverse.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.vits.flow.FlipFlow">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.flow.</code><code class="sig-name descname">FlipFlow</code><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#FlipFlow"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.FlipFlow" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Flip flow module.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.gan_tts.vits.flow.FlipFlow.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">*args</em>, <em class="sig-param">inverse: bool = False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#FlipFlow.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.FlipFlow.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p></li>
<li><p><strong>inverse</strong> (<em>bool</em>) – Whether to inverse the flow.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Flipped tensor (B, channels, T).
Tensor: Log-determinant tensor for NLL (B,) if not inverse.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.vits.flow.LogFlow">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.flow.</code><code class="sig-name descname">LogFlow</code><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#LogFlow"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.LogFlow" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Log flow module.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.gan_tts.vits.flow.LogFlow.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: torch.Tensor</em>, <em class="sig-param">inverse: bool = False</em>, <em class="sig-param">eps: float = 1e-05</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#LogFlow.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.LogFlow.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p></li>
<li><p><strong>x_mask</strong> (<em>Tensor</em>) – Mask tensor (B, 1, T).</p></li>
<li><p><strong>inverse</strong> (<em>bool</em>) – Whether to inverse the flow.</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – Epsilon for log.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, channels, T).
Tensor: Log-determinant tensor for NLL (B,) if not inverse.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.vits.flow.Transpose">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.flow.</code><code class="sig-name descname">Transpose</code><span class="sig-paren">(</span><em class="sig-param">dim1: int</em>, <em class="sig-param">dim2: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#Transpose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.Transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transpose module for torch.nn.Sequential().</p>
<p>Initialize Transpose module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.vits.flow.Transpose.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/flow.html#Transpose.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.flow.Transpose.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Transpose.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-posterior-encoder">
<span id="id23"></span><h2>espnet2.gan_tts.vits.posterior_encoder<a class="headerlink" href="#espnet2-gan-tts-vits-posterior-encoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.posterior_encoder"></span><p>Posterior encoder module in VITS.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.vits.posterior_encoder.PosteriorEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.posterior_encoder.</code><code class="sig-name descname">PosteriorEncoder</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 513</em>, <em class="sig-param">out_channels: int = 192</em>, <em class="sig-param">hidden_channels: int = 192</em>, <em class="sig-param">kernel_size: int = 5</em>, <em class="sig-param">layers: int = 16</em>, <em class="sig-param">stacks: int = 1</em>, <em class="sig-param">base_dilation: int = 1</em>, <em class="sig-param">global_channels: int = -1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/posterior_encoder.html#PosteriorEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.posterior_encoder.PosteriorEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Posterior encoder module in VITS.</p>
<p>This is a module of posterior encoder described in <a class="reference external" href="https://arxiv.org/abs/2006.04558">Conditional Variational
Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</a>.</p>
<p>Initilialize PosteriorEncoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size in WaveNet.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of layers of WaveNet.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of repeat stacking of WaveNet.</p></li>
<li><p><strong>base_dilation</strong> (<em>int</em>) – Base dilation factor.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameters in conv.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to apply weight norm.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.posterior_encoder.PosteriorEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_lengths: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/posterior_encoder.html#PosteriorEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.posterior_encoder.PosteriorEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T_feats).</p></li>
<li><p><strong>x_lengths</strong> (<em>Tensor</em>) – Length tensor (B,).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded hidden representation tensor (B, out_channels, T_feats).
Tensor: Projected mean tensor (B, out_channels, T_feats).
Tensor: Projected scale tensor (B, out_channels, T_feats).
Tensor: Mask tensor for input tensor (B, 1, T_feats).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-generator">
<span id="id25"></span><h2>espnet2.gan_tts.vits.generator<a class="headerlink" href="#espnet2-gan-tts-vits-generator" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.generator"></span><p>Generator module in VITS.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.vits.generator.VITSGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.vits.generator.</code><code class="sig-name descname">VITSGenerator</code><span class="sig-paren">(</span><em class="sig-param">vocabs: int, aux_channels: int = 513, hidden_channels: int = 192, spks: Optional[int] = None, langs: Optional[int] = None, spk_embed_dim: Optional[int] = None, global_channels: int = -1, segment_size: int = 32, text_encoder_attention_heads: int = 2, text_encoder_ffn_expand: int = 4, text_encoder_blocks: int = 6, text_encoder_positionwise_layer_type: str = 'conv1d', text_encoder_positionwise_conv_kernel_size: int = 1, text_encoder_positional_encoding_layer_type: str = 'rel_pos', text_encoder_self_attention_layer_type: str = 'rel_selfattn', text_encoder_activation_type: str = 'swish', text_encoder_normalize_before: bool = True, text_encoder_dropout_rate: float = 0.1, text_encoder_positional_dropout_rate: float = 0.0, text_encoder_attention_dropout_rate: float = 0.0, text_encoder_conformer_kernel_size: int = 7, use_macaron_style_in_text_encoder: bool = True, use_conformer_conv_in_text_encoder: bool = True, decoder_kernel_size: int = 7, decoder_channels: int = 512, decoder_upsample_scales: List[int] = [8, 8, 2, 2], decoder_upsample_kernel_sizes: List[int] = [16, 16, 4, 4], decoder_resblock_kernel_sizes: List[int] = [3, 7, 11], decoder_resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], use_weight_norm_in_decoder: bool = True, posterior_encoder_kernel_size: int = 5, posterior_encoder_layers: int = 16, posterior_encoder_stacks: int = 1, posterior_encoder_base_dilation: int = 1, posterior_encoder_dropout_rate: float = 0.0, use_weight_norm_in_posterior_encoder: bool = True, flow_flows: int = 4, flow_kernel_size: int = 5, flow_base_dilation: int = 1, flow_layers: int = 4, flow_dropout_rate: float = 0.0, use_weight_norm_in_flow: bool = True, use_only_mean_in_flow: bool = True, stochastic_duration_predictor_kernel_size: int = 3, stochastic_duration_predictor_dropout_rate: float = 0.5, stochastic_duration_predictor_flows: int = 4, stochastic_duration_predictor_dds_conv_layers: int = 3</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/generator.html#VITSGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.generator.VITSGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Generator module in VITS.</p>
<p>This is a module of VITS described in <a class="reference external" href="https://arxiv.org/abs/2006.04558">Conditional Variational Autoencoder
with Adversarial Learning for End-to-End Text-to-Speech</a>.</p>
<p>As text encoder, we use conformer architecture instead of the relative positional
Transformer, which contains additional convolution layers.</p>
<p>Initialize VITS generator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocabs</strong> (<em>int</em>) – Input vocabulary size.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of acoustic feature channels.</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) – Number of hidden channels.</p></li>
<li><p><strong>spks</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Number of speakers. If set to &gt; 1, assume that the
sids will be provided as the input and use sid embedding layer.</p></li>
<li><p><strong>langs</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Number of languages. If set to &gt; 1, assume that the
lids will be provided as the input and use sid embedding layer.</p></li>
<li><p><strong>spk_embed_dim</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Speaker embedding dimension. If set to &gt; 0,
assume that spembs will be provided as the input.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size for decoder.</p></li>
<li><p><strong>text_encoder_attention_heads</strong> (<em>int</em>) – Number of heads in conformer block
of text encoder.</p></li>
<li><p><strong>text_encoder_ffn_expand</strong> (<em>int</em>) – Expansion ratio of FFN in conformer block
of text encoder.</p></li>
<li><p><strong>text_encoder_blocks</strong> (<em>int</em>) – Number of conformer blocks in text encoder.</p></li>
<li><p><strong>text_encoder_positionwise_layer_type</strong> (<em>str</em>) – Position-wise layer type in
conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_positionwise_conv_kernel_size</strong> (<em>int</em>) – Position-wise convolution
kernel size in conformer block of text encoder. Only used when the
above layer type is conv1d or conv1d-linear.</p></li>
<li><p><strong>text_encoder_positional_encoding_layer_type</strong> (<em>str</em>) – Positional encoding layer
type in conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_self_attention_layer_type</strong> (<em>str</em>) – Self-attention layer type in
conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_activation_type</strong> (<em>str</em>) – Activation function type in conformer
block of text encoder.</p></li>
<li><p><strong>text_encoder_normalize_before</strong> (<em>bool</em>) – Whether to apply layer norm before
self-attention in conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_dropout_rate</strong> (<em>float</em>) – Dropout rate in conformer block of
text encoder.</p></li>
<li><p><strong>text_encoder_positional_dropout_rate</strong> (<em>float</em>) – Dropout rate for positional
encoding in conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_attention_dropout_rate</strong> (<em>float</em>) – Dropout rate for attention in
conformer block of text encoder.</p></li>
<li><p><strong>text_encoder_conformer_kernel_size</strong> (<em>int</em>) – Conformer conv kernel size. It
will be used when only use_conformer_conv_in_text_encoder = True.</p></li>
<li><p><strong>use_macaron_style_in_text_encoder</strong> (<em>bool</em>) – Whether to use macaron style FFN
in conformer block of text encoder.</p></li>
<li><p><strong>use_conformer_conv_in_text_encoder</strong> (<em>bool</em>) – Whether to use covolution in
conformer block of text encoder.</p></li>
<li><p><strong>decoder_kernel_size</strong> (<em>int</em>) – Decoder kernel size.</p></li>
<li><p><strong>decoder_channels</strong> (<em>int</em>) – Number of decoder initial channels.</p></li>
<li><p><strong>decoder_upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales in decoder.</p></li>
<li><p><strong>decoder_upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel size for
upsampling layers in decoder.</p></li>
<li><p><strong>decoder_resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel size for resblocks
in decoder.</p></li>
<li><p><strong>decoder_resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for
resblocks in decoder.</p></li>
<li><p><strong>use_weight_norm_in_decoder</strong> (<em>bool</em>) – Whether to apply weight normalization in
decoder.</p></li>
<li><p><strong>posterior_encoder_kernel_size</strong> (<em>int</em>) – Posterior encoder kernel size.</p></li>
<li><p><strong>posterior_encoder_layers</strong> (<em>int</em>) – Number of layers of posterior encoder.</p></li>
<li><p><strong>posterior_encoder_stacks</strong> (<em>int</em>) – Number of stacks of posterior encoder.</p></li>
<li><p><strong>posterior_encoder_base_dilation</strong> (<em>int</em>) – Base dilation of posterior encoder.</p></li>
<li><p><strong>posterior_encoder_dropout_rate</strong> (<em>float</em>) – Dropout rate for posterior encoder.</p></li>
<li><p><strong>use_weight_norm_in_posterior_encoder</strong> (<em>bool</em>) – Whether to apply weight
normalization in posterior encoder.</p></li>
<li><p><strong>flow_flows</strong> (<em>int</em>) – Number of flows in flow.</p></li>
<li><p><strong>flow_kernel_size</strong> (<em>int</em>) – Kernel size in flow.</p></li>
<li><p><strong>flow_base_dilation</strong> (<em>int</em>) – Base dilation in flow.</p></li>
<li><p><strong>flow_layers</strong> (<em>int</em>) – Number of layers in flow.</p></li>
<li><p><strong>flow_dropout_rate</strong> (<em>float</em>) – Dropout rate in flow</p></li>
<li><p><strong>use_weight_norm_in_flow</strong> (<em>bool</em>) – Whether to apply weight normalization in
flow.</p></li>
<li><p><strong>use_only_mean_in_flow</strong> (<em>bool</em>) – Whether to use only mean in flow.</p></li>
<li><p><strong>stochastic_duration_predictor_kernel_size</strong> (<em>int</em>) – Kernel size in stochastic
duration predictor.</p></li>
<li><p><strong>stochastic_duration_predictor_dropout_rate</strong> (<em>float</em>) – Dropout rate in
stochastic duration predictor.</p></li>
<li><p><strong>stochastic_duration_predictor_flows</strong> (<em>int</em>) – Number of flows in stochastic
duration predictor.</p></li>
<li><p><strong>stochastic_duration_predictor_dds_conv_layers</strong> (<em>int</em>) – Number of DDS conv
layers in stochastic duration predictor.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.vits.generator.VITSGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_lengths: torch.Tensor</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/generator.html#VITSGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.generator.VITSGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, aux_channels, T_feats).</p></li>
<li><p><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker index tensor (B,) or (B, 1).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, spk_embed_dim).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language index tensor (B,) or (B, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Waveform tensor (B, 1, segment_size * upsample_factor).
Tensor: Duration negative log-likelihood (NLL) tensor (B,).
Tensor: Monotonic attention weight tensor (B, 1, T_feats, T_text).
Tensor: Segments start index tensor (B,).
Tensor: Text mask tensor (B, 1, T_text).
Tensor: Feature mask tensor (B, 1, T_feats).
tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:</p>
<blockquote>
<div><ul class="simple">
<li><p>Tensor: Posterior encoder hidden representation (B, H, T_feats).</p></li>
<li><p>Tensor: Flow hidden representation (B, H, T_feats).</p></li>
<li><p>Tensor: Expanded text encoder projected mean (B, H, T_feats).</p></li>
<li><p>Tensor: Expanded text encoder projected scale (B, H, T_feats).</p></li>
<li><p>Tensor: Posterior encoder projected mean (B, H, T_feats).</p></li>
<li><p>Tensor: Posterior encoder projected scale (B, H, T_feats).</p></li>
</ul>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.vits.generator.VITSGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: Optional[torch.Tensor] = None</em>, <em class="sig-param">feats_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">dur: Optional[torch.Tensor] = None</em>, <em class="sig-param">noise_scale: float = 0.667</em>, <em class="sig-param">noise_scale_dur: float = 0.8</em>, <em class="sig-param">alpha: float = 1.0</em>, <em class="sig-param">max_len: Optional[int] = None</em>, <em class="sig-param">use_teacher_forcing: bool = False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/generator.html#VITSGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.generator.VITSGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Run inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (B, T_text,).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, aux_channels, T_feats,).</p></li>
<li><p><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker index tensor (B,) or (B, 1).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, spk_embed_dim).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language index tensor (B,) or (B, 1).</p></li>
<li><p><strong>dur</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Ground-truth duration (B, T_text,). If provided,
skip the prediction of durations (i.e., teacher forcing).</p></li>
<li><p><strong>noise_scale</strong> (<em>float</em>) – Noise scale parameter for flow.</p></li>
<li><p><strong>noise_scale_dur</strong> (<em>float</em>) – Noise scale parameter for duration predictor.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – Alpha parameter to control the speed of generated speech.</p></li>
<li><p><strong>max_len</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Maximum length of acoustic feature sequence.</p></li>
<li><p><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Generated waveform tensor (B, T_wav).
Tensor: Monotonic attention weight tensor (B, T_feats, T_text).
Tensor: Duration tensor (B, T_text).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-vits-init">
<span id="id27"></span><h2>espnet2.gan_tts.vits.__init__<a class="headerlink" href="#espnet2-gan-tts-vits-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.__init__"></span></section>
<section id="espnet2-gan-tts-vits-monotonic-align-setup">
<span id="id28"></span><h2>espnet2.gan_tts.vits.monotonic_align.setup<a class="headerlink" href="#espnet2-gan-tts-vits-monotonic-align-setup" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-gan-tts-vits-monotonic-align-init">
<span id="id29"></span><h2>espnet2.gan_tts.vits.monotonic_align.__init__<a class="headerlink" href="#espnet2-gan-tts-vits-monotonic-align-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.vits.monotonic_align.__init__"></span><p>Maximum path calculation module.</p>
<p>This code is based on <a class="reference external" href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a>.</p>
<dl class="function">
<dt id="espnet2.gan_tts.vits.monotonic_align.__init__.maximum_path">
<code class="sig-prename descclassname">espnet2.gan_tts.vits.monotonic_align.__init__.</code><code class="sig-name descname">maximum_path</code><span class="sig-paren">(</span><em class="sig-param">neg_x_ent: torch.Tensor</em>, <em class="sig-param">attn_mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/vits/monotonic_align/__init__.html#maximum_path"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.monotonic_align.__init__.maximum_path" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate maximum path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neg_x_ent</strong> (<em>Tensor</em>) – Negative X entropy tensor (B, T_feats, T_text).</p></li>
<li><p><strong>attn_mask</strong> (<em>Tensor</em>) – Attention mask (B, T_feats, T_text).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Maximum path tensor (B, T_feats, T_text).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="espnet2.gan_tts.vits.monotonic_align.__init__.maximum_path_each_numba">
<code class="sig-prename descclassname">espnet2.gan_tts.vits.monotonic_align.__init__.</code><code class="sig-name descname">maximum_path_each_numba</code><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/monotonic_align/__init__.html#maximum_path_each_numba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.monotonic_align.__init__.maximum_path_each_numba" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate a single maximum path with numba.</p>
</dd></dl>

<dl class="attribute">
<dt id="espnet2.gan_tts.vits.monotonic_align.__init__.maximum_path_numba">
<code class="sig-prename descclassname">espnet2.gan_tts.vits.monotonic_align.__init__.</code><code class="sig-name descname">maximum_path_numba</code><a class="reference internal" href="../_modules/espnet2/gan_tts/vits/monotonic_align/__init__.html#maximum_path_numba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.vits.monotonic_align.__init__.maximum_path_numba" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate batch maximum path with numba.</p>
</dd></dl>

</section>
<section id="espnet2-gan-tts-style-melgan-style-melgan">
<span id="id30"></span><h2>espnet2.gan_tts.style_melgan.style_melgan<a class="headerlink" href="#espnet2-gan-tts-style-melgan-style-melgan" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.style_melgan.style_melgan"></span><p>StyleMelGAN Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.style_melgan.style_melgan.</code><code class="sig-name descname">StyleMelGANDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">repeats: int = 2, window_sizes: List[int] = [512, 1024, 2048, 4096], pqmf_params: List[List[int]] = [[1, None, None, None], [2, 62, 0.267, 9.0], [4, 62, 0.142, 9.0], [8, 62, 0.07949, 9.0]], discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 16, 'downsample_scales': [4, 4, 4, 1], 'kernel_sizes': [5, 3], 'max_downsample_channels': 512, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.2}, 'out_channels': 1, 'pad': 'ReflectionPad1d', 'pad_params': {}}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Style MelGAN disciminator module.</p>
<p>Initilize StyleMelGANDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>repeats</strong> (<em>int</em>) – Number of repititons to apply RWD.</p></li>
<li><p><strong>window_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of random window sizes.</p></li>
<li><p><strong>pqmf_params</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of Parameters for PQMF modules</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for base discriminator
module.</p></li>
<li><p><strong>use_weight_nom</strong> (<em>bool</em>) – Whether to apply weight normalization.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of discriminator outputs, #items in the list will be</dt><dd><p>equal to repeats * #discriminators.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANDiscriminator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANDiscriminator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.style_melgan.style_melgan.</code><code class="sig-name descname">StyleMelGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 128, aux_channels: int = 80, channels: int = 64, out_channels: int = 1, kernel_size: int = 9, dilation: int = 2, bias: bool = True, noise_upsample_scales: List[int] = [11, 2, 2, 2], noise_upsample_activation: str = 'LeakyReLU', noise_upsample_activation_params: Dict[str, Any] = {'negative_slope': 0.2}, upsample_scales: List[int] = [2, 2, 2, 2, 2, 2, 2, 2, 1], upsample_mode: str = 'nearest', gated_function: str = 'softmax', use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Style MelGAN generator module.</p>
<p>Initilize StyleMelGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input noise channels.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of auxiliary input channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of channels for conv layer.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of conv layers.</p></li>
<li><p><strong>dilation</strong> (<em>int</em>) – Dilation factor for conv layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>noise_upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of noise upsampling scales.</p></li>
<li><p><strong>noise_upsample_activation</strong> (<em>str</em>) – Activation function module name for noise
upsampling.</p></li>
<li><p><strong>noise_upsample_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for the
above activation function.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_mode</strong> (<em>str</em>) – Upsampling mode in TADE layer.</p></li>
<li><p><strong>gated_function</strong> (<em>str</em>) – Gated function used in TADEResBlock
(“softmax” or “sigmoid”).</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">z: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Auxiliary input tensor (B, channels, T).</p></li>
<li><p><strong>z</strong> (<em>Tensor</em>) – Input noise tensor (B, in_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T ** prod(upsample_scales)).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (T, in_channels).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T ** prod(upsample_scales), out_channels).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/style_melgan.html#StyleMelGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.style_melgan.StyleMelGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-style-melgan-tade-res-block">
<span id="id31"></span><h2>espnet2.gan_tts.style_melgan.tade_res_block<a class="headerlink" href="#espnet2-gan-tts-style-melgan-tade-res-block" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.style_melgan.tade_res_block"></span><p>StyleMelGAN’s TADEResBlock Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.style_melgan.tade_res_block.TADELayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.style_melgan.tade_res_block.</code><code class="sig-name descname">TADELayer</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">kernel_size: int = 9</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">upsample_factor: int = 2</em>, <em class="sig-param">upsample_mode: str = 'nearest'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/tade_res_block.html#TADELayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.tade_res_block.TADELayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>TADE Layer module.</p>
<p>Initilize TADELayer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channles.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of auxirialy channles.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv.</p></li>
<li><p><strong>upsample_factor</strong> (<em>int</em>) – Upsample factor.</p></li>
<li><p><strong>upsample_mode</strong> (<em>str</em>) – Upsample mode.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.tade_res_block.TADELayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/tade_res_block.html#TADELayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.tade_res_block.TADELayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>c</strong> (<em>Tensor</em>) – Auxiliary input tensor (B, aux_channels, T’).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, in_channels, T * in_upsample_factor).
Tensor: Upsampled aux tensor (B, in_channels, T * aux_upsample_factor).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.style_melgan.tade_res_block.TADEResBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.style_melgan.tade_res_block.</code><code class="sig-name descname">TADEResBlock</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">kernel_size: int = 9</em>, <em class="sig-param">dilation: int = 2</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">upsample_factor: int = 2</em>, <em class="sig-param">upsample_mode: str = 'nearest'</em>, <em class="sig-param">gated_function: str = 'softmax'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/tade_res_block.html#TADEResBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.tade_res_block.TADEResBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>TADEResBlock module.</p>
<p>Initialize TADEResBlock module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channles.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of auxirialy channles.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv.</p></li>
<li><p><strong>upsample_factor</strong> (<em>int</em>) – Upsample factor.</p></li>
<li><p><strong>upsample_mode</strong> (<em>str</em>) – Upsample mode.</p></li>
<li><p><strong>gated_function</strong> (<em>str</em>) – Gated function type (softmax of sigmoid).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.style_melgan.tade_res_block.TADEResBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">c: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/style_melgan/tade_res_block.html#TADEResBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.style_melgan.tade_res_block.TADEResBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>c</strong> (<em>Tensor</em>) – Auxiliary input tensor (B, aux_channels, T’).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, in_channels, T * in_upsample_factor).
Tensor: Upsampled auxirialy tensor (B, in_channels, T * in_upsample_factor).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-style-melgan-init">
<span id="id32"></span><h2>espnet2.gan_tts.style_melgan.__init__<a class="headerlink" href="#espnet2-gan-tts-style-melgan-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.style_melgan.__init__"></span></section>
<section id="espnet2-gan-tts-joint-joint-text2wav">
<span id="id33"></span><h2>espnet2.gan_tts.joint.joint_text2wav<a class="headerlink" href="#espnet2-gan-tts-joint-joint-text2wav" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.joint.joint_text2wav"></span><p>Joint text-to-wav module for end-to-end training.</p>
<dl class="class">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.joint.joint_text2wav.</code><code class="sig-name descname">JointText2Wav</code><span class="sig-paren">(</span><em class="sig-param">idim: int, odim: int, segment_size: int = 32, sampling_rate: int = 22050, text2mel_type: str = 'fastspeech2', text2mel_params: Dict[str, Any] = {'adim': 384, 'aheads': 2, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'conformer', 'dlayers': 4, 'dunits': 1536, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 4, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'conformer', 'energy_embed_dropout': 0.5, 'energy_embed_kernel_size': 1, 'energy_predictor_chans': 384, 'energy_predictor_dropout': 0.5, 'energy_predictor_kernel_size': 3, 'energy_predictor_layers': 2, 'eunits': 1536, 'gst_conv_chans_list': [32, 32, 64, 64, 128, 128], 'gst_conv_kernel_size': 3, 'gst_conv_layers': 6, 'gst_conv_stride': 2, 'gst_gru_layers': 1, 'gst_gru_units': 128, 'gst_heads': 4, 'gst_tokens': 10, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'langs': -1, 'pitch_embed_dropout': 0.5, 'pitch_embed_kernel_size': 1, 'pitch_predictor_chans': 384, 'pitch_predictor_dropout': 0.5, 'pitch_predictor_kernel_size': 5, 'pitch_predictor_layers': 5, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'postnet_chans': 512, 'postnet_dropout_rate': 0.5, 'postnet_filts': 5, 'postnet_layers': 5, 'reduction_factor': 1, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': -1, 'stop_gradient_from_energy_predictor': False, 'stop_gradient_from_pitch_predictor': True, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_gst': False, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, vocoder_type: str = 'hifigan_generator', vocoder_params: Dict[str, Any] = {'bias': True, 'channels': 512, 'global_channels': -1, 'kernel_size': 7, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'upsample_kernel_sizes': [16, 16, 4, 4], 'upsample_scales': [8, 8, 2, 2], 'use_additional_convs': True, 'use_weight_norm': True}, use_pqmf: bool = False, pqmf_params: Dict[str, Any] = {'beta': 9.0, 'cutoff_ratio': 0.142, 'subbands': 4, 'taps': 62}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, use_feat_match_loss: bool = True, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, use_mel_loss: bool = True, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_text2mel: float = 1.0, lambda_adv: float = 1.0, lambda_feat_match: float = 2.0, lambda_mel: float = 45.0, cache_generator_outputs: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/joint/joint_text2wav.html#JointText2Wav"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.gan_tts.abs_gan_tts.AbsGANTTS" title="espnet2.gan_tts.abs_gan_tts.AbsGANTTS"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.gan_tts.abs_gan_tts.AbsGANTTS</span></code></a></p>
<p>General class to jointly train text2mel and vocoder parts.</p>
<p>Initialize JointText2Wav module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will
be 1 since the model is the end-to-end text-to-wave model but for the
compatibility odim is used to indicate the acoustic feature dimension.</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size for random windowed inputs.</p></li>
<li><p><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will
be referred in saving waveform during the inference.</p></li>
<li><p><strong>text2mel_type</strong> (<em>str</em>) – The text2mel model type.</p></li>
<li><p><strong>text2mel_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for text2mel model.</p></li>
<li><p><strong>use_pqmf</strong> (<em>bool</em>) – Whether to use PQMF for multi-band vocoder.</p></li>
<li><p><strong>pqmf_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for PQMF module.</p></li>
<li><p><strong>vocoder_type</strong> (<em>str</em>) – The vocoder model type.</p></li>
<li><p><strong>vocoder_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for vocoder model.</p></li>
<li><p><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for discriminator.</p></li>
<li><p><strong>generator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for generator
adversarial loss.</p></li>
<li><p><strong>discriminator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for
discriminator adversarial loss.</p></li>
<li><p><strong>use_feat_match_loss</strong> (<em>bool</em>) – Whether to use feat match loss.</p></li>
<li><p><strong>feat_match_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for feat match loss.</p></li>
<li><p><strong>use_mel_loss</strong> (<em>bool</em>) – Whether to use mel loss.</p></li>
<li><p><strong>mel_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for mel loss.</p></li>
<li><p><strong>lambda_text2mel</strong> (<em>float</em>) – Loss scaling coefficient for text2mel model loss.</p></li>
<li><p><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</p></li>
<li><p><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</p></li>
<li><p><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel loss.</p></li>
<li><p><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_lengths: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">forward_generator: bool = True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/gan_tts/joint/joint_text2wav.html#JointText2Wav.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform generator forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, T_feats, aux_channels).</p></li>
<li><p><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
<li><p><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</p></li>
<li><p><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</p></li>
<li><p><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>loss (Tensor): Loss scalar tensor.</p></li>
<li><p>stats (Dict[str, float]): Statistics to be monitored.</p></li>
<li><p>weight (Tensor): Weight tensor to summarize losses.</p></li>
<li><p>optim_idx (int): Optimizer index (0 for G and 1 for D).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/joint/joint_text2wav.html#JointText2Wav.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Run inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>wav (Tensor): Generated waveform tensor (T_wav,).</p></li>
<li><p>feat_gan (Tensor): Generated feature tensor (T_text, C).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.require_raw_speech">
<em class="property">property </em><code class="sig-name descname">require_raw_speech</code><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.require_raw_speech" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not speech is required.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.require_vocoder">
<em class="property">property </em><code class="sig-name descname">require_vocoder</code><a class="headerlink" href="#espnet2.gan_tts.joint.joint_text2wav.JointText2Wav.require_vocoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not vocoder is required.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-joint-init">
<span id="id34"></span><h2>espnet2.gan_tts.joint.__init__<a class="headerlink" href="#espnet2-gan-tts-joint-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.joint.__init__"></span></section>
<section id="espnet2-gan-tts-hifigan-loss">
<span id="id35"></span><h2>espnet2.gan_tts.hifigan.loss<a class="headerlink" href="#espnet2-gan-tts-hifigan-loss" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.hifigan.loss"></span><p>HiFiGAN-related loss modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.hifigan.loss.DiscriminatorAdversarialLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.loss.</code><code class="sig-name descname">DiscriminatorAdversarialLoss</code><span class="sig-paren">(</span><em class="sig-param">average_by_discriminators: bool = True</em>, <em class="sig-param">loss_type: str = 'mse'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#DiscriminatorAdversarialLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.DiscriminatorAdversarialLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Discriminator adversarial loss module.</p>
<p>Initialize DiscriminatorAversarialLoss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>average_by_discriminators</strong> (<em>bool</em>) – Whether to average the loss by
the number of discriminators.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em>) – Loss type, “mse” or “hinge”.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.loss.DiscriminatorAdversarialLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">outputs_hat: Union[List[List[torch.Tensor]], List[torch.Tensor], torch.Tensor], outputs: Union[List[List[torch.Tensor]], List[torch.Tensor], torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#DiscriminatorAdversarialLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.DiscriminatorAdversarialLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calcualate discriminator adversarial loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs_hat</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – Discriminator
outputs, list of discriminator outputs, or list of list of discriminator
outputs calculated from generator.</p></li>
<li><p><strong>outputs</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – Discriminator
outputs, list of discriminator outputs, or list of list of discriminator
outputs calculated from groundtruth.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Discriminator real loss value.
Tensor: Discriminator fake loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.loss.FeatureMatchLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.loss.</code><code class="sig-name descname">FeatureMatchLoss</code><span class="sig-paren">(</span><em class="sig-param">average_by_layers: bool = True</em>, <em class="sig-param">average_by_discriminators: bool = True</em>, <em class="sig-param">include_final_outputs: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#FeatureMatchLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.FeatureMatchLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Feature matching loss module.</p>
<p>Initialize FeatureMatchLoss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>average_by_layers</strong> (<em>bool</em>) – Whether to average the loss by the number
of layers.</p></li>
<li><p><strong>average_by_discriminators</strong> (<em>bool</em>) – Whether to average the loss by
the number of discriminators.</p></li>
<li><p><strong>include_final_outputs</strong> (<em>bool</em>) – Whether to include the final output of
each discriminator for loss calculation.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.loss.FeatureMatchLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">feats_hat: Union[List[List[torch.Tensor]], List[torch.Tensor]], feats: Union[List[List[torch.Tensor]], List[torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#FeatureMatchLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.FeatureMatchLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate feature matching loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats_hat</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em>) – List of list of
discriminator outputs or list of discriminator outputs calcuated
from generator’s outputs.</p></li>
<li><p><strong>feats</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em>) – List of list of
discriminator outputs or list of discriminator outputs calcuated
from groundtruth..</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Feature matching loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.loss.GeneratorAdversarialLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.loss.</code><code class="sig-name descname">GeneratorAdversarialLoss</code><span class="sig-paren">(</span><em class="sig-param">average_by_discriminators: bool = True</em>, <em class="sig-param">loss_type: str = 'mse'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#GeneratorAdversarialLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.GeneratorAdversarialLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Generator adversarial loss module.</p>
<p>Initialize GeneratorAversarialLoss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>average_by_discriminators</strong> (<em>bool</em>) – Whether to average the loss by
the number of discriminators.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em>) – Loss type, “mse” or “hinge”.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.loss.GeneratorAdversarialLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">outputs: Union[List[List[torch.Tensor]], List[torch.Tensor], torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#GeneratorAdversarialLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.GeneratorAdversarialLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calcualate generator adversarial loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>outputs</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – Discriminator
outputs, list of discriminator outputs, or list of list of discriminator
outputs..</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Generator adversarial loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.loss.MelSpectrogramLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.loss.</code><code class="sig-name descname">MelSpectrogramLoss</code><span class="sig-paren">(</span><em class="sig-param">fs: int = 22050</em>, <em class="sig-param">n_fft: int = 1024</em>, <em class="sig-param">hop_length: int = 256</em>, <em class="sig-param">win_length: Optional[int] = None</em>, <em class="sig-param">window: str = 'hann'</em>, <em class="sig-param">n_mels: int = 80</em>, <em class="sig-param">fmin: Optional[int] = 0</em>, <em class="sig-param">fmax: Optional[int] = None</em>, <em class="sig-param">center: bool = True</em>, <em class="sig-param">normalized: bool = False</em>, <em class="sig-param">onesided: bool = True</em>, <em class="sig-param">log_base: Optional[float] = 10.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#MelSpectrogramLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.MelSpectrogramLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Mel-spectrogram loss.</p>
<p>Initialize Mel-spectrogram loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fs</strong> (<em>int</em>) – Sampling rate.</p></li>
<li><p><strong>n_fft</strong> (<em>int</em>) – FFT points.</p></li>
<li><p><strong>hop_length</strong> (<em>int</em>) – Hop length.</p></li>
<li><p><strong>win_length</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Window length.</p></li>
<li><p><strong>window</strong> (<em>str</em>) – Window type.</p></li>
<li><p><strong>n_mels</strong> (<em>int</em>) – Number of Mel basis.</p></li>
<li><p><strong>fmin</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Minimum frequency for Mel.</p></li>
<li><p><strong>fmax</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Maximum frequency for Mel.</p></li>
<li><p><strong>center</strong> (<em>bool</em>) – Whether to use center window.</p></li>
<li><p><strong>normalized</strong> (<em>bool</em>) – Whether to use normalized one.</p></li>
<li><p><strong>onesided</strong> (<em>bool</em>) – Whether to use oneseded one.</p></li>
<li><p><strong>log_base</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – Log base value.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.loss.MelSpectrogramLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">y_hat: torch.Tensor</em>, <em class="sig-param">y: torch.Tensor</em>, <em class="sig-param">spec: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/loss.html#MelSpectrogramLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.loss.MelSpectrogramLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate Mel-spectrogram loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_hat</strong> (<em>Tensor</em>) – Generated waveform tensor (B, 1, T).</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – Groundtruth waveform tensor (B, 1, T).</p></li>
<li><p><strong>spec</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Groundtruth linear amplitude spectrum tensor
(B, n_fft, T). if provided, use it instead of groundtruth waveform.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mel-spectrogram loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-hifigan-init">
<span id="id36"></span><h2>espnet2.gan_tts.hifigan.__init__<a class="headerlink" href="#espnet2-gan-tts-hifigan-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.hifigan.__init__"></span><dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, channels: int = 512, global_channels: int = -1, kernel_size: int = 7, upsample_scales: List[int] = [8, 8, 2, 2], upsample_kernel_sizes: List[int] = [16, 16, 4, 4], resblock_kernel_sizes: List[int] = [3, 7, 11], resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], use_additional_convs: bool = True, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN generator module.</p>
<p>Initialize HiFiGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for upsample layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for residual
blocks.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>torch.Tensor</em>) – Input tensor (T, in_channels).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T ** upsample_factor, out_channels).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANMultiPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">periods: List[int] = [2, 3, 5, 7, 11], discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN multi-period discriminator module.</p>
<p>Initialize HiFiGANMultiPeriodDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>periods</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of periods.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for hifi-gan period
discriminator module. The period parameter will be overwritten.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs, which consists of each</dt><dd><p>layer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANMultiScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 3, downsample_pooling: str = 'AvgPool1d', downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN multi-scale discriminator module.</p>
<p>Initilize HiFiGAN multi-scale discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>downsample_pooling_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the above pooling
module.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for hifi-gan scale
discriminator module.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the norm setting of the
official implementaion. The first discriminator uses spectral norm
and the other discriminators use weight norm.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs,</dt><dd><p>which consists of eachlayer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[torch.Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleMultiPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANMultiScaleMultiPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 3, scale_downsample_pooling: str = 'AvgPool1d', scale_downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, scale_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = True, periods: List[int] = [2, 3, 5, 7, 11], period_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleMultiPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleMultiPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN multi-scale + multi-period discriminator module.</p>
<p>Initilize HiFiGAN multi-scale + multi-period discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>scale_downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>scale_downsample_pooling_params</strong> (<em>dict</em>) – Parameters for the above pooling
module.</p></li>
<li><p><strong>scale_discriminator_params</strong> (<em>dict</em>) – Parameters for hifi-gan scale
discriminator module.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the norm setting of the
official implementaion. The first discriminator uses spectral norm and
the other discriminators use weight norm.</p></li>
<li><p><strong>periods</strong> (<em>list</em>) – List of periods.</p></li>
<li><p><strong>period_discriminator_params</strong> (<em>dict</em>) – Parameters for hifi-gan period
discriminator module. The period parameter will be overwritten.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleMultiPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleMultiPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANMultiScaleMultiPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs,</dt><dd><p>which consists of each layer output tensors. Multi scale and
multi period ones are concatenated.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, period: int = 3, kernel_sizes: List[int] = [5, 3], channels: int = 32, downsample_scales: List[int] = [3, 3, 3, 3, 1], max_downsample_channels: int = 1024, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True, use_spectral_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN period discriminator module.</p>
<p>Initialize HiFiGANPeriodDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>period</strong> (<em>int</em>) – Period.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>list</em>) – Kernel sizes of initial conv layers and the final conv
layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of initial channels.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Number of maximum downsampling channels.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.apply_spectral_norm">
<code class="sig-name descname">apply_spectral_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.apply_spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.apply_spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply spectral normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of each layer’s tensors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.__init__.</code><code class="sig-name descname">HiFiGANScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, kernel_sizes: List[int] = [15, 41, 5, 3], channels: int = 128, max_downsample_channels: int = 1024, max_groups: int = 16, bias: int = True, downsample_scales: List[int] = [2, 2, 4, 4, 1], nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True, use_spectral_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN scale discriminator module.</p>
<p>Initilize HiFiGAN scale discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of four kernel sizes. The first will be used
for the first conv layer, and the second is for downsampling part, and
the remaining two are for the last two output layers.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Maximum number of channels for downsampling
layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral norm. If set to true, it
will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.apply_spectral_norm">
<code class="sig-name descname">apply_spectral_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.apply_spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.apply_spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply spectral normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.__init__.HiFiGANScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of output tensors of each layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-hifigan-hifigan">
<span id="id37"></span><h2>espnet2.gan_tts.hifigan.hifigan<a class="headerlink" href="#espnet2-gan-tts-hifigan-hifigan" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.hifigan.hifigan"></span><p>HiFi-GAN Modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANGenerator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 80, out_channels: int = 1, channels: int = 512, global_channels: int = -1, kernel_size: int = 7, upsample_scales: List[int] = [8, 8, 2, 2], upsample_kernel_sizes: List[int] = [16, 16, 4, 4], resblock_kernel_sizes: List[int] = [3, 7, 11], resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], use_additional_convs: bool = True, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN generator module.</p>
<p>Initialize HiFiGANGenerator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for upsample layers.</p></li>
<li><p><strong>resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for residual blocks.</p></li>
<li><p><strong>resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations for residual
blocks.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, out_channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">c: torch.Tensor</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>torch.Tensor</em>) – Input tensor (T, in_channels).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (T ** upsample_factor, out_channels).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANGenerator.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANGenerator.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
<p>This initialization follows the official implementation manner.
<a class="reference external" href="https://github.com/jik876/hifi-gan/blob/master/models.py">https://github.com/jik876/hifi-gan/blob/master/models.py</a></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANMultiPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">periods: List[int] = [2, 3, 5, 7, 11], discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN multi-period discriminator module.</p>
<p>Initialize HiFiGANMultiPeriodDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>periods</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of periods.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for hifi-gan period
discriminator module. The period parameter will be overwritten.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs, which consists of each</dt><dd><p>layer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANMultiScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 3, downsample_pooling: str = 'AvgPool1d', downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN multi-scale discriminator module.</p>
<p>Initilize HiFiGAN multi-scale discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>downsample_pooling_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for the above pooling
module.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameters for hifi-gan scale
discriminator module.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the norm setting of the
official implementaion. The first discriminator uses spectral norm
and the other discriminators use weight norm.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs,</dt><dd><p>which consists of eachlayer output tensors.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[torch.Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleMultiPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANMultiScaleMultiPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">scales: int = 3, scale_downsample_pooling: str = 'AvgPool1d', scale_downsample_pooling_params: Dict[str, Any] = {'kernel_size': 4, 'padding': 2, 'stride': 2}, scale_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1}, follow_official_norm: bool = True, periods: List[int] = [2, 3, 5, 7, 11], period_discriminator_params: Dict[str, Any] = {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleMultiPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleMultiPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN multi-scale + multi-period discriminator module.</p>
<p>Initilize HiFiGAN multi-scale + multi-period discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>int</em>) – Number of multi-scales.</p></li>
<li><p><strong>scale_downsample_pooling</strong> (<em>str</em>) – Pooling module name for downsampling of the
inputs.</p></li>
<li><p><strong>scale_downsample_pooling_params</strong> (<em>dict</em>) – Parameters for the above pooling
module.</p></li>
<li><p><strong>scale_discriminator_params</strong> (<em>dict</em>) – Parameters for hifi-gan scale
discriminator module.</p></li>
<li><p><strong>follow_official_norm</strong> (<em>bool</em>) – Whether to follow the norm setting of the
official implementaion. The first discriminator uses spectral norm and
the other discriminators use weight norm.</p></li>
<li><p><strong>periods</strong> (<em>list</em>) – List of periods.</p></li>
<li><p><strong>period_discriminator_params</strong> (<em>dict</em>) – Parameters for hifi-gan period
discriminator module. The period parameter will be overwritten.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleMultiPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANMultiScaleMultiPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANMultiScaleMultiPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of list of each discriminator outputs,</dt><dd><p>which consists of each layer output tensors. Multi scale and
multi period ones are concatenated.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[Tensor]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANPeriodDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, period: int = 3, kernel_sizes: List[int] = [5, 3], channels: int = 32, downsample_scales: List[int] = [3, 3, 3, 3, 1], max_downsample_channels: int = 1024, bias: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True, use_spectral_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFiGAN period discriminator module.</p>
<p>Initialize HiFiGANPeriodDiscriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>period</strong> (<em>int</em>) – Period.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>list</em>) – Kernel sizes of initial conv layers and the final conv
layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of initial channels.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Number of maximum downsampling channels.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers in
residual blocks.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.apply_spectral_norm">
<code class="sig-name descname">apply_spectral_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.apply_spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.apply_spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply spectral normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANPeriodDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANPeriodDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>c</strong> (<em>Tensor</em>) – Input tensor (B, in_channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of each layer’s tensors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.hifigan.</code><code class="sig-name descname">HiFiGANScaleDiscriminator</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1, out_channels: int = 1, kernel_sizes: List[int] = [15, 41, 5, 3], channels: int = 128, max_downsample_channels: int = 1024, max_groups: int = 16, bias: int = True, downsample_scales: List[int] = [2, 2, 4, 4, 1], nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, use_weight_norm: bool = True, use_spectral_norm: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>HiFi-GAN scale discriminator module.</p>
<p>Initilize HiFiGAN scale discriminator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of four kernel sizes. The first will be used
for the first conv layer, and the second is for downsampling part, and
the remaining two are for the last two output layers.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Initial number of channels for conv layer.</p></li>
<li><p><strong>max_downsample_channels</strong> (<em>int</em>) – Maximum number of channels for downsampling
layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>downsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of downsampling scales.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
<li><p><strong>use_spectral_norm</strong> (<em>bool</em>) – Whether to use spectral norm. If set to true, it
will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.apply_spectral_norm">
<code class="sig-name descname">apply_spectral_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.apply_spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.apply_spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply spectral normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/hifigan.html#HiFiGANScaleDiscriminator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.hifigan.HiFiGANScaleDiscriminator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of output tensors of each layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-hifigan-residual-block">
<span id="id38"></span><h2>espnet2.gan_tts.hifigan.residual_block<a class="headerlink" href="#espnet2-gan-tts-hifigan-residual-block" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.hifigan.residual_block"></span><p>HiFiGAN Residual block modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.hifigan.residual_block.ResidualBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.hifigan.residual_block.</code><code class="sig-name descname">ResidualBlock</code><span class="sig-paren">(</span><em class="sig-param">kernel_size: int = 3, channels: int = 512, dilations: List[int] = [1, 3, 5], bias: bool = True, use_additional_convs: bool = True, nonlinear_activation: str = 'LeakyReLU', nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/residual_block.html#ResidualBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.residual_block.ResidualBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Residual block module in HiFiGAN.</p>
<p>Initialize ResidualBlock module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilation convolution layer.</p></li>
<li><p><strong>channels</strong> (<em>int</em>) – Number of channels for convolution layer.</p></li>
<li><p><strong>dilations</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of dilation factors.</p></li>
<li><p><strong>use_additional_convs</strong> (<em>bool</em>) – Whether to use additional convolution layers.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for activation
function.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.hifigan.residual_block.ResidualBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/hifigan/residual_block.html#ResidualBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.hifigan.residual_block.ResidualBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (B, channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-jets-alignments">
<span id="id39"></span><h2>espnet2.gan_tts.jets.alignments<a class="headerlink" href="#espnet2-gan-tts-jets-alignments" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.jets.alignments"></span><dl class="class">
<dt id="espnet2.gan_tts.jets.alignments.AlignmentModule">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.jets.alignments.</code><code class="sig-name descname">AlignmentModule</code><span class="sig-paren">(</span><em class="sig-param">adim</em>, <em class="sig-param">odim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/alignments.html#AlignmentModule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.alignments.AlignmentModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Alignment Learning Framework proposed for parallel TTS models in:</p>
<p><a class="reference external" href="https://arxiv.org/abs/2108.10447">https://arxiv.org/abs/2108.10447</a></p>
<dl class="method">
<dt id="espnet2.gan_tts.jets.alignments.AlignmentModule.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text</em>, <em class="sig-param">feats</em>, <em class="sig-param">x_masks=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/alignments.html#AlignmentModule.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.alignments.AlignmentModule.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate alignment loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Batched text embedding (B, T_text, adim).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Batched acoustic feature (B, T_feats, odim).</p></li>
<li><p><strong>x_masks</strong> (<em>Tensor</em>) – Mask tensor (B, T_text).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Log probability of attention matrix (B, T_feats, T_text).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.jets.alignments.average_by_duration">
<code class="sig-prename descclassname">espnet2.gan_tts.jets.alignments.</code><code class="sig-name descname">average_by_duration</code><span class="sig-paren">(</span><em class="sig-param">ds</em>, <em class="sig-param">xs</em>, <em class="sig-param">text_lengths</em>, <em class="sig-param">feats_lengths</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/alignments.html#average_by_duration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.alignments.average_by_duration" title="Permalink to this definition">¶</a></dt>
<dd><p>Average frame-level features into token-level according to durations</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ds</strong> (<em>Tensor</em>) – Batched token duration (B, T_text).</p></li>
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batched feature sequences to be averaged (B, T_feats).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batched feature averaged according to the token duration (B, T_text).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.gan_tts.jets.alignments.viterbi_decode">
<code class="sig-prename descclassname">espnet2.gan_tts.jets.alignments.</code><code class="sig-name descname">viterbi_decode</code><span class="sig-paren">(</span><em class="sig-param">log_p_attn</em>, <em class="sig-param">text_lengths</em>, <em class="sig-param">feats_lengths</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/alignments.html#viterbi_decode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.alignments.viterbi_decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract duration from an attention probability matrix</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_p_attn</strong> (<em>Tensor</em>) – Batched log probability of attention
matrix (B, T_feats, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats_legnths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batched token duration extracted from <cite>log_p_attn</cite> (B, T_text).
Tensor: Binarization loss tensor ().</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-gan-tts-jets-length-regulator">
<span id="id40"></span><h2>espnet2.gan_tts.jets.length_regulator<a class="headerlink" href="#espnet2-gan-tts-jets-length-regulator" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.jets.length_regulator"></span><dl class="class">
<dt id="espnet2.gan_tts.jets.length_regulator.GaussianUpsampling">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.jets.length_regulator.</code><code class="sig-name descname">GaussianUpsampling</code><span class="sig-paren">(</span><em class="sig-param">delta=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/length_regulator.html#GaussianUpsampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.length_regulator.GaussianUpsampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Gaussian upsampling with fixed temperature as in:</p>
<p><a class="reference external" href="https://arxiv.org/abs/2010.04301">https://arxiv.org/abs/2010.04301</a></p>
<dl class="method">
<dt id="espnet2.gan_tts.jets.length_regulator.GaussianUpsampling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs</em>, <em class="sig-param">ds</em>, <em class="sig-param">h_masks=None</em>, <em class="sig-param">d_masks=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/length_regulator.html#GaussianUpsampling.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.length_regulator.GaussianUpsampling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Upsample hidden states according to durations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs</strong> (<em>Tensor</em>) – Batched hidden state to be expanded (B, T_text, adim).</p></li>
<li><p><strong>ds</strong> (<em>Tensor</em>) – Batched token duration (B, T_text).</p></li>
<li><p><strong>h_masks</strong> (<em>Tensor</em>) – Mask tensor (B, T_feats).</p></li>
<li><p><strong>d_masks</strong> (<em>Tensor</em>) – Mask tensor (B, T_text).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Expanded hidden state (B, T_feat, adim).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-jets-loss">
<span id="id41"></span><h2>espnet2.gan_tts.jets.loss<a class="headerlink" href="#espnet2-gan-tts-jets-loss" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.jets.loss"></span><p>JETS related loss module for ESPnet2.</p>
<dl class="class">
<dt id="espnet2.gan_tts.jets.loss.ForwardSumLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.jets.loss.</code><code class="sig-name descname">ForwardSumLoss</code><span class="sig-paren">(</span><em class="sig-param">cache_prior: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/loss.html#ForwardSumLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.loss.ForwardSumLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Forwardsum loss described at <a class="reference external" href="https://openreview.net/forum?id=0NQwnnwAORi">https://openreview.net/forum?id=0NQwnnwAORi</a></p>
<p>Initialize forwardsum loss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cache_prior</strong> (<em>bool</em>) – Whether to cache beta-binomial prior</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.jets.loss.ForwardSumLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">log_p_attn: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">olens: torch.Tensor</em>, <em class="sig-param">blank_prob: float = 0.36787944117144233</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/jets/loss.html#ForwardSumLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.loss.ForwardSumLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_p_attn</strong> (<em>Tensor</em>) – Batch of log probability of attention matrix
(B, T_feats, T_text).</p></li>
<li><p><strong>ilens</strong> (<em>Tensor</em>) – Batch of the lengths of each input (B,).</p></li>
<li><p><strong>olens</strong> (<em>Tensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>blank_prob</strong> (<em>float</em>) – Blank symbol probability.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>forwardsum loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.jets.loss.VarianceLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.jets.loss.</code><code class="sig-name descname">VarianceLoss</code><span class="sig-paren">(</span><em class="sig-param">use_masking: bool = True</em>, <em class="sig-param">use_weighted_masking: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/loss.html#VarianceLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.loss.VarianceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize JETS variance loss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_masking</strong> (<em>bool</em>) – Whether to apply masking for padded part in loss
calculation.</p></li>
<li><p><strong>use_weighted_masking</strong> (<em>bool</em>) – Whether to weighted masking in loss
calculation.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.jets.loss.VarianceLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">d_outs: torch.Tensor</em>, <em class="sig-param">ds: torch.Tensor</em>, <em class="sig-param">p_outs: torch.Tensor</em>, <em class="sig-param">ps: torch.Tensor</em>, <em class="sig-param">e_outs: torch.Tensor</em>, <em class="sig-param">es: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/jets/loss.html#VarianceLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.loss.VarianceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_outs</strong> (<em>LongTensor</em>) – Batch of outputs of duration predictor (B, T_text).</p></li>
<li><p><strong>ds</strong> (<em>LongTensor</em>) – Batch of durations (B, T_text).</p></li>
<li><p><strong>p_outs</strong> (<em>Tensor</em>) – Batch of outputs of pitch predictor (B, T_text, 1).</p></li>
<li><p><strong>ps</strong> (<em>Tensor</em>) – Batch of target token-averaged pitch (B, T_text, 1).</p></li>
<li><p><strong>e_outs</strong> (<em>Tensor</em>) – Batch of outputs of energy predictor (B, T_text, 1).</p></li>
<li><p><strong>es</strong> (<em>Tensor</em>) – Batch of target token-averaged energy (B, T_text, 1).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of the lengths of each input (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Duration predictor loss value.
Tensor: Pitch predictor loss value.
Tensor: Energy predictor loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-jets-jets">
<span id="id42"></span><h2>espnet2.gan_tts.jets.jets<a class="headerlink" href="#espnet2-gan-tts-jets-jets" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.jets.jets"></span><p>JETS module for GAN-TTS task.</p>
<dl class="class">
<dt id="espnet2.gan_tts.jets.jets.JETS">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.jets.jets.</code><code class="sig-name descname">JETS</code><span class="sig-paren">(</span><em class="sig-param">idim: int, odim: int, sampling_rate: int = 22050, generator_type: str = 'jets_generator', generator_params: Dict[str, Any] = {'adim': 256, 'aheads': 2, 'conformer_activation_type': 'swish', 'conformer_dec_kernel_size': 31, 'conformer_enc_kernel_size': 7, 'conformer_pos_enc_layer_type': 'rel_pos', 'conformer_rel_pos_type': 'latest', 'conformer_self_attn_layer_type': 'rel_selfattn', 'decoder_concat_after': False, 'decoder_normalize_before': True, 'decoder_type': 'transformer', 'dlayers': 4, 'dunits': 1024, 'duration_predictor_chans': 384, 'duration_predictor_dropout_rate': 0.1, 'duration_predictor_kernel_size': 3, 'duration_predictor_layers': 2, 'elayers': 4, 'encoder_concat_after': False, 'encoder_normalize_before': True, 'encoder_type': 'transformer', 'energy_embed_dropout': 0.5, 'energy_embed_kernel_size': 1, 'energy_predictor_chans': 384, 'energy_predictor_dropout': 0.5, 'energy_predictor_kernel_size': 3, 'energy_predictor_layers': 2, 'eunits': 1024, 'generator_bias': True, 'generator_channels': 512, 'generator_global_channels': -1, 'generator_kernel_size': 7, 'generator_nonlinear_activation': 'LeakyReLU', 'generator_nonlinear_activation_params': {'negative_slope': 0.1}, 'generator_out_channels': 1, 'generator_resblock_dilations': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'generator_resblock_kernel_sizes': [3, 7, 11], 'generator_upsample_kernel_sizes': [16, 16, 4, 4], 'generator_upsample_scales': [8, 8, 2, 2], 'generator_use_additional_convs': True, 'generator_use_weight_norm': True, 'gst_conv_chans_list': [32, 32, 64, 64, 128, 128], 'gst_conv_kernel_size': 3, 'gst_conv_layers': 6, 'gst_conv_stride': 2, 'gst_gru_layers': 1, 'gst_gru_units': 128, 'gst_heads': 4, 'gst_tokens': 10, 'init_dec_alpha': 1.0, 'init_enc_alpha': 1.0, 'init_type': 'xavier_uniform', 'langs': -1, 'pitch_embed_dropout': 0.5, 'pitch_embed_kernel_size': 1, 'pitch_predictor_chans': 384, 'pitch_predictor_dropout': 0.5, 'pitch_predictor_kernel_size': 5, 'pitch_predictor_layers': 5, 'positionwise_conv_kernel_size': 1, 'positionwise_layer_type': 'conv1d', 'reduction_factor': 1, 'segment_size': 64, 'spk_embed_dim': None, 'spk_embed_integration_type': 'add', 'spks': -1, 'stop_gradient_from_energy_predictor': False, 'stop_gradient_from_pitch_predictor': True, 'transformer_dec_attn_dropout_rate': 0.1, 'transformer_dec_dropout_rate': 0.1, 'transformer_dec_positional_dropout_rate': 0.1, 'transformer_enc_attn_dropout_rate': 0.1, 'transformer_enc_dropout_rate': 0.1, 'transformer_enc_positional_dropout_rate': 0.1, 'use_batch_norm': True, 'use_cnn_in_conformer': True, 'use_gst': False, 'use_macaron_style_in_conformer': True, 'use_masking': False, 'use_scaled_pos_enc': True, 'use_weighted_masking': False, 'zero_triu': False}, discriminator_type: str = 'hifigan_multi_scale_multi_period_discriminator', discriminator_params: Dict[str, Any] = {'follow_official_norm': False, 'period_discriminator_params': {'bias': True, 'channels': 32, 'downsample_scales': [3, 3, 3, 3, 1], 'in_channels': 1, 'kernel_sizes': [5, 3], 'max_downsample_channels': 1024, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'periods': [2, 3, 5, 7, 11], 'scale_discriminator_params': {'bias': True, 'channels': 128, 'downsample_scales': [2, 2, 4, 4, 1], 'in_channels': 1, 'kernel_sizes': [15, 41, 5, 3], 'max_downsample_channels': 1024, 'max_groups': 16, 'nonlinear_activation': 'LeakyReLU', 'nonlinear_activation_params': {'negative_slope': 0.1}, 'out_channels': 1, 'use_spectral_norm': False, 'use_weight_norm': True}, 'scale_downsample_pooling': 'AvgPool1d', 'scale_downsample_pooling_params': {'kernel_size': 4, 'padding': 2, 'stride': 2}, 'scales': 1}, generator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, discriminator_adv_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'loss_type': 'mse'}, feat_match_loss_params: Dict[str, Any] = {'average_by_discriminators': False, 'average_by_layers': False, 'include_final_outputs': True}, mel_loss_params: Dict[str, Any] = {'fmax': None, 'fmin': 0, 'fs': 22050, 'hop_length': 256, 'log_base': None, 'n_fft': 1024, 'n_mels': 80, 'win_length': None, 'window': 'hann'}, lambda_adv: float = 1.0, lambda_mel: float = 45.0, lambda_feat_match: float = 2.0, lambda_var: float = 1.0, lambda_align: float = 2.0, cache_generator_outputs: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/jets.html#JETS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.jets.JETS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.gan_tts.abs_gan_tts.AbsGANTTS" title="espnet2.gan_tts.abs_gan_tts.AbsGANTTS"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.gan_tts.abs_gan_tts.AbsGANTTS</span></code></a></p>
<p>JETS module (generator + discriminator).</p>
<p>This is a module of JETS described in <a href="#id43"><span class="problematic" id="id44">`</span></a>JETS: Jointly Training FastSpeech2
and HiFi-GAN for End to End Text to Speech’_.</p>
<p>Initialize JETS module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input vocabrary size.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Acoustic feature dimension. The actual output channels will
be 1 since JETS is the end-to-end text-to-wave model but for the
compatibility odim is used to indicate the acoustic feature dimension.</p></li>
<li><p><strong>sampling_rate</strong> (<em>int</em>) – Sampling rate, not used for the training but it will
be referred in saving waveform during the inference.</p></li>
<li><p><strong>generator_type</strong> (<em>str</em>) – Generator type.</p></li>
<li><p><strong>generator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for generator.</p></li>
<li><p><strong>discriminator_type</strong> (<em>str</em>) – Discriminator type.</p></li>
<li><p><strong>discriminator_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for discriminator.</p></li>
<li><p><strong>generator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for generator
adversarial loss.</p></li>
<li><p><strong>discriminator_adv_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for
discriminator adversarial loss.</p></li>
<li><p><strong>feat_match_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for feat match loss.</p></li>
<li><p><strong>mel_loss_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Parameter dict for mel loss.</p></li>
<li><p><strong>lambda_adv</strong> (<em>float</em>) – Loss scaling coefficient for adversarial loss.</p></li>
<li><p><strong>lambda_mel</strong> (<em>float</em>) – Loss scaling coefficient for mel spectrogram loss.</p></li>
<li><p><strong>lambda_feat_match</strong> (<em>float</em>) – Loss scaling coefficient for feat match loss.</p></li>
<li><p><strong>lambda_var</strong> (<em>float</em>) – Loss scaling coefficient for variance loss.</p></li>
<li><p><strong>lambda_align</strong> (<em>float</em>) – Loss scaling coefficient for alignment loss.</p></li>
<li><p><strong>cache_generator_outputs</strong> (<em>bool</em>) – Whether to cache generator outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.jets.jets.JETS.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_lengths: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">forward_generator: bool = True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/gan_tts/jets/jets.html#JETS.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.jets.JETS.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform generator forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, T_feats, aux_channels).</p></li>
<li><p><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
<li><p><strong>speech</strong> (<em>Tensor</em>) – Speech waveform tensor (B, T_wav).</p></li>
<li><p><strong>speech_lengths</strong> (<em>Tensor</em>) – Speech length tensor (B,).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker index tensor (B,) or (B, 1).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, spk_embed_dim).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language index tensor (B,) or (B, 1).</p></li>
<li><p><strong>forward_generator</strong> (<em>bool</em>) – Whether to forward generator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>loss (Tensor): Loss scalar tensor.</p></li>
<li><p>stats (Dict[str, float]): Statistics to be monitored.</p></li>
<li><p>weight (Tensor): Weight tensor to summarize losses.</p></li>
<li><p>optim_idx (int): Optimizer index (0 for G and 1 for D).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.jets.jets.JETS.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">feats: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy: Optional[torch.Tensor] = None</em>, <em class="sig-param">use_teacher_forcing: bool = False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/jets/jets.html#JETS.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.jets.JETS.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Run inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (T_text,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (T_feats, aux_channels).</p></li>
<li><p><strong>pitch</strong> (<em>Tensor</em>) – Pitch tensor (T_feats, 1).</p></li>
<li><p><strong>energy</strong> (<em>Tensor</em>) – Energy tensor (T_feats, 1).</p></li>
<li><p><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>wav (Tensor): Generated waveform tensor (T_wav,).</p></li>
<li><p>duration (Tensor): Predicted duration tensor (T_text,).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.jets.jets.JETS.require_raw_speech">
<em class="property">property </em><code class="sig-name descname">require_raw_speech</code><a class="headerlink" href="#espnet2.gan_tts.jets.jets.JETS.require_raw_speech" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not speech is required.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.jets.jets.JETS.require_vocoder">
<em class="property">property </em><code class="sig-name descname">require_vocoder</code><a class="headerlink" href="#espnet2.gan_tts.jets.jets.JETS.require_vocoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether or not vocoder is required.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-jets-generator">
<span id="id45"></span><h2>espnet2.gan_tts.jets.generator<a class="headerlink" href="#espnet2-gan-tts-jets-generator" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.jets.generator"></span><p>Generator module in JETS.</p>
<dl class="class">
<dt id="espnet2.gan_tts.jets.generator.JETSGenerator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.jets.generator.</code><code class="sig-name descname">JETSGenerator</code><span class="sig-paren">(</span><em class="sig-param">idim: int, odim: int, adim: int = 256, aheads: int = 2, elayers: int = 4, eunits: int = 1024, dlayers: int = 4, dunits: int = 1024, positionwise_layer_type: str = 'conv1d', positionwise_conv_kernel_size: int = 1, use_scaled_pos_enc: bool = True, use_batch_norm: bool = True, encoder_normalize_before: bool = True, decoder_normalize_before: bool = True, encoder_concat_after: bool = False, decoder_concat_after: bool = False, reduction_factor: int = 1, encoder_type: str = 'transformer', decoder_type: str = 'transformer', transformer_enc_dropout_rate: float = 0.1, transformer_enc_positional_dropout_rate: float = 0.1, transformer_enc_attn_dropout_rate: float = 0.1, transformer_dec_dropout_rate: float = 0.1, transformer_dec_positional_dropout_rate: float = 0.1, transformer_dec_attn_dropout_rate: float = 0.1, conformer_rel_pos_type: str = 'legacy', conformer_pos_enc_layer_type: str = 'rel_pos', conformer_self_attn_layer_type: str = 'rel_selfattn', conformer_activation_type: str = 'swish', use_macaron_style_in_conformer: bool = True, use_cnn_in_conformer: bool = True, zero_triu: bool = False, conformer_enc_kernel_size: int = 7, conformer_dec_kernel_size: int = 31, duration_predictor_layers: int = 2, duration_predictor_chans: int = 384, duration_predictor_kernel_size: int = 3, duration_predictor_dropout_rate: float = 0.1, energy_predictor_layers: int = 2, energy_predictor_chans: int = 384, energy_predictor_kernel_size: int = 3, energy_predictor_dropout: float = 0.5, energy_embed_kernel_size: int = 9, energy_embed_dropout: float = 0.5, stop_gradient_from_energy_predictor: bool = False, pitch_predictor_layers: int = 2, pitch_predictor_chans: int = 384, pitch_predictor_kernel_size: int = 3, pitch_predictor_dropout: float = 0.5, pitch_embed_kernel_size: int = 9, pitch_embed_dropout: float = 0.5, stop_gradient_from_pitch_predictor: bool = False, spks: Optional[int] = None, langs: Optional[int] = None, spk_embed_dim: Optional[int] = None, spk_embed_integration_type: str = 'add', use_gst: bool = False, gst_tokens: int = 10, gst_heads: int = 4, gst_conv_layers: int = 6, gst_conv_chans_list: Sequence[int] = (32, 32, 64, 64, 128, 128), gst_conv_kernel_size: int = 3, gst_conv_stride: int = 2, gst_gru_layers: int = 1, gst_gru_units: int = 128, init_type: str = 'xavier_uniform', init_enc_alpha: float = 1.0, init_dec_alpha: float = 1.0, use_masking: bool = False, use_weighted_masking: bool = False, segment_size: int = 64, generator_out_channels: int = 1, generator_channels: int = 512, generator_global_channels: int = -1, generator_kernel_size: int = 7, generator_upsample_scales: List[int] = [8, 8, 2, 2], generator_upsample_kernel_sizes: List[int] = [16, 16, 4, 4], generator_resblock_kernel_sizes: List[int] = [3, 7, 11], generator_resblock_dilations: List[List[int]] = [[1, 3, 5], [1, 3, 5], [1, 3, 5]], generator_use_additional_convs: bool = True, generator_bias: bool = True, generator_nonlinear_activation: str = 'LeakyReLU', generator_nonlinear_activation_params: Dict[str, Any] = {'negative_slope': 0.1}, generator_use_weight_norm: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/jets/generator.html#JETSGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.generator.JETSGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Generator module in JETS.</p>
<p>Initialize JETS generator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>elayers</strong> (<em>int</em>) – Number of encoder layers.</p></li>
<li><p><strong>eunits</strong> (<em>int</em>) – Number of encoder hidden units.</p></li>
<li><p><strong>dlayers</strong> (<em>int</em>) – Number of decoder layers.</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – Number of decoder hidden units.</p></li>
<li><p><strong>use_scaled_pos_enc</strong> (<em>bool</em>) – Whether to use trainable scaled pos encoding.</p></li>
<li><p><strong>use_batch_norm</strong> (<em>bool</em>) – Whether to use batch normalization in encoder prenet.</p></li>
<li><p><strong>encoder_normalize_before</strong> (<em>bool</em>) – Whether to apply layernorm layer before
encoder block.</p></li>
<li><p><strong>decoder_normalize_before</strong> (<em>bool</em>) – Whether to apply layernorm layer before
decoder block.</p></li>
<li><p><strong>encoder_concat_after</strong> (<em>bool</em>) – Whether to concatenate attention layer’s input
and output in encoder.</p></li>
<li><p><strong>decoder_concat_after</strong> (<em>bool</em>) – Whether to concatenate attention layer’s input
and output in decoder.</p></li>
<li><p><strong>reduction_factor</strong> (<em>int</em>) – Reduction factor.</p></li>
<li><p><strong>encoder_type</strong> (<em>str</em>) – Encoder type (“transformer” or “conformer”).</p></li>
<li><p><strong>decoder_type</strong> (<em>str</em>) – Decoder type (“transformer” or “conformer”).</p></li>
<li><p><strong>transformer_enc_dropout_rate</strong> (<em>float</em>) – Dropout rate in encoder except
attention and positional encoding.</p></li>
<li><p><strong>transformer_enc_positional_dropout_rate</strong> (<em>float</em>) – Dropout rate after encoder
positional encoding.</p></li>
<li><p><strong>transformer_enc_attn_dropout_rate</strong> (<em>float</em>) – Dropout rate in encoder
self-attention module.</p></li>
<li><p><strong>transformer_dec_dropout_rate</strong> (<em>float</em>) – Dropout rate in decoder except
attention &amp; positional encoding.</p></li>
<li><p><strong>transformer_dec_positional_dropout_rate</strong> (<em>float</em>) – Dropout rate after decoder
positional encoding.</p></li>
<li><p><strong>transformer_dec_attn_dropout_rate</strong> (<em>float</em>) – Dropout rate in decoder
self-attention module.</p></li>
<li><p><strong>conformer_rel_pos_type</strong> (<em>str</em>) – Relative pos encoding type in conformer.</p></li>
<li><p><strong>conformer_pos_enc_layer_type</strong> (<em>str</em>) – Pos encoding layer type in conformer.</p></li>
<li><p><strong>conformer_self_attn_layer_type</strong> (<em>str</em>) – Self-attention layer type in conformer</p></li>
<li><p><strong>conformer_activation_type</strong> (<em>str</em>) – Activation function type in conformer.</p></li>
<li><p><strong>use_macaron_style_in_conformer</strong> – Whether to use macaron style FFN.</p></li>
<li><p><strong>use_cnn_in_conformer</strong> – Whether to use CNN in conformer.</p></li>
<li><p><strong>zero_triu</strong> – Whether to use zero triu in relative self-attention module.</p></li>
<li><p><strong>conformer_enc_kernel_size</strong> – Kernel size of encoder conformer.</p></li>
<li><p><strong>conformer_dec_kernel_size</strong> – Kernel size of decoder conformer.</p></li>
<li><p><strong>duration_predictor_layers</strong> (<em>int</em>) – Number of duration predictor layers.</p></li>
<li><p><strong>duration_predictor_chans</strong> (<em>int</em>) – Number of duration predictor channels.</p></li>
<li><p><strong>duration_predictor_kernel_size</strong> (<em>int</em>) – Kernel size of duration predictor.</p></li>
<li><p><strong>duration_predictor_dropout_rate</strong> (<em>float</em>) – Dropout rate in duration predictor.</p></li>
<li><p><strong>pitch_predictor_layers</strong> (<em>int</em>) – Number of pitch predictor layers.</p></li>
<li><p><strong>pitch_predictor_chans</strong> (<em>int</em>) – Number of pitch predictor channels.</p></li>
<li><p><strong>pitch_predictor_kernel_size</strong> (<em>int</em>) – Kernel size of pitch predictor.</p></li>
<li><p><strong>pitch_predictor_dropout_rate</strong> (<em>float</em>) – Dropout rate in pitch predictor.</p></li>
<li><p><strong>pitch_embed_kernel_size</strong> (<em>float</em>) – Kernel size of pitch embedding.</p></li>
<li><p><strong>pitch_embed_dropout_rate</strong> (<em>float</em>) – Dropout rate for pitch embedding.</p></li>
<li><p><strong>stop_gradient_from_pitch_predictor</strong> – Whether to stop gradient from pitch
predictor to encoder.</p></li>
<li><p><strong>energy_predictor_layers</strong> (<em>int</em>) – Number of energy predictor layers.</p></li>
<li><p><strong>energy_predictor_chans</strong> (<em>int</em>) – Number of energy predictor channels.</p></li>
<li><p><strong>energy_predictor_kernel_size</strong> (<em>int</em>) – Kernel size of energy predictor.</p></li>
<li><p><strong>energy_predictor_dropout_rate</strong> (<em>float</em>) – Dropout rate in energy predictor.</p></li>
<li><p><strong>energy_embed_kernel_size</strong> (<em>float</em>) – Kernel size of energy embedding.</p></li>
<li><p><strong>energy_embed_dropout_rate</strong> (<em>float</em>) – Dropout rate for energy embedding.</p></li>
<li><p><strong>stop_gradient_from_energy_predictor</strong> – Whether to stop gradient from energy
predictor to encoder.</p></li>
<li><p><strong>spks</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Number of speakers. If set to &gt; 1, assume that the
sids will be provided as the input and use sid embedding layer.</p></li>
<li><p><strong>langs</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Number of languages. If set to &gt; 1, assume that the
lids will be provided as the input and use sid embedding layer.</p></li>
<li><p><strong>spk_embed_dim</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Speaker embedding dimension. If set to &gt; 0,
assume that spembs will be provided as the input.</p></li>
<li><p><strong>spk_embed_integration_type</strong> – How to integrate speaker embedding.</p></li>
<li><p><strong>use_gst</strong> (<em>str</em>) – Whether to use global style token.</p></li>
<li><p><strong>gst_tokens</strong> (<em>int</em>) – The number of GST embeddings.</p></li>
<li><p><strong>gst_heads</strong> (<em>int</em>) – The number of heads in GST multihead attention.</p></li>
<li><p><strong>gst_conv_layers</strong> (<em>int</em>) – The number of conv layers in GST.</p></li>
<li><p><strong>gst_conv_chans_list</strong> – (Sequence[int]):
List of the number of channels of conv layers in GST.</p></li>
<li><p><strong>gst_conv_kernel_size</strong> (<em>int</em>) – Kernel size of conv layers in GST.</p></li>
<li><p><strong>gst_conv_stride</strong> (<em>int</em>) – Stride size of conv layers in GST.</p></li>
<li><p><strong>gst_gru_layers</strong> (<em>int</em>) – The number of GRU layers in GST.</p></li>
<li><p><strong>gst_gru_units</strong> (<em>int</em>) – The number of GRU units in GST.</p></li>
<li><p><strong>init_type</strong> (<em>str</em>) – How to initialize transformer parameters.</p></li>
<li><p><strong>init_enc_alpha</strong> (<em>float</em>) – Initial value of alpha in scaled pos encoding of the
encoder.</p></li>
<li><p><strong>init_dec_alpha</strong> (<em>float</em>) – Initial value of alpha in scaled pos encoding of the
decoder.</p></li>
<li><p><strong>use_masking</strong> (<em>bool</em>) – Whether to apply masking for padded part in loss
calculation.</p></li>
<li><p><strong>use_weighted_masking</strong> (<em>bool</em>) – Whether to apply weighted masking in loss
calculation.</p></li>
<li><p><strong>segment_size</strong> (<em>int</em>) – Segment size for random windowed discriminator</p></li>
<li><p><strong>generator_out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>generator_channels</strong> (<em>int</em>) – Number of hidden representation channels.</p></li>
<li><p><strong>generator_global_channels</strong> (<em>int</em>) – Number of global conditioning channels.</p></li>
<li><p><strong>generator_kernel_size</strong> (<em>int</em>) – Kernel size of initial and final conv layer.</p></li>
<li><p><strong>generator_upsample_scales</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of upsampling scales.</p></li>
<li><p><strong>generator_upsample_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for
upsample layers.</p></li>
<li><p><strong>generator_resblock_kernel_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of kernel sizes for
residual blocks.</p></li>
<li><p><strong>generator_resblock_dilations</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – List of list of dilations
for residual blocks.</p></li>
<li><p><strong>generator_use_additional_convs</strong> (<em>bool</em>) – Whether to use additional conv layers
in residual blocks.</p></li>
<li><p><strong>generator_bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>generator_nonlinear_activation</strong> (<em>str</em>) – Activation function module name.</p></li>
<li><p><strong>generator_nonlinear_activation_params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – Hyperparameters for
activation function.</p></li>
<li><p><strong>generator_use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm.
If set to true, it will be applied to all of the conv layers.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.jets.generator.JETSGenerator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_lengths: torch.Tensor</em>, <em class="sig-param">pitch: torch.Tensor</em>, <em class="sig-param">pitch_lengths: torch.Tensor</em>, <em class="sig-param">energy: torch.Tensor</em>, <em class="sig-param">energy_lengths: torch.Tensor</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/jets/generator.html#JETSGenerator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.generator.JETSGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Text index tensor (B, T_text).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, T_feats, aux_channels).</p></li>
<li><p><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
<li><p><strong>pitch</strong> (<em>Tensor</em>) – Batch of padded token-averaged pitch (B, T_text, 1).</p></li>
<li><p><strong>pitch_lengths</strong> (<em>LongTensor</em>) – Batch of pitch lengths (B, T_text).</p></li>
<li><p><strong>energy</strong> (<em>Tensor</em>) – Batch of padded token-averaged energy (B, T_text, 1).</p></li>
<li><p><strong>energy_lengths</strong> (<em>LongTensor</em>) – Batch of energy lengths (B, T_text).</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker index tensor (B,) or (B, 1).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, spk_embed_dim).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language index tensor (B,) or (B, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Waveform tensor (B, 1, segment_size * upsample_factor).
Tensor: Binarization loss ().
Tensor: Log probability attention matrix (B, T_feats, T_text).
Tensor: Segments start index tensor (B,).
Tensor: predicted duration (B, T_text).
Tensor: ground-truth duration obtained from an alignment module (B, T_text).
Tensor: predicted pitch (B, T_text,1).
Tensor: ground-truth averaged pitch (B, T_text, 1).
Tensor: predicted energy (B, T_text, 1).
Tensor: ground-truth averaged energy (B, T_text, 1).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.jets.generator.JETSGenerator.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">feats: Optional[torch.Tensor] = None</em>, <em class="sig-param">feats_lengths: Optional[torch.Tensor] = None</em>, <em class="sig-param">pitch: Optional[torch.Tensor] = None</em>, <em class="sig-param">energy: Optional[torch.Tensor] = None</em>, <em class="sig-param">sids: Optional[torch.Tensor] = None</em>, <em class="sig-param">spembs: Optional[torch.Tensor] = None</em>, <em class="sig-param">lids: Optional[torch.Tensor] = None</em>, <em class="sig-param">use_teacher_forcing: bool = False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/jets/generator.html#JETSGenerator.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.jets.generator.JETSGenerator.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Run inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>Tensor</em>) – Input text index tensor (B, T_text,).</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) – Text length tensor (B,).</p></li>
<li><p><strong>feats</strong> (<em>Tensor</em>) – Feature tensor (B, T_feats, aux_channels).</p></li>
<li><p><strong>feats_lengths</strong> (<em>Tensor</em>) – Feature length tensor (B,).</p></li>
<li><p><strong>pitch</strong> (<em>Tensor</em>) – Pitch tensor (B, T_feats, 1)</p></li>
<li><p><strong>energy</strong> (<em>Tensor</em>) – Energy tensor (B, T_feats, 1)</p></li>
<li><p><strong>sids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker index tensor (B,) or (B, 1).</p></li>
<li><p><strong>spembs</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Speaker embedding tensor (B, spk_embed_dim).</p></li>
<li><p><strong>lids</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Language index tensor (B,) or (B, 1).</p></li>
<li><p><strong>use_teacher_forcing</strong> (<em>bool</em>) – Whether to use teacher forcing.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Generated waveform tensor (B, T_wav).
Tensor: Duration tensor (B, T_text).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-jets-init">
<span id="id46"></span><h2>espnet2.gan_tts.jets.__init__<a class="headerlink" href="#espnet2-gan-tts-jets-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.jets.__init__"></span></section>
<section id="espnet2-gan-tts-wavenet-wavenet">
<span id="id47"></span><h2>espnet2.gan_tts.wavenet.wavenet<a class="headerlink" href="#espnet2-gan-tts-wavenet-wavenet" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.wavenet.wavenet"></span><p>WaveNet modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.wavenet.wavenet.</code><code class="sig-name descname">WaveNet</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 1</em>, <em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">layers: int = 30</em>, <em class="sig-param">stacks: int = 3</em>, <em class="sig-param">base_dilation: int = 2</em>, <em class="sig-param">residual_channels: int = 64</em>, <em class="sig-param">aux_channels: int = -1</em>, <em class="sig-param">gate_channels: int = 128</em>, <em class="sig-param">skip_channels: int = 64</em>, <em class="sig-param">global_channels: int = -1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">use_weight_norm: bool = True</em>, <em class="sig-param">use_first_conv: bool = False</em>, <em class="sig-param">use_last_conv: bool = False</em>, <em class="sig-param">scale_residual: bool = False</em>, <em class="sig-param">scale_skip_connect: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/wavenet.html#WaveNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>WaveNet with global conditioning.</p>
<p>Initialize WaveNet module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilated convolution.</p></li>
<li><p><strong>layers</strong> (<em>int</em>) – Number of residual block layers.</p></li>
<li><p><strong>stacks</strong> (<em>int</em>) – Number of stacks i.e., dilation cycles.</p></li>
<li><p><strong>base_dilation</strong> (<em>int</em>) – Base dilation factor.</p></li>
<li><p><strong>residual_channels</strong> (<em>int</em>) – Number of channels in residual conv.</p></li>
<li><p><strong>gate_channels</strong> (<em>int</em>) – Number of channels in gated conv.</p></li>
<li><p><strong>skip_channels</strong> (<em>int</em>) – Number of channels in skip conv.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of channels for local conditioning feature.</p></li>
<li><p><strong>global_channels</strong> (<em>int</em>) – Number of channels for global conditioning feature.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate. 0.0 means no dropout applied.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to use bias parameter in conv layer.</p></li>
<li><p><strong>use_weight_norm</strong> (<em>bool</em>) – Whether to use weight norm. If set to true, it will
be applied to all of the conv layers.</p></li>
<li><p><strong>use_first_conv</strong> (<em>bool</em>) – Whether to use the first conv layers.</p></li>
<li><p><strong>use_last_conv</strong> (<em>bool</em>) – Whether to use the last conv layers.</p></li>
<li><p><strong>scale_residual</strong> (<em>bool</em>) – Whether to scale the residual outputs.</p></li>
<li><p><strong>scale_skip_connect</strong> (<em>bool</em>) – Whether to scale the skip connection outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet.apply_weight_norm">
<code class="sig-name descname">apply_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/wavenet.html#WaveNet.apply_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet.apply_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply weight normalization module from all of the layers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">c: Optional[torch.Tensor] = None</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/wavenet.html#WaveNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input noise signal (B, 1, T) if use_first_conv else
(B, residual_channels, T).</p></li>
<li><p><strong>x_mask</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Mask tensor (B, 1, T).</p></li>
<li><p><strong>c</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Local conditioning features (B, aux_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning features (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Output tensor (B, out_channels, T) if use_last_conv else</dt><dd><p>(B, residual_channels, T).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet.receptive_field_size">
<em class="property">property </em><code class="sig-name descname">receptive_field_size</code><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet.receptive_field_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Return receptive field size.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.gan_tts.wavenet.wavenet.WaveNet.remove_weight_norm">
<code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/wavenet.html#WaveNet.remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.wavenet.WaveNet.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove weight normalization module from all of the layers.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-gan-tts-wavenet-init">
<span id="id48"></span><h2>espnet2.gan_tts.wavenet.__init__<a class="headerlink" href="#espnet2-gan-tts-wavenet-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.wavenet.__init__"></span></section>
<section id="espnet2-gan-tts-wavenet-residual-block">
<span id="id49"></span><h2>espnet2.gan_tts.wavenet.residual_block<a class="headerlink" href="#espnet2-gan-tts-wavenet-residual-block" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.gan_tts.wavenet.residual_block"></span><p>Residual block modules.</p>
<p>This code is modified from <a class="reference external" href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a>.</p>
<dl class="class">
<dt id="espnet2.gan_tts.wavenet.residual_block.Conv1d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.wavenet.residual_block.</code><code class="sig-name descname">Conv1d</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#Conv1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.Conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.conv.Conv1d</span></code></p>
<p>Conv1d module with customized initialization.</p>
<p>Initialize Conv1d module.</p>
<dl class="method">
<dt id="espnet2.gan_tts.wavenet.residual_block.Conv1d.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#Conv1d.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.Conv1d.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.wavenet.residual_block.Conv1d1x1">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.wavenet.residual_block.</code><code class="sig-name descname">Conv1d1x1</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int</em>, <em class="sig-param">out_channels: int</em>, <em class="sig-param">bias: bool</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#Conv1d1x1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.Conv1d1x1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.gan_tts.wavenet.residual_block.Conv1d" title="espnet2.gan_tts.wavenet.residual_block.Conv1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.gan_tts.wavenet.residual_block.Conv1d</span></code></a></p>
<p>1x1 Conv1d with customized initialization.</p>
<p>Initialize 1x1 Conv1d module.</p>
</dd></dl>

<dl class="class">
<dt id="espnet2.gan_tts.wavenet.residual_block.ResidualBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.gan_tts.wavenet.residual_block.</code><code class="sig-name descname">ResidualBlock</code><span class="sig-paren">(</span><em class="sig-param">kernel_size: int = 3</em>, <em class="sig-param">residual_channels: int = 64</em>, <em class="sig-param">gate_channels: int = 128</em>, <em class="sig-param">skip_channels: int = 64</em>, <em class="sig-param">aux_channels: int = 80</em>, <em class="sig-param">global_channels: int = -1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">dilation: int = 1</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">scale_residual: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#ResidualBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.ResidualBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Residual block module in WaveNet.</p>
<p>Initialize ResidualBlock module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of dilation convolution layer.</p></li>
<li><p><strong>residual_channels</strong> (<em>int</em>) – Number of channels for residual connection.</p></li>
<li><p><strong>skip_channels</strong> (<em>int</em>) – Number of channels for skip connection.</p></li>
<li><p><strong>aux_channels</strong> (<em>int</em>) – Number of local conditioning channels.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout probability.</p></li>
<li><p><strong>dilation</strong> (<em>int</em>) – Dilation factor.</p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – Whether to add bias parameter in convolution layers.</p></li>
<li><p><strong>scale_residual</strong> (<em>bool</em>) – Whether to scale the residual outputs.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.gan_tts.wavenet.residual_block.ResidualBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">c: Optional[torch.Tensor] = None</em>, <em class="sig-param">g: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/gan_tts/wavenet/residual_block.html#ResidualBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.gan_tts.wavenet.residual_block.ResidualBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input tensor (B, residual_channels, T).</p></li>
<li><p><strong>Optional</strong><strong>[</strong><strong>torch.Tensor</strong><strong>]</strong> (<em>x_mask</em>) – Mask tensor (B, 1, T).</p></li>
<li><p><strong>c</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Local conditioning tensor (B, aux_channels, T).</p></li>
<li><p><strong>g</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – Global conditioning tensor (B, global_channels, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor for residual connection (B, residual_channels, T).
Tensor: Output tensor for skip connection (B, skip_channels, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="espnet2.torch_utils.html" class="btn btn-neutral float-left" title="espnet2.torch_utils package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="espnet2.asr.html" class="btn btn-neutral float-right" title="espnet2.asr package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>