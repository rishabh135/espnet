<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>espnet.nets package &mdash; ESPnet 202205 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="espnet.mt package" href="espnet.mt.html" />
    <link rel="prev" title="espnet.bin package" href="espnet.bin.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> ESPnet
          </a>
              <div class="version">
                202205
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelization.html">Using Job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">espnet.nets package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-transducer-decoder-interface">espnet.nets.transducer_decoder_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-beam-search-transducer">espnet.nets.beam_search_transducer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-ctc-prefix-score">espnet.nets.ctc_prefix_score</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-st-interface">espnet.nets.st_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-mt-interface">espnet.nets.mt_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-e2e-asr-common">espnet.nets.e2e_asr_common</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-lm-interface">espnet.nets.lm_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-init">espnet.nets.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-scorer-interface">espnet.nets.scorer_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-batch-beam-search-online">espnet.nets.batch_beam_search_online</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-tts-interface">espnet.nets.tts_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-beam-search">espnet.nets.beam_search</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-batch-beam-search-online-sim">espnet.nets.batch_beam_search_online_sim</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-asr-interface">espnet.nets.asr_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-e2e-mt-common">espnet.nets.e2e_mt_common</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-batch-beam-search">espnet.nets.batch_beam_search</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-ctc">espnet.nets.chainer_backend.ctc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-deterministic-embed-id">espnet.nets.chainer_backend.deterministic_embed_id</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-init">espnet.nets.chainer_backend.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-e2e-asr">espnet.nets.chainer_backend.e2e_asr</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-asr-interface">espnet.nets.chainer_backend.asr_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-e2e-asr-transformer">espnet.nets.chainer_backend.e2e_asr_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-nets-utils">espnet.nets.chainer_backend.nets_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-attention">espnet.nets.chainer_backend.transformer.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-embedding">espnet.nets.chainer_backend.transformer.embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-mask">espnet.nets.chainer_backend.transformer.mask</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-decoder">espnet.nets.chainer_backend.transformer.decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-encoder">espnet.nets.chainer_backend.transformer.encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-subsampling">espnet.nets.chainer_backend.transformer.subsampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-layer-norm">espnet.nets.chainer_backend.transformer.layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-ctc">espnet.nets.chainer_backend.transformer.ctc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-encoder-layer">espnet.nets.chainer_backend.transformer.encoder_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-init">espnet.nets.chainer_backend.transformer.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-label-smoothing-loss">espnet.nets.chainer_backend.transformer.label_smoothing_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-positionwise-feed-forward">espnet.nets.chainer_backend.transformer.positionwise_feed_forward</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-training">espnet.nets.chainer_backend.transformer.training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-transformer-decoder-layer">espnet.nets.chainer_backend.transformer.decoder_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-rnn-init">espnet.nets.chainer_backend.rnn.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-rnn-attentions">espnet.nets.chainer_backend.rnn.attentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-rnn-decoders">espnet.nets.chainer_backend.rnn.decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-rnn-encoders">espnet.nets.chainer_backend.rnn.encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-rnn-training">espnet.nets.chainer_backend.rnn.training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-scorers-length-bonus">espnet.nets.scorers.length_bonus</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-scorers-ngram">espnet.nets.scorers.ngram</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-scorers-ctc">espnet.nets.scorers.ctc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-scorers-init">espnet.nets.scorers.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-initialization">espnet.nets.pytorch_backend.initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr-conformer">espnet.nets.pytorch_backend.e2e_asr_conformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-mt-transformer">espnet.nets.pytorch_backend.e2e_mt_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr-mix-transformer">espnet.nets.pytorch_backend.e2e_asr_mix_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-st">espnet.nets.pytorch_backend.e2e_st</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-mt">espnet.nets.pytorch_backend.e2e_mt</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-ctc">espnet.nets.pytorch_backend.ctc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-tts-tacotron2">espnet.nets.pytorch_backend.e2e_tts_tacotron2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-wavenet">espnet.nets.pytorch_backend.wavenet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr-transducer">espnet.nets.pytorch_backend.e2e_asr_transducer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-tts-transformer">espnet.nets.pytorch_backend.e2e_tts_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-gtn-ctc">espnet.nets.pytorch_backend.gtn_ctc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-tts-fastspeech">espnet.nets.pytorch_backend.e2e_tts_fastspeech</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-init">espnet.nets.pytorch_backend.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-st-conformer">espnet.nets.pytorch_backend.e2e_st_conformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr">espnet.nets.pytorch_backend.e2e_asr</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr-mulenc">espnet.nets.pytorch_backend.e2e_asr_mulenc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-st-transformer">espnet.nets.pytorch_backend.e2e_st_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-vc-transformer">espnet.nets.pytorch_backend.e2e_vc_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr-mix">espnet.nets.pytorch_backend.e2e_asr_mix</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr-transformer">espnet.nets.pytorch_backend.e2e_asr_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-nets-utils">espnet.nets.pytorch_backend.nets_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-vc-tacotron2">espnet.nets.pytorch_backend.e2e_vc_tacotron2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr-maskctc">espnet.nets.pytorch_backend.e2e_asr_maskctc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-conformer-encoder">espnet.nets.pytorch_backend.conformer.encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-conformer-contextual-block-encoder-layer">espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-conformer-encoder-layer">espnet.nets.pytorch_backend.conformer.encoder_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-conformer-init">espnet.nets.pytorch_backend.conformer.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-conformer-convolution">espnet.nets.pytorch_backend.conformer.convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-conformer-argument">espnet.nets.pytorch_backend.conformer.argument</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-conformer-swish">espnet.nets.pytorch_backend.conformer.swish</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-lm-transformer">espnet.nets.pytorch_backend.lm.transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-lm-init">espnet.nets.pytorch_backend.lm.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-lm-seq-rnn">espnet.nets.pytorch_backend.lm.seq_rnn</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-lm-default">espnet.nets.pytorch_backend.lm.default</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-maskctc-mask">espnet.nets.pytorch_backend.maskctc.mask</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-maskctc-init">espnet.nets.pytorch_backend.maskctc.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-maskctc-add-mask-token">espnet.nets.pytorch_backend.maskctc.add_mask_token</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-attention">espnet.nets.pytorch_backend.transformer.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-embedding">espnet.nets.pytorch_backend.transformer.embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-mask">espnet.nets.pytorch_backend.transformer.mask</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-plot">espnet.nets.pytorch_backend.transformer.plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-optimizer">espnet.nets.pytorch_backend.transformer.optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-decoder">espnet.nets.pytorch_backend.transformer.decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-multi-layer-conv">espnet.nets.pytorch_backend.transformer.multi_layer_conv</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-encoder">espnet.nets.pytorch_backend.transformer.encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-contextual-block-encoder-layer">espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-lightconv2d">espnet.nets.pytorch_backend.transformer.lightconv2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-subsampling">espnet.nets.pytorch_backend.transformer.subsampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-layer-norm">espnet.nets.pytorch_backend.transformer.layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-dynamic-conv">espnet.nets.pytorch_backend.transformer.dynamic_conv</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-encoder-layer">espnet.nets.pytorch_backend.transformer.encoder_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-repeat">espnet.nets.pytorch_backend.transformer.repeat</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-init">espnet.nets.pytorch_backend.transformer.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-label-smoothing-loss">espnet.nets.pytorch_backend.transformer.label_smoothing_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-dynamic-conv2d">espnet.nets.pytorch_backend.transformer.dynamic_conv2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-subsampling-without-posenc">espnet.nets.pytorch_backend.transformer.subsampling_without_posenc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-encoder-mix">espnet.nets.pytorch_backend.transformer.encoder_mix</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-argument">espnet.nets.pytorch_backend.transformer.argument</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-lightconv">espnet.nets.pytorch_backend.transformer.lightconv</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-positionwise-feed-forward">espnet.nets.pytorch_backend.transformer.positionwise_feed_forward</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-initializer">espnet.nets.pytorch_backend.transformer.initializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-add-sos-eos">espnet.nets.pytorch_backend.transformer.add_sos_eos</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-longformer-attention">espnet.nets.pytorch_backend.transformer.longformer_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer-decoder-layer">espnet.nets.pytorch_backend.transformer.decoder_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-rnn-init">espnet.nets.pytorch_backend.rnn.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-rnn-attentions">espnet.nets.pytorch_backend.rnn.attentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-rnn-argument">espnet.nets.pytorch_backend.rnn.argument</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-rnn-decoders">espnet.nets.pytorch_backend.rnn.decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-rnn-encoders">espnet.nets.pytorch_backend.rnn.encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-streaming-segment">espnet.nets.pytorch_backend.streaming.segment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-streaming-window">espnet.nets.pytorch_backend.streaming.window</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-streaming-init">espnet.nets.pytorch_backend.streaming.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-frontends-dnn-beamformer">espnet.nets.pytorch_backend.frontends.dnn_beamformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-frontends-dnn-wpe">espnet.nets.pytorch_backend.frontends.dnn_wpe</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-frontends-feature-transform">espnet.nets.pytorch_backend.frontends.feature_transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-frontends-init">espnet.nets.pytorch_backend.frontends.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-frontends-beamformer">espnet.nets.pytorch_backend.frontends.beamformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-frontends-frontend">espnet.nets.pytorch_backend.frontends.frontend</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-frontends-mask-estimator">espnet.nets.pytorch_backend.frontends.mask_estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-tacotron2-decoder">espnet.nets.pytorch_backend.tacotron2.decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-tacotron2-encoder">espnet.nets.pytorch_backend.tacotron2.encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-tacotron2-cbhg">espnet.nets.pytorch_backend.tacotron2.cbhg</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-tacotron2-init">espnet.nets.pytorch_backend.tacotron2.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-fastspeech-duration-predictor">espnet.nets.pytorch_backend.fastspeech.duration_predictor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-fastspeech-duration-calculator">espnet.nets.pytorch_backend.fastspeech.duration_calculator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-fastspeech-length-regulator">espnet.nets.pytorch_backend.fastspeech.length_regulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-fastspeech-init">espnet.nets.pytorch_backend.fastspeech.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-joint-network">espnet.nets.pytorch_backend.transducer.joint_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-transformer-decoder-layer">espnet.nets.pytorch_backend.transducer.transformer_decoder_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-custom-encoder">espnet.nets.pytorch_backend.transducer.custom_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-error-calculator">espnet.nets.pytorch_backend.transducer.error_calculator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-init">espnet.nets.pytorch_backend.transducer.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-transducer-tasks">espnet.nets.pytorch_backend.transducer.transducer_tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-rnn-decoder">espnet.nets.pytorch_backend.transducer.rnn_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-arguments">espnet.nets.pytorch_backend.transducer.arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-initializer">espnet.nets.pytorch_backend.transducer.initializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-utils">espnet.nets.pytorch_backend.transducer.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-custom-decoder">espnet.nets.pytorch_backend.transducer.custom_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-conv1d-nets">espnet.nets.pytorch_backend.transducer.conv1d_nets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-blocks">espnet.nets.pytorch_backend.transducer.blocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-rnn-encoder">espnet.nets.pytorch_backend.transducer.rnn_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transducer-vgg2l">espnet.nets.pytorch_backend.transducer.vgg2l</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.gan_tts.html">espnet2.gan_tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.diar.html">espnet2.diar package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>espnet.nets package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_gen/espnet.nets.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="espnet-nets-package">
<h1>espnet.nets package<a class="headerlink" href="#espnet-nets-package" title="Permalink to this headline">¶</a></h1>
<p>Initialize sub package.</p>
<section id="espnet-nets-transducer-decoder-interface">
<span id="id1"></span><h2>espnet.nets.transducer_decoder_interface<a class="headerlink" href="#espnet-nets-transducer-decoder-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.transducer_decoder_interface"></span><p>Transducer decoder interface module.</p>
<dl class="class">
<dt id="espnet.nets.transducer_decoder_interface.ExtendedHypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.transducer_decoder_interface.</code><code class="sig-name descname">ExtendedHypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]], torch.Tensor], lm_state: Union[Dict[str, Any], List[Any]] = None, dec_out: List[torch.Tensor] = None, lm_scores: torch.Tensor = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/transducer_decoder_interface.html#ExtendedHypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.ExtendedHypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.transducer_decoder_interface.Hypothesis</span></code></a></p>
<p>Extended hypothesis definition for NSC beam search and mAES.</p>
<dl class="attribute">
<dt id="espnet.nets.transducer_decoder_interface.ExtendedHypothesis.dec_out">
<code class="sig-name descname">dec_out</code><em class="property"> = None</em><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.ExtendedHypothesis.dec_out" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet.nets.transducer_decoder_interface.ExtendedHypothesis.lm_scores">
<code class="sig-name descname">lm_scores</code><em class="property"> = None</em><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.ExtendedHypothesis.lm_scores" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.transducer_decoder_interface.Hypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.transducer_decoder_interface.</code><code class="sig-name descname">Hypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]], torch.Tensor], lm_state: Union[Dict[str, Any], List[Any]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/transducer_decoder_interface.html#Hypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Default hypothesis definition for Transducer search algorithms.</p>
<dl class="attribute">
<dt id="espnet.nets.transducer_decoder_interface.Hypothesis.lm_state">
<code class="sig-name descname">lm_state</code><em class="property"> = None</em><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.Hypothesis.lm_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.transducer_decoder_interface.TransducerDecoderInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.transducer_decoder_interface.</code><code class="sig-name descname">TransducerDecoderInterface</code><a class="reference internal" href="../_modules/espnet/nets/transducer_decoder_interface.html#TransducerDecoderInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.TransducerDecoderInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Decoder interface for Transducer models.</p>
<dl class="method">
<dt id="espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: Union[List[espnet.nets.transducer_decoder_interface.Hypothesis], List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]], dec_states: Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]]], cache: Dict[str, Any], use_lm: bool</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]]], torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/transducer_decoder_interface.html#TransducerDecoderInterface.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses.</p></li>
<li><p><strong>dec_states</strong> – Decoder hidden states.</p></li>
<li><p><strong>cache</strong> – Pairs of (dec_out, dec_states) for each label sequence. (key)</p></li>
<li><p><strong>use_lm</strong> – Whether to compute label ID sequences for LM.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences.
dec_states: Decoder hidden states.
lm_labels: Label ID sequences for LM.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.create_batch_states">
<code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">states: Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]]], new_states: List[Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]]]], l_tokens: List[List[int]]</em><span class="sig-paren">)</span> &#x2192; Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet/nets/transducer_decoder_interface.html#TransducerDecoderInterface.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_states</strong> – Batch of decoder states</p></li>
<li><p><strong>l_states</strong> – List of decoder states</p></li>
<li><p><strong>l_tokens</strong> – List of token sequences for input batch</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of decoder states</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>batch_states</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int</em><span class="sig-paren">)</span> &#x2192; Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet/nets/transducer_decoder_interface.html#TransducerDecoderInterface.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Initial decoder hidden states.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>state</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">hyp: espnet.nets.transducer_decoder_interface.Hypothesis, cache: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]]], torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/transducer_decoder_interface.html#TransducerDecoderInterface.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyp</strong> – Hypothesis.</p></li>
<li><p><strong>cache</strong> – Pairs of (dec_out, dec_state) for each token sequence. (key)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequence.
new_state: Decoder hidden states.
lm_tokens: Label ID for LM.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">batch_states: Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[torch.Tensor]], idx: int</em><span class="sig-paren">)</span> &#x2192; Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet/nets/transducer_decoder_interface.html#TransducerDecoderInterface.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.transducer_decoder_interface.TransducerDecoderInterface.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_states</strong> – Decoder hidden states.</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder hidden state for given ID.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>state_idx</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-beam-search-transducer">
<span id="id2"></span><h2>espnet.nets.beam_search_transducer<a class="headerlink" href="#espnet-nets-beam-search-transducer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.beam_search_transducer"></span><p>Search algorithms for Transducer models.</p>
<dl class="class">
<dt id="espnet.nets.beam_search_transducer.BeamSearchTransducer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.beam_search_transducer.</code><code class="sig-name descname">BeamSearchTransducer</code><span class="sig-paren">(</span><em class="sig-param">decoder: Union[espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder, espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder], joint_network: espnet.nets.pytorch_backend.transducer.joint_network.JointNetwork, beam_size: int, lm: torch.nn.modules.module.Module = None, lm_weight: float = 0.1, search_type: str = 'default', max_sym_exp: int = 2, u_max: int = 50, nstep: int = 1, prefix_alpha: int = 1, expansion_gamma: int = 2.3, expansion_beta: int = 2, score_norm: bool = True, softmax_temperature: float = 1.0, nbest: int = 1, quantization: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/beam_search_transducer.html#BeamSearchTransducer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search_transducer.BeamSearchTransducer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Beam search implementation for Transducer.</p>
<p>Initialize Transducer search module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint network module.</p></li>
<li><p><strong>beam_size</strong> – Beam size.</p></li>
<li><p><strong>lm</strong> – LM class.</p></li>
<li><p><strong>lm_weight</strong> – LM weight for soft fusion.</p></li>
<li><p><strong>search_type</strong> – Search algorithm to use during inference.</p></li>
<li><p><strong>max_sym_exp</strong> – Number of maximum symbol expansions at each time step. (TSD)</p></li>
<li><p><strong>u_max</strong> – Maximum output sequence length. (ALSD)</p></li>
<li><p><strong>nstep</strong> – Number of maximum expansion steps at each time step. (NSC/mAES)</p></li>
<li><p><strong>prefix_alpha</strong> – Maximum prefix length in prefix search. (NSC/mAES)</p></li>
<li><p><strong>expansion_beta</strong> – Number of additional candidates for expanded hypotheses selection. (mAES)</p></li>
<li><p><strong>expansion_gamma</strong> – Allowed logp difference for prune-by-value method. (mAES)</p></li>
<li><p><strong>score_norm</strong> – Normalize final scores by length. (“default”)</p></li>
<li><p><strong>softmax_temperature</strong> – Penalization term for softmax function.</p></li>
<li><p><strong>nbest</strong> – Number of final hypothesis.</p></li>
<li><p><strong>quantization</strong> – Whether dynamic quantization is used.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.beam_search_transducer.BeamSearchTransducer.align_length_sync_decoding">
<code class="sig-name descname">align_length_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search_transducer.html#BeamSearchTransducer.align_length_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search_transducer.BeamSearchTransducer.align_length_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Alignment-length synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>h</strong> – Encoder output sequences. (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search_transducer.BeamSearchTransducer.default_beam_search">
<code class="sig-name descname">default_beam_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search_transducer.html#BeamSearchTransducer.default_beam_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search_transducer.BeamSearchTransducer.default_beam_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Beam search implementation.</p>
<p>Modified from <a class="reference external" href="https://arxiv.org/pdf/1211.3711.pdf">https://arxiv.org/pdf/1211.3711.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search_transducer.BeamSearchTransducer.greedy_search">
<code class="sig-name descname">greedy_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search_transducer.html#BeamSearchTransducer.greedy_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search_transducer.BeamSearchTransducer.greedy_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Greedy search implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>1-best hypotheses.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>hyp</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search_transducer.BeamSearchTransducer.modified_adaptive_expansion_search">
<code class="sig-name descname">modified_adaptive_expansion_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search_transducer.html#BeamSearchTransducer.modified_adaptive_expansion_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search_transducer.BeamSearchTransducer.modified_adaptive_expansion_search" title="Permalink to this definition">¶</a></dt>
<dd><p>It’s the modified Adaptive Expansion Search (mAES) implementation.</p>
<p>Based on/modified from <a class="reference external" href="https://ieeexplore.ieee.org/document/9250505">https://ieeexplore.ieee.org/document/9250505</a> and NSC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search_transducer.BeamSearchTransducer.nsc_beam_search">
<code class="sig-name descname">nsc_beam_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search_transducer.html#BeamSearchTransducer.nsc_beam_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search_transducer.BeamSearchTransducer.nsc_beam_search" title="Permalink to this definition">¶</a></dt>
<dd><p>N-step constrained beam search implementation.</p>
<p>Based on/Modified from <a class="reference external" href="https://arxiv.org/pdf/2002.03577.pdf">https://arxiv.org/pdf/2002.03577.pdf</a>.
Please reference ESPnet (b-flo, PR #2444) for any usage outside ESPnet
until further modifications.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search_transducer.BeamSearchTransducer.prefix_search">
<code class="sig-name descname">prefix_search</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis], enc_out_t: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search_transducer.html#BeamSearchTransducer.prefix_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search_transducer.BeamSearchTransducer.prefix_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Prefix search for NSC and mAES strategies.</p>
<p>Based on <a class="reference external" href="https://arxiv.org/pdf/1211.3711.pdf">https://arxiv.org/pdf/1211.3711.pdf</a></p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search_transducer.BeamSearchTransducer.sort_nbest">
<code class="sig-name descname">sort_nbest</code><span class="sig-paren">(</span><em class="sig-param">hyps: Union[List[espnet.nets.transducer_decoder_interface.Hypothesis], List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]]</em><span class="sig-paren">)</span> &#x2192; Union[List[espnet.nets.transducer_decoder_interface.Hypothesis], List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]]<a class="reference internal" href="../_modules/espnet/nets/beam_search_transducer.html#BeamSearchTransducer.sort_nbest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search_transducer.BeamSearchTransducer.sort_nbest" title="Permalink to this definition">¶</a></dt>
<dd><p>Sort hypotheses by score or score given sequence length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypothesis.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Sorted hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search_transducer.BeamSearchTransducer.time_sync_decoding">
<code class="sig-name descname">time_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search_transducer.html#BeamSearchTransducer.time_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search_transducer.BeamSearchTransducer.time_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Time synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-ctc-prefix-score">
<span id="id3"></span><h2>espnet.nets.ctc_prefix_score<a class="headerlink" href="#espnet-nets-ctc-prefix-score" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.ctc_prefix_score"></span><dl class="class">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScore">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.ctc_prefix_score.</code><code class="sig-name descname">CTCPrefixScore</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">blank</em>, <em class="sig-param">eos</em>, <em class="sig-param">xp</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/ctc_prefix_score.html#CTCPrefixScore"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Compute CTC label sequence scores</p>
<p>which is based on Algorithm 2 in WATANABE et al.
“HYBRID CTC/ATTENTION ARCHITECTURE FOR END-TO-END SPEECH RECOGNITION,”
but extended to efficiently compute the probablities of multiple labels
simultaneously</p>
<dl class="method">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScore.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/ctc_prefix_score.html#CTCPrefixScore.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScore.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain an initial CTC state</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>CTC state</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScoreTH">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.ctc_prefix_score.</code><code class="sig-name descname">CTCPrefixScoreTH</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">xlens</em>, <em class="sig-param">blank</em>, <em class="sig-param">eos</em>, <em class="sig-param">margin=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/ctc_prefix_score.html#CTCPrefixScoreTH"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScoreTH" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Batch processing of CTCPrefixScore</p>
<p>which is based on Algorithm 2 in WATANABE et al.
“HYBRID CTC/ATTENTION ARCHITECTURE FOR END-TO-END SPEECH RECOGNITION,”
but extended to efficiently compute the label probablities for multiple
hypotheses simultaneously
See also Seki et al. “Vectorized Beam Search for CTC-Attention-Based
Speech Recognition,” In INTERSPEECH (pp. 3825-3829), 2019.</p>
<p>Construct CTC prefix scorer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – input label posterior sequences (B, T, O)</p></li>
<li><p><strong>xlens</strong> (<em>torch.Tensor</em>) – input lengths (B,)</p></li>
<li><p><strong>blank</strong> (<em>int</em>) – blank label id</p></li>
<li><p><strong>eos</strong> (<em>int</em>) – end-of-sequence id</p></li>
<li><p><strong>margin</strong> (<em>int</em>) – margin parameter for windowing (0 means no windowing)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.extend_prob">
<code class="sig-name descname">extend_prob</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/ctc_prefix_score.html#CTCPrefixScoreTH.extend_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.extend_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Extend CTC prob.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – input label posterior sequences (B, T, O)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.extend_state">
<code class="sig-name descname">extend_state</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/ctc_prefix_score.html#CTCPrefixScoreTH.extend_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.extend_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute CTC prefix state.</p>
<p>:param state    : CTC state
:return ctc_state</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.index_select_state">
<code class="sig-name descname">index_select_state</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">best_ids</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/ctc_prefix_score.html#CTCPrefixScoreTH.index_select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.index_select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Select CTC states according to best ids</p>
<p>:param state    : CTC state
:param best_ids : index numbers selected by beam pruning (B, W)
:return selected_state</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-st-interface">
<span id="id4"></span><h2>espnet.nets.st_interface<a class="headerlink" href="#espnet-nets-st-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.st_interface"></span><p>ST Interface module.</p>
<dl class="class">
<dt id="espnet.nets.st_interface.STInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.st_interface.</code><code class="sig-name descname">STInterface</code><a class="reference internal" href="../_modules/espnet/nets/st_interface.html#STInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.st_interface.STInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a></p>
<p>ST Interface for ESPnet model implementation.</p>
<p>NOTE: This class is inherited from ASRInterface to enable joint translation
and recognition when performing multi-task learning with the ASR task.</p>
<dl class="method">
<dt id="espnet.nets.st_interface.STInterface.translate">
<code class="sig-name descname">translate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em>, <em class="sig-param">ensemble_models=[]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/st_interface.html#STInterface.translate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.st_interface.STInterface.translate" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize x for evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – input acouctic feature (B, T, D) or (T, D)</p></li>
<li><p><strong>trans_args</strong> (<em>namespace</em>) – argment namespace contraining options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.st_interface.STInterface.translate_batch">
<code class="sig-name descname">translate_batch</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/st_interface.html#STInterface.translate_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.st_interface.STInterface.translate_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Beam search implementation for batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – encoder hidden state sequences (B, Tmax, Henc)</p></li>
<li><p><strong>trans_args</strong> (<em>namespace</em>) – argument namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.st_interface.dynamic_import_st">
<code class="sig-prename descclassname">espnet.nets.st_interface.</code><code class="sig-name descname">dynamic_import_st</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">backend</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/st_interface.html#dynamic_import_st"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.st_interface.dynamic_import_st" title="Permalink to this definition">¶</a></dt>
<dd><p>Import ST models dynamically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>str</em>) – module_name:class_name or alias in <cite>predefined_st</cite></p></li>
<li><p><strong>backend</strong> (<em>str</em>) – NN backend. e.g., pytorch, chainer</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ST class</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>type</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-mt-interface">
<span id="id5"></span><h2>espnet.nets.mt_interface<a class="headerlink" href="#espnet-nets-mt-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.mt_interface"></span><p>MT Interface module.</p>
<dl class="class">
<dt id="espnet.nets.mt_interface.MTInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.mt_interface.</code><code class="sig-name descname">MTInterface</code><a class="reference internal" href="../_modules/espnet/nets/mt_interface.html#MTInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.mt_interface.MTInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>MT Interface for ESPnet model implementation.</p>
<dl class="method">
<dt id="espnet.nets.mt_interface.MTInterface.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/mt_interface.html#MTInterface.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.mt_interface.MTInterface.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments to parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.mt_interface.MTInterface.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.mt_interface.MTInterface.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Get attention plot class.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.mt_interface.MTInterface.build">
<em class="property">classmethod </em><code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">odim: int</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/mt_interface.html#MTInterface.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.mt_interface.MTInterface.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize this class with python-level args.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – The number of an input feature dim.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – The number of output vocab.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new instance of ASRInterface.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ASRinterface</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.mt_interface.MTInterface.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/mt_interface.html#MTInterface.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.mt_interface.MTInterface.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>list</em>) – list of padded input sequences [(T1, idim), (T2, idim), …]</p></li>
<li><p><strong>ilens</strong> (<em>ndarray</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys</strong> (<em>list</em>) – list of character id sequence tensor [(L1), (L2), (L3), …]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weights (B, Lmax, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.mt_interface.MTInterface.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/mt_interface.html#MTInterface.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.mt_interface.MTInterface.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute loss for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> – For pytorch, batch of padded source sequences torch.Tensor (B, Tmax, idim)
For chainer, list of source sequences chainer.Variable</p></li>
<li><p><strong>ilens</strong> – batch of lengths of source sequences (B)
For pytorch, torch.Tensor
For chainer, list of int</p></li>
<li><p><strong>ys</strong> – For pytorch, batch of padded source sequences torch.Tensor (B, Lmax)
For chainer, list of source sequences chainer.Variable</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor for pytorch, chainer.Variable for chainer</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.mt_interface.MTInterface.translate">
<code class="sig-name descname">translate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/mt_interface.html#MTInterface.translate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.mt_interface.MTInterface.translate" title="Permalink to this definition">¶</a></dt>
<dd><p>Translate x for evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – input acouctic feature (B, T, D) or (T, D)</p></li>
<li><p><strong>trans_args</strong> (<em>namespace</em>) – argment namespace contraining options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.mt_interface.MTInterface.translate_batch">
<code class="sig-name descname">translate_batch</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/mt_interface.html#MTInterface.translate_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.mt_interface.MTInterface.translate_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Beam search implementation for batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – encoder hidden state sequences (B, Tmax, Henc)</p></li>
<li><p><strong>trans_args</strong> (<em>namespace</em>) – argument namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-e2e-asr-common">
<span id="id6"></span><h2>espnet.nets.e2e_asr_common<a class="headerlink" href="#espnet-nets-e2e-asr-common" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.e2e_asr_common"></span><p>Common functions for ASR.</p>
<dl class="class">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.e2e_asr_common.</code><code class="sig-name descname">ErrorCalculator</code><span class="sig-paren">(</span><em class="sig-param">char_list</em>, <em class="sig-param">sym_space</em>, <em class="sig-param">sym_blank</em>, <em class="sig-param">report_cer=False</em>, <em class="sig-param">report_wer=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_asr_common.html#ErrorCalculator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Calculate CER and WER for E2E_ASR and CTC models during training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_hats</strong> – numpy array with predicted text</p></li>
<li><p><strong>y_pads</strong> – numpy array with true (target) text</p></li>
<li><p><strong>char_list</strong> – </p></li>
<li><p><strong>sym_space</strong> – </p></li>
<li><p><strong>sym_blank</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
<p>Construct an ErrorCalculator object.</p>
<dl class="method">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator.calculate_cer">
<code class="sig-name descname">calculate_cer</code><span class="sig-paren">(</span><em class="sig-param">seqs_hat</em>, <em class="sig-param">seqs_true</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_asr_common.html#ErrorCalculator.calculate_cer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator.calculate_cer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level CER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seqs_hat</strong> (<em>list</em>) – prediction</p></li>
<li><p><strong>seqs_true</strong> (<em>list</em>) – reference</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>average sentence-level CER score</p>
</dd>
</dl>
<p>:rtype float</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator.calculate_cer_ctc">
<code class="sig-name descname">calculate_cer_ctc</code><span class="sig-paren">(</span><em class="sig-param">ys_hat</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_asr_common.html#ErrorCalculator.calculate_cer_ctc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator.calculate_cer_ctc" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level CER score for CTC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys_hat</strong> (<em>torch.Tensor</em>) – prediction (batch, seqlen)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – reference (batch, seqlen)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>average sentence-level CER score</p>
</dd>
</dl>
<p>:rtype float</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator.calculate_wer">
<code class="sig-name descname">calculate_wer</code><span class="sig-paren">(</span><em class="sig-param">seqs_hat</em>, <em class="sig-param">seqs_true</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_asr_common.html#ErrorCalculator.calculate_wer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator.calculate_wer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level WER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seqs_hat</strong> (<em>list</em>) – prediction</p></li>
<li><p><strong>seqs_true</strong> (<em>list</em>) – reference</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>average sentence-level WER score</p>
</dd>
</dl>
<p>:rtype float</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator.convert_to_char">
<code class="sig-name descname">convert_to_char</code><span class="sig-paren">(</span><em class="sig-param">ys_hat</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_asr_common.html#ErrorCalculator.convert_to_char"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator.convert_to_char" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert index to character.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seqs_hat</strong> (<em>torch.Tensor</em>) – prediction (batch, seqlen)</p></li>
<li><p><strong>seqs_true</strong> (<em>torch.Tensor</em>) – reference (batch, seqlen)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>token list of prediction</p>
</dd>
</dl>
<p>:rtype list
:return: token list of reference
:rtype list</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.e2e_asr_common.end_detect">
<code class="sig-prename descclassname">espnet.nets.e2e_asr_common.</code><code class="sig-name descname">end_detect</code><span class="sig-paren">(</span><em class="sig-param">ended_hyps</em>, <em class="sig-param">i</em>, <em class="sig-param">M=3</em>, <em class="sig-param">D_end=-10.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_asr_common.html#end_detect"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_asr_common.end_detect" title="Permalink to this definition">¶</a></dt>
<dd><p>End detection.</p>
<p>described in Eq. (50) of S. Watanabe et al
“Hybrid CTC/Attention Architecture for End-to-End Speech Recognition”</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ended_hyps</strong> – </p></li>
<li><p><strong>i</strong> – </p></li>
<li><p><strong>M</strong> – </p></li>
<li><p><strong>D_end</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.e2e_asr_common.get_vgg2l_odim">
<code class="sig-prename descclassname">espnet.nets.e2e_asr_common.</code><code class="sig-name descname">get_vgg2l_odim</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">in_channel=3</em>, <em class="sig-param">out_channel=128</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_asr_common.html#get_vgg2l_odim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_asr_common.get_vgg2l_odim" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the output size of the VGG frontend.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channel</strong> – input channel size</p></li>
<li><p><strong>out_channel</strong> – output channel size</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output size</p>
</dd>
</dl>
<p>:rtype int</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.e2e_asr_common.label_smoothing_dist">
<code class="sig-prename descclassname">espnet.nets.e2e_asr_common.</code><code class="sig-name descname">label_smoothing_dist</code><span class="sig-paren">(</span><em class="sig-param">odim</em>, <em class="sig-param">lsm_type</em>, <em class="sig-param">transcript=None</em>, <em class="sig-param">blank=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_asr_common.html#label_smoothing_dist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_asr_common.label_smoothing_dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain label distribution for loss smoothing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> – </p></li>
<li><p><strong>lsm_type</strong> – </p></li>
<li><p><strong>blank</strong> – </p></li>
<li><p><strong>transcript</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-lm-interface">
<span id="id7"></span><h2>espnet.nets.lm_interface<a class="headerlink" href="#espnet-nets-lm-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.lm_interface"></span><p>Language model interface.</p>
<dl class="class">
<dt id="espnet.nets.lm_interface.LMInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.lm_interface.</code><code class="sig-name descname">LMInterface</code><a class="reference internal" href="../_modules/espnet/nets/lm_interface.html#LMInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.lm_interface.LMInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.ScorerInterface</span></code></a></p>
<p>LM Interface for ESPnet model implementation.</p>
<dl class="method">
<dt id="espnet.nets.lm_interface.LMInterface.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/lm_interface.html#LMInterface.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.lm_interface.LMInterface.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments to command line argument parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.lm_interface.LMInterface.build">
<em class="property">classmethod </em><code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">n_vocab: int</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/lm_interface.html#LMInterface.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.lm_interface.LMInterface.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize this class with python-level args.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idim</strong> (<em>int</em>) – The number of vocabulary.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new instance of LMInterface.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>LMinterface</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.lm_interface.LMInterface.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">t</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/lm_interface.html#LMInterface.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.lm_interface.LMInterface.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute LM loss value from buffer sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input ids. (batch, len)</p></li>
<li><p><strong>t</strong> (<em>torch.Tensor</em>) – Target ids. (batch, len)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>loss to backward (scalar),
negative log-likelihood of t: -log p(t) (scalar) and
the number of elements in x (scalar)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The last two return values are used
in perplexity: p(t)^{-n} = exp(-log p(t) / n)</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.lm_interface.dynamic_import_lm">
<code class="sig-prename descclassname">espnet.nets.lm_interface.</code><code class="sig-name descname">dynamic_import_lm</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">backend</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/lm_interface.html#dynamic_import_lm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.lm_interface.dynamic_import_lm" title="Permalink to this definition">¶</a></dt>
<dd><p>Import LM class dynamically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>str</em>) – module_name:class_name or alias in <cite>predefined_lms</cite></p></li>
<li><p><strong>backend</strong> (<em>str</em>) – NN backend. e.g., pytorch, chainer</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>LM class</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>type</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-init">
<span id="id8"></span><h2>espnet.nets.__init__<a class="headerlink" href="#espnet-nets-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-scorer-interface">
<span id="id9"></span><h2>espnet.nets.scorer_interface<a class="headerlink" href="#espnet-nets-scorer-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.scorer_interface"></span><p>Scorer interface module.</p>
<dl class="class">
<dt id="espnet.nets.scorer_interface.BatchPartialScorerInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.scorer_interface.</code><code class="sig-name descname">BatchPartialScorerInterface</code><a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#BatchPartialScorerInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.BatchPartialScorerInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a>, <a class="reference internal" href="#espnet.nets.scorer_interface.PartialScorerInterface" title="espnet.nets.scorer_interface.PartialScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.PartialScorerInterface</span></code></a></p>
<p>Batch partial scorer interface for beam search.</p>
<dl class="method">
<dt id="espnet.nets.scorer_interface.BatchPartialScorerInterface.batch_score_partial">
<code class="sig-name descname">batch_score_partial</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, next_tokens: torch.Tensor, states: List[Any], xs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Any]<a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#BatchPartialScorerInterface.batch_score_partial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.BatchPartialScorerInterface.batch_score_partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>next_tokens</strong> (<em>torch.Tensor</em>) – torch.int64 tokens to score (n_batch, n_token).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of a score tensor for ys that has a shape <cite>(n_batch, n_vocab)</cite>
and next states for ys</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.scorer_interface.BatchScorerInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.scorer_interface.</code><code class="sig-name descname">BatchScorerInterface</code><a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#BatchScorerInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.BatchScorerInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.ScorerInterface</span></code></a></p>
<p>Batch scorer interface.</p>
<dl class="method">
<dt id="espnet.nets.scorer_interface.BatchScorerInterface.batch_init_state">
<code class="sig-name descname">batch_init_state</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Any<a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#BatchScorerInterface.batch_init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.BatchScorerInterface.batch_init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an initial state for decoding (optional).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoded feature tensor</p>
</dd>
</dl>
<p>Returns: initial state</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorer_interface.BatchScorerInterface.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#BatchScorerInterface.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.BatchScorerInterface.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.scorer_interface.PartialScorerInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.scorer_interface.</code><code class="sig-name descname">PartialScorerInterface</code><a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#PartialScorerInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.PartialScorerInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.ScorerInterface</span></code></a></p>
<p>Partial scorer interface for beam search.</p>
<p>The partial scorer performs scoring when non-partial scorer finished scoring,
and receives pre-pruned next tokens to score because it is too heavy to score
all the tokens.</p>
<p class="rubric">Examples</p>
<ul class="simple">
<li><dl class="simple">
<dt>Prefix search for connectionist-temporal-classification models</dt><dd><ul>
<li><p><a class="reference internal" href="#espnet.nets.scorers.ctc.CTCPrefixScorer" title="espnet.nets.scorers.ctc.CTCPrefixScorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorers.ctc.CTCPrefixScorer</span></code></a></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<dl class="method">
<dt id="espnet.nets.scorer_interface.PartialScorerInterface.score_partial">
<code class="sig-name descname">score_partial</code><span class="sig-paren">(</span><em class="sig-param">y: torch.Tensor</em>, <em class="sig-param">next_tokens: torch.Tensor</em>, <em class="sig-param">state: Any</em>, <em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Any]<a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#PartialScorerInterface.score_partial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.PartialScorerInterface.score_partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D prefix token</p></li>
<li><p><strong>next_tokens</strong> (<em>torch.Tensor</em>) – torch.int64 next token to score</p></li>
<li><p><strong>state</strong> – decoder state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of a score tensor for y that has a shape <cite>(len(next_tokens),)</cite>
and next state for ys</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.scorer_interface.ScorerInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.scorer_interface.</code><code class="sig-name descname">ScorerInterface</code><a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#ScorerInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.ScorerInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Scorer interface for beam search.</p>
<p>The scorer performs scoring of the all tokens in vocabulary.</p>
<p class="rubric">Examples</p>
<ul class="simple">
<li><dl class="simple">
<dt>Search heuristics</dt><dd><ul>
<li><p><a class="reference internal" href="#espnet.nets.scorers.length_bonus.LengthBonus" title="espnet.nets.scorers.length_bonus.LengthBonus"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorers.length_bonus.LengthBonus</span></code></a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Decoder networks of the sequence-to-sequence models</dt><dd><ul>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.nets.transformer.decoder.Decoder</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.nets.rnn.decoders.Decoder</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Neural language models</dt><dd><ul>
<li><p><a class="reference internal" href="#espnet.nets.pytorch_backend.lm.transformer.TransformerLM" title="espnet.nets.pytorch_backend.lm.transformer.TransformerLM"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.lm.transformer.TransformerLM</span></code></a></p></li>
<li><p><a class="reference internal" href="#espnet.nets.pytorch_backend.lm.default.DefaultRNNLM" title="espnet.nets.pytorch_backend.lm.default.DefaultRNNLM"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.lm.default.DefaultRNNLM</span></code></a></p></li>
<li><p><a class="reference internal" href="#espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM" title="espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM</span></code></a></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<dl class="method">
<dt id="espnet.nets.scorer_interface.ScorerInterface.final_score">
<code class="sig-name descname">final_score</code><span class="sig-paren">(</span><em class="sig-param">state: Any</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#ScorerInterface.final_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.ScorerInterface.final_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score eos (optional).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> – Scorer state for prefix tokens</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>final score</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorer_interface.ScorerInterface.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Any<a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#ScorerInterface.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.ScorerInterface.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an initial state for decoding (optional).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoded feature tensor</p>
</dd>
</dl>
<p>Returns: initial state</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorer_interface.ScorerInterface.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">y: torch.Tensor</em>, <em class="sig-param">state: Any</em>, <em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Any]<a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#ScorerInterface.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.ScorerInterface.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</p></li>
<li><p><strong>state</strong> – Scorer state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>scores for next token that has a shape of <cite>(n_vocab)</cite>
and next state for ys</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorer_interface.ScorerInterface.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">state: Any</em>, <em class="sig-param">i: int</em>, <em class="sig-param">new_id: int = None</em><span class="sig-paren">)</span> &#x2192; Any<a class="reference internal" href="../_modules/espnet/nets/scorer_interface.html#ScorerInterface.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorer_interface.ScorerInterface.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Select state with relative ids in the main beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state</strong> – Decoder state for prefix tokens</p></li>
<li><p><strong>i</strong> (<em>int</em>) – Index to select a state in the main beam search</p></li>
<li><p><strong>new_id</strong> (<em>int</em>) – New label index to select a state if necessary</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>pruned state</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>state</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-batch-beam-search-online">
<span id="id10"></span><h2>espnet.nets.batch_beam_search_online<a class="headerlink" href="#espnet-nets-batch-beam-search-online" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.batch_beam_search_online"></span><p>Parallel beam search module for online simulation.</p>
<dl class="class">
<dt id="espnet.nets.batch_beam_search_online.BatchBeamSearchOnline">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.batch_beam_search_online.</code><code class="sig-name descname">BatchBeamSearchOnline</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">block_size=40</em>, <em class="sig-param">hop_size=16</em>, <em class="sig-param">look_ahead=16</em>, <em class="sig-param">disable_repetition_detection=False</em>, <em class="sig-param">encoded_feat_length_limit=0</em>, <em class="sig-param">decoder_text_length_limit=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online.html#BatchBeamSearchOnline"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online.BatchBeamSearchOnline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.batch_beam_search.BatchBeamSearch" title="espnet.nets.batch_beam_search.BatchBeamSearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.batch_beam_search.BatchBeamSearch</span></code></a></p>
<p>Online beam search implementation.</p>
<p>This simulates streaming decoding.
It requires encoded features of entire utterance and
extracts block by block from it as it shoud be done
in streaming processing.
This is based on Tsunoo et al, “STREAMING TRANSFORMER ASR
WITH BLOCKWISE SYNCHRONOUS BEAM SEARCH”
(<a class="reference external" href="https://arxiv.org/abs/2006.14941">https://arxiv.org/abs/2006.14941</a>).</p>
<p>Initialize beam search.</p>
<dl class="method">
<dt id="espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.assemble_hyps">
<code class="sig-name descname">assemble_hyps</code><span class="sig-paren">(</span><em class="sig-param">ended_hyps</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online.html#BatchBeamSearchOnline.assemble_hyps"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.assemble_hyps" title="Permalink to this definition">¶</a></dt>
<dd><p>Assemble the hypotheses.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.extend">
<code class="sig-name descname">extend</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">hyps: espnet.nets.beam_search.Hypothesis</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online.html#BatchBeamSearchOnline.extend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.extend" title="Permalink to this definition">¶</a></dt>
<dd><p>Extend probabilities and states with more encoded chunks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – The extended encoder output feature</p></li>
<li><p><strong>hyps</strong> (<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a>) – Current list of hypothesis</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The extended hypothesis</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis">Hypothesis</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">maxlenratio: float = 0.0</em>, <em class="sig-param">minlenratio: float = 0.0</em>, <em class="sig-param">is_final: bool = True</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online.html#BatchBeamSearchOnline.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Encoded speech feature (T, D)</p></li>
<li><p><strong>maxlenratio</strong> (<em>float</em>) – Input length ratio to obtain max output length.
If maxlenratio=0.0 (default), it uses a end-detect function
to automatically find maximum hypothesis lengths</p></li>
<li><p><strong>minlenratio</strong> (<em>float</em>) – Input length ratio to obtain min output length.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis">Hypothesis</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.process_one_block">
<code class="sig-name descname">process_one_block</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">is_final</em>, <em class="sig-param">maxlen</em>, <em class="sig-param">maxlenratio</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online.html#BatchBeamSearchOnline.process_one_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.process_one_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize one block.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online.html#BatchBeamSearchOnline.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.score_full">
<code class="sig-name descname">score_full</code><span class="sig-paren">(</span><em class="sig-param">hyp: espnet.nets.batch_beam_search.BatchHypothesis</em>, <em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Dict[str, torch.Tensor], Dict[str, Any]]<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online.html#BatchBeamSearchOnline.score_full"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online.BatchBeamSearchOnline.score_full" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new hypothesis by <cite>self.full_scorers</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyp</strong> (<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a>) – Hypothesis with prefix tokens to score</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Corresponding input feature</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>score dict of <cite>hyp</cite> that has string keys of <cite>self.full_scorers</cite>
and tensor score values of shape: <cite>(self.n_vocab,)</cite>,
and state dict that has string keys
and state values of <cite>self.full_scorers</cite></p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Dict[str, torch.Tensor], Dict[str, Any]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-tts-interface">
<span id="id11"></span><h2>espnet.nets.tts_interface<a class="headerlink" href="#espnet-nets-tts-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.tts_interface"></span><p>TTS Interface realted modules.</p>
<dl class="class">
<dt id="espnet.nets.tts_interface.Reporter">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.tts_interface.</code><code class="sig-name descname">Reporter</code><span class="sig-paren">(</span><em class="sig-param">**links</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/tts_interface.html#Reporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.tts_interface.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Reporter module.</p>
<dl class="method">
<dt id="espnet.nets.tts_interface.Reporter.report">
<code class="sig-name descname">report</code><span class="sig-paren">(</span><em class="sig-param">dicts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/tts_interface.html#Reporter.report"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.tts_interface.Reporter.report" title="Permalink to this definition">¶</a></dt>
<dd><p>Report values from a given dict.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.tts_interface.TTSInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.tts_interface.</code><code class="sig-name descname">TTSInterface</code><a class="reference internal" href="../_modules/espnet/nets/tts_interface.html#TTSInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>TTS Interface for ESPnet model implementation.</p>
<p>Initilize TTS module.</p>
<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/tts_interface.html#TTSInterface.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add model specific argments to parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot attention weights.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.base_plot_keys">
<em class="property">property </em><code class="sig-name descname">base_plot_keys</code><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.base_plot_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>Return base key names to plot during training.</p>
<p>The keys should match what <cite>chainer.reporter</cite> reports.
if you add the key <cite>loss</cite>,
the reporter will report <cite>main/loss</cite> and <cite>validation/main/loss</cite> values.
also <cite>loss.png</cite> will be created as a figure visulizing <cite>main/loss</cite>
and <cite>validation/main/loss</cite> values.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Base keys to plot during training.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/tts_interface.html#TTSInterface.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate TTS attention weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>Tensor</strong> – Batch of attention weights (B, Lmax, Tmax).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/tts_interface.html#TTSInterface.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate TTS forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Loss value.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/tts_interface.html#TTSInterface.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate the sequence of features given the sequences of characters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The sequence of generated features (L, odim).
Tensor: The sequence of stop probabilities (L,).
Tensor: The sequence of attention weights (L, T).</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.load_pretrained_model">
<code class="sig-name descname">load_pretrained_model</code><span class="sig-paren">(</span><em class="sig-param">model_path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/tts_interface.html#TTSInterface.load_pretrained_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.load_pretrained_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Load pretrained model parameters.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-beam-search">
<span id="id12"></span><h2>espnet.nets.beam_search<a class="headerlink" href="#espnet-nets-beam-search" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.beam_search"></span><p>Beam search module.</p>
<dl class="class">
<dt id="espnet.nets.beam_search.BeamSearch">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.beam_search.</code><code class="sig-name descname">BeamSearch</code><span class="sig-paren">(</span><em class="sig-param">scorers: Dict[str, espnet.nets.scorer_interface.ScorerInterface], weights: Dict[str, float], beam_size: int, vocab_size: int, sos: int, eos: int, token_list: List[str] = None, pre_beam_ratio: float = 1.5, pre_beam_score_key: str = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Beam search implementation.</p>
<p>Initialize beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scorers</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface"><em>ScorerInterface</em></a><em>]</em>) – Dict of decoder modules
e.g., Decoder, CTCPrefixScorer, LM
The scorer will be ignored if it is <cite>None</cite></p></li>
<li><p><strong>weights</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em>) – Dict of weights for each scorers
The scorer will be ignored if its weight is 0</p></li>
<li><p><strong>beam_size</strong> (<em>int</em>) – The number of hypotheses kept during search</p></li>
<li><p><strong>vocab_size</strong> (<em>int</em>) – The number of vocabulary</p></li>
<li><p><strong>sos</strong> (<em>int</em>) – Start of sequence id</p></li>
<li><p><strong>eos</strong> (<em>int</em>) – End of sequence id</p></li>
<li><p><strong>token_list</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of tokens for debug log</p></li>
<li><p><strong>pre_beam_score_key</strong> (<em>str</em>) – key of scores to perform pre-beam search</p></li>
<li><p><strong>pre_beam_ratio</strong> (<em>float</em>) – beam size in the pre-beam search
will be <cite>int(pre_beam_ratio * beam_size)</cite></p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.append_token">
<em class="property">static </em><code class="sig-name descname">append_token</code><span class="sig-paren">(</span><em class="sig-param">xs: torch.Tensor</em>, <em class="sig-param">x: int</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.append_token"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.append_token" title="Permalink to this definition">¶</a></dt>
<dd><p>Append new token to prefix tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The prefix token</p></li>
<li><p><strong>x</strong> (<em>int</em>) – The new token to append</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>New tensor contains: xs + [x] with xs.dtype and xs.device</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.beam">
<code class="sig-name descname">beam</code><span class="sig-paren">(</span><em class="sig-param">weighted_scores: torch.Tensor</em>, <em class="sig-param">ids: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.beam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.beam" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute topk full token ids and partial token ids.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weighted_scores</strong> (<em>torch.Tensor</em>) – The weighted sum scores for each tokens.</p></li>
<li><p><strong>shape is `</strong> (<em>Its</em>) – </p></li>
<li><p><strong>ids</strong> (<em>torch.Tensor</em>) – The partial token ids to compute topk</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The topk full token ids and partial token ids.
Their shapes are <cite>(self.beam_size,)</cite></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">maxlenratio: float = 0.0</em>, <em class="sig-param">minlenratio: float = 0.0</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Encoded speech feature (T, D)</p></li>
<li><p><strong>maxlenratio</strong> (<em>float</em>) – Input length ratio to obtain max output length.
If maxlenratio=0.0 (default), it uses a end-detect function
to automatically find maximum hypothesis lengths
If maxlenratio&lt;0.0, its absolute value is interpreted
as a constant max output length.</p></li>
<li><p><strong>minlenratio</strong> (<em>float</em>) – Input length ratio to obtain min output length.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis">Hypothesis</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.init_hyp">
<code class="sig-name descname">init_hyp</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.init_hyp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.init_hyp" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an initial hypothesis data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoder output feature</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The initial hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis">Hypothesis</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.merge_scores">
<em class="property">static </em><code class="sig-name descname">merge_scores</code><span class="sig-paren">(</span><em class="sig-param">prev_scores: Dict[str, float], next_full_scores: Dict[str, torch.Tensor], full_idx: int, next_part_scores: Dict[str, torch.Tensor], part_idx: int</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.merge_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.merge_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Merge scores for new hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prev_scores</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em>) – The previous hypothesis scores by <cite>self.scorers</cite></p></li>
<li><p><strong>next_full_scores</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>torch.Tensor</em><em>]</em>) – scores by <cite>self.full_scorers</cite></p></li>
<li><p><strong>full_idx</strong> (<em>int</em>) – The next token id for <cite>next_full_scores</cite></p></li>
<li><p><strong>next_part_scores</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>torch.Tensor</em><em>]</em>) – scores of partial tokens by <cite>self.part_scorers</cite></p></li>
<li><p><strong>part_idx</strong> (<em>int</em>) – The new token id for <cite>next_part_scores</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>The new score dict.</dt><dd><p>Its keys are names of <cite>self.full_scorers</cite> and <cite>self.part_scorers</cite>.
Its values are scalar tensors by the scorers.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.merge_states">
<code class="sig-name descname">merge_states</code><span class="sig-paren">(</span><em class="sig-param">states: Any</em>, <em class="sig-param">part_states: Any</em>, <em class="sig-param">part_idx: int</em><span class="sig-paren">)</span> &#x2192; Any<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.merge_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.merge_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Merge states for new hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – states of <cite>self.full_scorers</cite></p></li>
<li><p><strong>part_states</strong> – states of <cite>self.part_scorers</cite></p></li>
<li><p><strong>part_idx</strong> (<em>int</em>) – The new token id for <cite>part_scores</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>The new score dict.</dt><dd><p>Its keys are names of <cite>self.full_scorers</cite> and <cite>self.part_scorers</cite>.
Its values are states of the scorers.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.post_process">
<code class="sig-name descname">post_process</code><span class="sig-paren">(</span><em class="sig-param">i: int, maxlen: int, maxlenratio: float, running_hyps: List[espnet.nets.beam_search.Hypothesis], ended_hyps: List[espnet.nets.beam_search.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.post_process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.post_process" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform post-processing of beam search iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>i</strong> (<em>int</em>) – The length of hypothesis tokens.</p></li>
<li><p><strong>maxlen</strong> (<em>int</em>) – The maximum length of tokens in beam search.</p></li>
<li><p><strong>maxlenratio</strong> (<em>int</em>) – The maximum length ratio in beam search.</p></li>
<li><p><strong>running_hyps</strong> (<em>List</em><em>[</em><a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a><em>]</em>) – The running hypotheses in beam search.</p></li>
<li><p><strong>ended_hyps</strong> (<em>List</em><em>[</em><a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a><em>]</em>) – The ended hypotheses in beam search.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The new running hypotheses.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis">Hypothesis</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.score_full">
<code class="sig-name descname">score_full</code><span class="sig-paren">(</span><em class="sig-param">hyp: espnet.nets.beam_search.Hypothesis</em>, <em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Dict[str, torch.Tensor], Dict[str, Any]]<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.score_full"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.score_full" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new hypothesis by <cite>self.full_scorers</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyp</strong> (<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a>) – Hypothesis with prefix tokens to score</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Corresponding input feature</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>score dict of <cite>hyp</cite> that has string keys of <cite>self.full_scorers</cite>
and tensor score values of shape: <cite>(self.n_vocab,)</cite>,
and state dict that has string keys
and state values of <cite>self.full_scorers</cite></p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Dict[str, torch.Tensor], Dict[str, Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.score_partial">
<code class="sig-name descname">score_partial</code><span class="sig-paren">(</span><em class="sig-param">hyp: espnet.nets.beam_search.Hypothesis</em>, <em class="sig-param">ids: torch.Tensor</em>, <em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Dict[str, torch.Tensor], Dict[str, Any]]<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.score_partial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.score_partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new hypothesis by <cite>self.part_scorers</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyp</strong> (<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a>) – Hypothesis with prefix tokens to score</p></li>
<li><p><strong>ids</strong> (<em>torch.Tensor</em>) – 1D tensor of new partial tokens to score</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Corresponding input feature</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>score dict of <cite>hyp</cite> that has string keys of <cite>self.part_scorers</cite>
and tensor score values of shape: <cite>(len(ids),)</cite>,
and state dict that has string keys
and state values of <cite>self.part_scorers</cite></p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Dict[str, torch.Tensor], Dict[str, Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.beam_search.BeamSearch.search">
<code class="sig-name descname">search</code><span class="sig-paren">(</span><em class="sig-param">running_hyps: List[espnet.nets.beam_search.Hypothesis], x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#BeamSearch.search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.BeamSearch.search" title="Permalink to this definition">¶</a></dt>
<dd><p>Search new tokens for running hypotheses and encoded speech x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>running_hyps</strong> (<em>List</em><em>[</em><a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a><em>]</em>) – Running hypotheses on beam</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Encoded speech feature (T, D)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Best sorted hypotheses</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[Hypotheses]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.beam_search.Hypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.beam_search.</code><code class="sig-name descname">Hypothesis</code><a class="reference internal" href="../_modules/espnet/nets/beam_search.html#Hypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.Hypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<p>Hypothesis data type.</p>
<p>Create new instance of Hypothesis(yseq, score, scores, states)</p>
<dl class="method">
<dt id="espnet.nets.beam_search.Hypothesis.asdict">
<code class="sig-name descname">asdict</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; dict<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#Hypothesis.asdict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.Hypothesis.asdict" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert data to JSON-friendly dict.</p>
</dd></dl>

<dl class="attribute">
<dt id="espnet.nets.beam_search.Hypothesis.score">
<code class="sig-name descname">score</code><a class="headerlink" href="#espnet.nets.beam_search.Hypothesis.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="espnet.nets.beam_search.Hypothesis.scores">
<code class="sig-name descname">scores</code><a class="headerlink" href="#espnet.nets.beam_search.Hypothesis.scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="espnet.nets.beam_search.Hypothesis.states">
<code class="sig-name descname">states</code><a class="headerlink" href="#espnet.nets.beam_search.Hypothesis.states" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="espnet.nets.beam_search.Hypothesis.yseq">
<code class="sig-name descname">yseq</code><a class="headerlink" href="#espnet.nets.beam_search.Hypothesis.yseq" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.beam_search.beam_search">
<code class="sig-prename descclassname">espnet.nets.beam_search.</code><code class="sig-name descname">beam_search</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor, sos: int, eos: int, beam_size: int, vocab_size: int, scorers: Dict[str, espnet.nets.scorer_interface.ScorerInterface], weights: Dict[str, float], token_list: List[str] = None, maxlenratio: float = 0.0, minlenratio: float = 0.0, pre_beam_ratio: float = 1.5, pre_beam_score_key: str = 'full'</em><span class="sig-paren">)</span> &#x2192; list<a class="reference internal" href="../_modules/espnet/nets/beam_search.html#beam_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.beam_search.beam_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform beam search with scorers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Encoded speech feature (T, D)</p></li>
<li><p><strong>sos</strong> (<em>int</em>) – Start of sequence id</p></li>
<li><p><strong>eos</strong> (<em>int</em>) – End of sequence id</p></li>
<li><p><strong>beam_size</strong> (<em>int</em>) – The number of hypotheses kept during search</p></li>
<li><p><strong>vocab_size</strong> (<em>int</em>) – The number of vocabulary</p></li>
<li><p><strong>scorers</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface"><em>ScorerInterface</em></a><em>]</em>) – Dict of decoder modules
e.g., Decoder, CTCPrefixScorer, LM
The scorer will be ignored if it is <cite>None</cite></p></li>
<li><p><strong>weights</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em>) – Dict of weights for each scorers
The scorer will be ignored if its weight is 0</p></li>
<li><p><strong>token_list</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of tokens for debug log</p></li>
<li><p><strong>maxlenratio</strong> (<em>float</em>) – Input length ratio to obtain max output length.
If maxlenratio=0.0 (default), it uses a end-detect function
to automatically find maximum hypothesis lengths</p></li>
<li><p><strong>minlenratio</strong> (<em>float</em>) – Input length ratio to obtain min output length.</p></li>
<li><p><strong>pre_beam_score_key</strong> (<em>str</em>) – key of scores to perform pre-beam search</p></li>
<li><p><strong>pre_beam_ratio</strong> (<em>float</em>) – beam size in the pre-beam search
will be <cite>int(pre_beam_ratio * beam_size)</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-batch-beam-search-online-sim">
<span id="id13"></span><h2>espnet.nets.batch_beam_search_online_sim<a class="headerlink" href="#espnet-nets-batch-beam-search-online-sim" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.batch_beam_search_online_sim"></span><p>Parallel beam search module for online simulation.</p>
<dl class="class">
<dt id="espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.batch_beam_search_online_sim.</code><code class="sig-name descname">BatchBeamSearchOnlineSim</code><span class="sig-paren">(</span><em class="sig-param">scorers: Dict[str, espnet.nets.scorer_interface.ScorerInterface], weights: Dict[str, float], beam_size: int, vocab_size: int, sos: int, eos: int, token_list: List[str] = None, pre_beam_ratio: float = 1.5, pre_beam_score_key: str = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online_sim.html#BatchBeamSearchOnlineSim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.batch_beam_search.BatchBeamSearch" title="espnet.nets.batch_beam_search.BatchBeamSearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.batch_beam_search.BatchBeamSearch</span></code></a></p>
<p>Online beam search implementation.</p>
<p>This simulates streaming decoding.
It requires encoded features of entire utterance and
extracts block by block from it as it shoud be done
in streaming processing.
This is based on Tsunoo et al, “STREAMING TRANSFORMER ASR
WITH BLOCKWISE SYNCHRONOUS BEAM SEARCH”
(<a class="reference external" href="https://arxiv.org/abs/2006.14941">https://arxiv.org/abs/2006.14941</a>).</p>
<p>Initialize beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scorers</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface"><em>ScorerInterface</em></a><em>]</em>) – Dict of decoder modules
e.g., Decoder, CTCPrefixScorer, LM
The scorer will be ignored if it is <cite>None</cite></p></li>
<li><p><strong>weights</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em>) – Dict of weights for each scorers
The scorer will be ignored if its weight is 0</p></li>
<li><p><strong>beam_size</strong> (<em>int</em>) – The number of hypotheses kept during search</p></li>
<li><p><strong>vocab_size</strong> (<em>int</em>) – The number of vocabulary</p></li>
<li><p><strong>sos</strong> (<em>int</em>) – Start of sequence id</p></li>
<li><p><strong>eos</strong> (<em>int</em>) – End of sequence id</p></li>
<li><p><strong>token_list</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of tokens for debug log</p></li>
<li><p><strong>pre_beam_score_key</strong> (<em>str</em>) – key of scores to perform pre-beam search</p></li>
<li><p><strong>pre_beam_ratio</strong> (<em>float</em>) – beam size in the pre-beam search
will be <cite>int(pre_beam_ratio * beam_size)</cite></p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.extend">
<code class="sig-name descname">extend</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">hyps: espnet.nets.beam_search.Hypothesis</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online_sim.html#BatchBeamSearchOnlineSim.extend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.extend" title="Permalink to this definition">¶</a></dt>
<dd><p>Extend probabilities and states with more encoded chunks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – The extended encoder output feature</p></li>
<li><p><strong>hyps</strong> (<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a>) – Current list of hypothesis</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The extended hypothesis</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis">Hypothesis</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">maxlenratio: float = 0.0</em>, <em class="sig-param">minlenratio: float = 0.0</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online_sim.html#BatchBeamSearchOnlineSim.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Encoded speech feature (T, D)</p></li>
<li><p><strong>maxlenratio</strong> (<em>float</em>) – Input length ratio to obtain max output length.
If maxlenratio=0.0 (default), it uses a end-detect function
to automatically find maximum hypothesis lengths</p></li>
<li><p><strong>minlenratio</strong> (<em>float</em>) – Input length ratio to obtain min output length.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis">Hypothesis</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.set_block_size">
<code class="sig-name descname">set_block_size</code><span class="sig-paren">(</span><em class="sig-param">block_size: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online_sim.html#BatchBeamSearchOnlineSim.set_block_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.set_block_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Set block size for streaming decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>block_size</strong> (<em>int</em>) – The block size of encoder</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.set_hop_size">
<code class="sig-name descname">set_hop_size</code><span class="sig-paren">(</span><em class="sig-param">hop_size: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online_sim.html#BatchBeamSearchOnlineSim.set_hop_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.set_hop_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Set hop size for streaming decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hop_size</strong> (<em>int</em>) – The hop size of encoder</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.set_look_ahead">
<code class="sig-name descname">set_look_ahead</code><span class="sig-paren">(</span><em class="sig-param">look_ahead: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online_sim.html#BatchBeamSearchOnlineSim.set_look_ahead"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.set_look_ahead" title="Permalink to this definition">¶</a></dt>
<dd><p>Set look ahead size for streaming decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>look_ahead</strong> (<em>int</em>) – The look ahead size of encoder</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.set_streaming_config">
<code class="sig-name descname">set_streaming_config</code><span class="sig-paren">(</span><em class="sig-param">asr_config: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search_online_sim.html#BatchBeamSearchOnlineSim.set_streaming_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search_online_sim.BatchBeamSearchOnlineSim.set_streaming_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Set config file for streaming decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>asr_config</strong> (<em>str</em>) – The config file for asr training</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-asr-interface">
<span id="id14"></span><h2>espnet.nets.asr_interface<a class="headerlink" href="#espnet-nets-asr-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.asr_interface"></span><p>ASR Interface module.</p>
<dl class="class">
<dt id="espnet.nets.asr_interface.ASRInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.asr_interface.</code><code class="sig-name descname">ASRInterface</code><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>ASR Interface for ESPnet model implementation.</p>
<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments to parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Get attention plot class.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.build">
<em class="property">classmethod </em><code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">odim: int</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize this class with python-level args.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – The number of an input feature dim.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – The number of output vocab.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new instance of ASRInterface.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ASRinterface</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>list</em>) – list of padded input sequences [(T1, idim), (T2, idim), …]</p></li>
<li><p><strong>ilens</strong> (<em>ndarray</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys</strong> (<em>list</em>) – list of character id sequence tensor [(L1), (L2), (L3), …]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weights (B, Lmax, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.calculate_all_ctc_probs">
<code class="sig-name descname">calculate_all_ctc_probs</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.calculate_all_ctc_probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.calculate_all_ctc_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate CTC probability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>list</em>) – list of padded input sequences [(T1, idim), (T2, idim), …]</p></li>
<li><p><strong>ilens</strong> (<em>ndarray</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys</strong> (<em>list</em>) – list of character id sequence tensor [(L1), (L2), (L3), …]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>CTC probabilities (B, Tmax, vocab)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.ctc_plot_class">
<em class="property">property </em><code class="sig-name descname">ctc_plot_class</code><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.ctc_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Get CTC plot class.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">feat</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode feature in <cite>beam_search</cite> (optional).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>numpy.ndarray</em>) – input feature (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoded feature (T, D)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor for pytorch, chainer.Variable for chainer</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute loss for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> – For pytorch, batch of padded source sequences torch.Tensor (B, Tmax, idim)
For chainer, list of source sequences chainer.Variable</p></li>
<li><p><strong>ilens</strong> – batch of lengths of source sequences (B)
For pytorch, torch.Tensor
For chainer, list of int</p></li>
<li><p><strong>ys</strong> – For pytorch, batch of padded source sequences torch.Tensor (B, Lmax)
For chainer, list of source sequences chainer.Variable</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor for pytorch, chainer.Variable for chainer</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize x for evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – input acouctic feature (B, T, D) or (T, D)</p></li>
<li><p><strong>recog_args</strong> (<em>namespace</em>) – argment namespace contraining options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.recognize_batch">
<code class="sig-name descname">recognize_batch</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.recognize_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.recognize_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Beam search implementation for batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – encoder hidden state sequences (B, Tmax, Henc)</p></li>
<li><p><strong>recog_args</strong> (<em>namespace</em>) – argument namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.scorers">
<code class="sig-name descname">scorers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#ASRInterface.scorers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.scorers" title="Permalink to this definition">¶</a></dt>
<dd><p>Get scorers for <cite>beam_search</cite> (optional).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>dict of <cite>ScorerInterface</cite> objects</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict[str, <a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface">ScorerInterface</a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.asr_interface.dynamic_import_asr">
<code class="sig-prename descclassname">espnet.nets.asr_interface.</code><code class="sig-name descname">dynamic_import_asr</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">backend</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/asr_interface.html#dynamic_import_asr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.asr_interface.dynamic_import_asr" title="Permalink to this definition">¶</a></dt>
<dd><p>Import ASR models dynamically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>str</em>) – module_name:class_name or alias in <cite>predefined_asr</cite></p></li>
<li><p><strong>backend</strong> (<em>str</em>) – NN backend. e.g., pytorch, chainer</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ASR class</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>type</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-e2e-mt-common">
<span id="id15"></span><h2>espnet.nets.e2e_mt_common<a class="headerlink" href="#espnet-nets-e2e-mt-common" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.e2e_mt_common"></span><p>Common functions for ST and MT.</p>
<dl class="class">
<dt id="espnet.nets.e2e_mt_common.ErrorCalculator">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.e2e_mt_common.</code><code class="sig-name descname">ErrorCalculator</code><span class="sig-paren">(</span><em class="sig-param">char_list</em>, <em class="sig-param">sym_space</em>, <em class="sig-param">sym_pad</em>, <em class="sig-param">report_bleu=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_mt_common.html#ErrorCalculator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_mt_common.ErrorCalculator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Calculate BLEU for ST and MT models during training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_hats</strong> – numpy array with predicted text</p></li>
<li><p><strong>y_pads</strong> – numpy array with true (target) text</p></li>
<li><p><strong>char_list</strong> – vocabulary list</p></li>
<li><p><strong>sym_space</strong> – space symbol</p></li>
<li><p><strong>sym_pad</strong> – pad symbol</p></li>
<li><p><strong>report_bleu</strong> – report BLUE score if True</p></li>
</ul>
</dd>
</dl>
<p>Construct an ErrorCalculator object.</p>
<dl class="method">
<dt id="espnet.nets.e2e_mt_common.ErrorCalculator.calculate_corpus_bleu">
<code class="sig-name descname">calculate_corpus_bleu</code><span class="sig-paren">(</span><em class="sig-param">ys_hat</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/e2e_mt_common.html#ErrorCalculator.calculate_corpus_bleu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.e2e_mt_common.ErrorCalculator.calculate_corpus_bleu" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate corpus-level BLEU score in a mini-batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seqs_hat</strong> (<em>torch.Tensor</em>) – prediction (batch, seqlen)</p></li>
<li><p><strong>seqs_true</strong> (<em>torch.Tensor</em>) – reference (batch, seqlen)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>corpus-level BLEU score</p>
</dd>
</dl>
<p>:rtype float</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-batch-beam-search">
<span id="id16"></span><h2>espnet.nets.batch_beam_search<a class="headerlink" href="#espnet-nets-batch-beam-search" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.batch_beam_search"></span><p>Parallel beam search module.</p>
<dl class="class">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.batch_beam_search.</code><code class="sig-name descname">BatchBeamSearch</code><span class="sig-paren">(</span><em class="sig-param">scorers: Dict[str, espnet.nets.scorer_interface.ScorerInterface], weights: Dict[str, float], beam_size: int, vocab_size: int, sos: int, eos: int, token_list: List[str] = None, pre_beam_ratio: float = 1.5, pre_beam_score_key: str = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.beam_search.BeamSearch" title="espnet.nets.beam_search.BeamSearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.beam_search.BeamSearch</span></code></a></p>
<p>Batch beam search implementation.</p>
<p>Initialize beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scorers</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface"><em>ScorerInterface</em></a><em>]</em>) – Dict of decoder modules
e.g., Decoder, CTCPrefixScorer, LM
The scorer will be ignored if it is <cite>None</cite></p></li>
<li><p><strong>weights</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em>) – Dict of weights for each scorers
The scorer will be ignored if its weight is 0</p></li>
<li><p><strong>beam_size</strong> (<em>int</em>) – The number of hypotheses kept during search</p></li>
<li><p><strong>vocab_size</strong> (<em>int</em>) – The number of vocabulary</p></li>
<li><p><strong>sos</strong> (<em>int</em>) – Start of sequence id</p></li>
<li><p><strong>eos</strong> (<em>int</em>) – End of sequence id</p></li>
<li><p><strong>token_list</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – List of tokens for debug log</p></li>
<li><p><strong>pre_beam_score_key</strong> (<em>str</em>) – key of scores to perform pre-beam search</p></li>
<li><p><strong>pre_beam_ratio</strong> (<em>float</em>) – beam size in the pre-beam search
will be <cite>int(pre_beam_ratio * beam_size)</cite></p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch.batch_beam">
<code class="sig-name descname">batch_beam</code><span class="sig-paren">(</span><em class="sig-param">weighted_scores: torch.Tensor</em>, <em class="sig-param">ids: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch.batch_beam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch.batch_beam" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch-compute topk full token ids and partial token ids.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weighted_scores</strong> (<em>torch.Tensor</em>) – The weighted sum scores for each tokens.
Its shape is <cite>(n_beam, self.vocab_size)</cite>.</p></li>
<li><p><strong>ids</strong> (<em>torch.Tensor</em>) – The partial token ids to compute topk.
Its shape is <cite>(n_beam, self.pre_beam_size)</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The topk full (prev_hyp, new_token) ids
and partial (prev_hyp, new_token) ids.
Their shapes are all <cite>(self.beam_size,)</cite></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch.batchfy">
<code class="sig-name descname">batchfy</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet.nets.beam_search.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; espnet.nets.batch_beam_search.BatchHypothesis<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch.batchfy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch.batchfy" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert list to batch.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch.init_hyp">
<code class="sig-name descname">init_hyp</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; espnet.nets.batch_beam_search.BatchHypothesis<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch.init_hyp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch.init_hyp" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an initial hypothesis data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoder output feature</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The initial hypothesis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis">Hypothesis</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch.merge_states">
<code class="sig-name descname">merge_states</code><span class="sig-paren">(</span><em class="sig-param">states: Any</em>, <em class="sig-param">part_states: Any</em>, <em class="sig-param">part_idx: int</em><span class="sig-paren">)</span> &#x2192; Any<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch.merge_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch.merge_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Merge states for new hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – states of <cite>self.full_scorers</cite></p></li>
<li><p><strong>part_states</strong> – states of <cite>self.part_scorers</cite></p></li>
<li><p><strong>part_idx</strong> (<em>int</em>) – The new token id for <cite>part_scores</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>The new score dict.</dt><dd><p>Its keys are names of <cite>self.full_scorers</cite> and <cite>self.part_scorers</cite>.
Its values are states of the scorers.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch.post_process">
<code class="sig-name descname">post_process</code><span class="sig-paren">(</span><em class="sig-param">i: int, maxlen: int, maxlenratio: float, running_hyps: espnet.nets.batch_beam_search.BatchHypothesis, ended_hyps: List[espnet.nets.beam_search.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; espnet.nets.batch_beam_search.BatchHypothesis<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch.post_process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch.post_process" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform post-processing of beam search iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>i</strong> (<em>int</em>) – The length of hypothesis tokens.</p></li>
<li><p><strong>maxlen</strong> (<em>int</em>) – The maximum length of tokens in beam search.</p></li>
<li><p><strong>maxlenratio</strong> (<em>int</em>) – The maximum length ratio in beam search.</p></li>
<li><p><strong>running_hyps</strong> (<a class="reference internal" href="#espnet.nets.batch_beam_search.BatchHypothesis" title="espnet.nets.batch_beam_search.BatchHypothesis"><em>BatchHypothesis</em></a>) – The running hypotheses in beam search.</p></li>
<li><p><strong>ended_hyps</strong> (<em>List</em><em>[</em><a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a><em>]</em>) – The ended hypotheses in beam search.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The new running hypotheses.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#espnet.nets.batch_beam_search.BatchHypothesis" title="espnet.nets.batch_beam_search.BatchHypothesis">BatchHypothesis</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch.score_full">
<code class="sig-name descname">score_full</code><span class="sig-paren">(</span><em class="sig-param">hyp: espnet.nets.batch_beam_search.BatchHypothesis</em>, <em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Dict[str, torch.Tensor], Dict[str, Any]]<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch.score_full"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch.score_full" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new hypothesis by <cite>self.full_scorers</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyp</strong> (<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a>) – Hypothesis with prefix tokens to score</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Corresponding input feature</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>score dict of <cite>hyp</cite> that has string keys of <cite>self.full_scorers</cite>
and tensor score values of shape: <cite>(self.n_vocab,)</cite>,
and state dict that has string keys
and state values of <cite>self.full_scorers</cite></p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Dict[str, torch.Tensor], Dict[str, Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch.score_partial">
<code class="sig-name descname">score_partial</code><span class="sig-paren">(</span><em class="sig-param">hyp: espnet.nets.batch_beam_search.BatchHypothesis</em>, <em class="sig-param">ids: torch.Tensor</em>, <em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Dict[str, torch.Tensor], Dict[str, Any]]<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch.score_partial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch.score_partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new hypothesis by <cite>self.full_scorers</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyp</strong> (<a class="reference internal" href="#espnet.nets.transducer_decoder_interface.Hypothesis" title="espnet.nets.transducer_decoder_interface.Hypothesis"><em>Hypothesis</em></a>) – Hypothesis with prefix tokens to score</p></li>
<li><p><strong>ids</strong> (<em>torch.Tensor</em>) – 2D tensor of new partial tokens to score</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Corresponding input feature</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>score dict of <cite>hyp</cite> that has string keys of <cite>self.full_scorers</cite>
and tensor score values of shape: <cite>(self.n_vocab,)</cite>,
and state dict that has string keys
and state values of <cite>self.full_scorers</cite></p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Dict[str, torch.Tensor], Dict[str, Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch.search">
<code class="sig-name descname">search</code><span class="sig-paren">(</span><em class="sig-param">running_hyps: espnet.nets.batch_beam_search.BatchHypothesis</em>, <em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; espnet.nets.batch_beam_search.BatchHypothesis<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch.search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch.search" title="Permalink to this definition">¶</a></dt>
<dd><p>Search new tokens for running hypotheses and encoded speech x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>running_hyps</strong> (<a class="reference internal" href="#espnet.nets.batch_beam_search.BatchHypothesis" title="espnet.nets.batch_beam_search.BatchHypothesis"><em>BatchHypothesis</em></a>) – Running hypotheses on beam</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Encoded speech feature (T, D)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Best sorted hypotheses</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#espnet.nets.batch_beam_search.BatchHypothesis" title="espnet.nets.batch_beam_search.BatchHypothesis">BatchHypothesis</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.batch_beam_search.BatchBeamSearch.unbatchfy">
<code class="sig-name descname">unbatchfy</code><span class="sig-paren">(</span><em class="sig-param">batch_hyps: espnet.nets.batch_beam_search.BatchHypothesis</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchBeamSearch.unbatchfy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchBeamSearch.unbatchfy" title="Permalink to this definition">¶</a></dt>
<dd><p>Revert batch to list.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.batch_beam_search.BatchHypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.batch_beam_search.</code><code class="sig-name descname">BatchHypothesis</code><a class="reference internal" href="../_modules/espnet/nets/batch_beam_search.html#BatchHypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchHypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<p>Batchfied/Vectorized hypothesis data type.</p>
<p>Create new instance of BatchHypothesis(yseq, score, length, scores, states)</p>
<dl class="attribute">
<dt id="espnet.nets.batch_beam_search.BatchHypothesis.length">
<code class="sig-name descname">length</code><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchHypothesis.length" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="espnet.nets.batch_beam_search.BatchHypothesis.score">
<code class="sig-name descname">score</code><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchHypothesis.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="espnet.nets.batch_beam_search.BatchHypothesis.scores">
<code class="sig-name descname">scores</code><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchHypothesis.scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="espnet.nets.batch_beam_search.BatchHypothesis.states">
<code class="sig-name descname">states</code><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchHypothesis.states" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="attribute">
<dt id="espnet.nets.batch_beam_search.BatchHypothesis.yseq">
<code class="sig-name descname">yseq</code><a class="headerlink" href="#espnet.nets.batch_beam_search.BatchHypothesis.yseq" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-ctc">
<span id="id17"></span><h2>espnet.nets.chainer_backend.ctc<a class="headerlink" href="#espnet-nets-chainer-backend-ctc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.ctc"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.ctc.CTC">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.ctc.</code><code class="sig-name descname">CTC</code><span class="sig-paren">(</span><em class="sig-param">odim</em>, <em class="sig-param">eprojs</em>, <em class="sig-param">dropout_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/ctc.html#CTC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.CTC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Chainer implementation of ctc layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>eprojs</strong> (<em>int | None</em>) – Dimension of input vectors from encoder.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.ctc.CTC.log_softmax">
<code class="sig-name descname">log_softmax</code><span class="sig-paren">(</span><em class="sig-param">hs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/ctc.html#CTC.log_softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.CTC.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Log_softmax of frame activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hs</strong> (<em>list of chainer.Variable | N-dimension array</em>) – Input variable from encoder.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A n-dimension float array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.ctc.WarpCTC">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.ctc.</code><code class="sig-name descname">WarpCTC</code><span class="sig-paren">(</span><em class="sig-param">odim</em>, <em class="sig-param">eprojs</em>, <em class="sig-param">dropout_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/ctc.html#WarpCTC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.WarpCTC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Chainer implementation of warp-ctc layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>eproj</strong> (<em>int | None</em>) – Dimension of input vector from encoder.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.ctc.WarpCTC.argmax">
<code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/ctc.html#WarpCTC.argmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.WarpCTC.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>argmax of frame activations</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>variable hs_pad</strong> (<em>chainer</em>) – 3d tensor (B, Tmax, eprojs)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>argmax applied 2d tensor (B, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.ctc.WarpCTC.log_softmax">
<code class="sig-name descname">log_softmax</code><span class="sig-paren">(</span><em class="sig-param">hs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/ctc.html#WarpCTC.log_softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.WarpCTC.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Log_softmax of frame activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hs</strong> (<em>list of chainer.Variable | N-dimension array</em>) – Input variable from encoder.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A n-dimension float array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.ctc.ctc_for">
<code class="sig-prename descclassname">espnet.nets.chainer_backend.ctc.</code><code class="sig-name descname">ctc_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">odim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/ctc.html#ctc_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.ctc_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the CTC layer corresponding to the args.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>Namespace</em>) – The program arguments.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – The output dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The CTC module.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-deterministic-embed-id">
<span id="id18"></span><h2>espnet.nets.chainer_backend.deterministic_embed_id<a class="headerlink" href="#espnet-nets-chainer-backend-deterministic-embed-id" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.deterministic_embed_id"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedID">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.deterministic_embed_id.</code><code class="sig-name descname">EmbedID</code><span class="sig-paren">(</span><em class="sig-param">in_size</em>, <em class="sig-param">out_size</em>, <em class="sig-param">initialW=None</em>, <em class="sig-param">ignore_label=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/deterministic_embed_id.html#EmbedID"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedID" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Link</span></code></p>
<p>Efficient linear layer for one-hot input.</p>
<p>This is a link that wraps the <code class="xref py py-func docutils literal notranslate"><span class="pre">embed_id()</span></code> function.
This link holds the ID (word) embedding matrix <code class="docutils literal notranslate"><span class="pre">W</span></code> as a parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_size</strong> (<em>int</em>) – Number of different identifiers (a.k.a. vocabulary size).</p></li>
<li><p><strong>out_size</strong> (<em>int</em>) – Output dimension.</p></li>
<li><p><strong>initialW</strong> (<em>Initializer</em>) – Initializer to initialize the weight.</p></li>
<li><p><strong>ignore_label</strong> (<em>int</em>) – If <cite>ignore_label</cite> is an int value, i-th column of
return value is filled with 0.</p></li>
</ul>
</dd>
</dl>
<p class="rubric"><code class="xref py py-func docutils literal notranslate"><span class="pre">embed_id()</span></code></p>
<dl class="attribute">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedID.W">
<code class="sig-name descname">W</code><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedID.W" title="Permalink to this definition">¶</a></dt>
<dd><p>Embedding parameter matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Variable</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">W</span>
<span class="go">array([[ 0.,  0.,  0.],</span>
<span class="go">       [ 1.,  1.,  1.],</span>
<span class="go">       [ 2.,  2.,  2.]], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">EmbedID</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">initialW</span><span class="o">=</span><span class="n">W</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">array([2, 1], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">data</span>
<span class="go">array([[ 2.,  2.,  2.],</span>
<span class="go">       [ 1.,  1.,  1.]], dtype=float32)</span>
</pre></div>
</div>
<dl class="attribute">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedID.ignore_label">
<code class="sig-name descname">ignore_label</code><em class="property"> = None</em><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedID.ignore_label" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.deterministic_embed_id.</code><code class="sig-name descname">EmbedIDFunction</code><span class="sig-paren">(</span><em class="sig-param">ignore_label=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/deterministic_embed_id.html#EmbedIDFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.function_node.FunctionNode</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.backward">
<code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">indexes</em>, <em class="sig-param">grad_outputs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/deterministic_embed_id.html#EmbedIDFunction.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes gradients w.r.t. specified inputs given output gradients.</p>
<p>This method is used to compute one step of the backpropagation
corresponding to the forward computation of this function node.
Given the gradients w.r.t. output variables, this method computes the
gradients w.r.t. specified input variables. Note that this method does
not need to compute any input gradients not specified by
<code class="docutils literal notranslate"><span class="pre">target_input_indices</span></code>.</p>
<p>Unlike <code class="xref py py-meth docutils literal notranslate"><span class="pre">Function.backward()</span></code>,
gradients are given as  <code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code> objects and this
method itself has to return input gradients as
<code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code> objects. It enables the function node to
return the input gradients with the full computational history, in
which case it supports <em>differentiable backpropagation</em> or
<em>higher-order differentiation</em>.</p>
<p>The default implementation returns <code class="docutils literal notranslate"><span class="pre">None</span></code> s, which means the
function is not differentiable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_input_indexes</strong> (<em>tuple of int</em>) – Sorted indices of the input
variables w.r.t. which the gradients are required. It is
guaranteed that this tuple contains at least one element.</p></li>
<li><p><strong>grad_outputs</strong> (tuple of <code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code>s) – Gradients
w.r.t. the output variables.
If the gradient w.r.t. an output variable is not
given, the corresponding element is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of variables that represent the gradients w.r.t. specified
input variables. The length of the tuple can be same as either
<code class="docutils literal notranslate"><span class="pre">len(target_input_indexes)</span></code> or the number of inputs. In the
latter case, the elements not specified by <code class="docutils literal notranslate"><span class="pre">target_input_indexes</span></code>
will be discarded.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-meth docutils literal notranslate"><span class="pre">backward_accumulate()</span></code> provides an alternative interface that
allows you to implement the backward computation fused with the
gradient accumulation.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.check_type_forward">
<code class="sig-name descname">check_type_forward</code><span class="sig-paren">(</span><em class="sig-param">in_types</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/deterministic_embed_id.html#EmbedIDFunction.check_type_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.check_type_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks types of input data before forward propagation.</p>
<p>This method is called before <a class="reference internal" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward" title="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> and validates the types of
input variables using
<span class="xref std std-ref">the type checking utilities</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>in_types</strong> (<em>TypeInfoTuple</em>) – The type
information of input variables for <a class="reference internal" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward" title="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a>.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/deterministic_embed_id.html#EmbedIDFunction.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output arrays from the input arrays.</p>
<p>It delegates the procedure to <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_cpu()</span></code> or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_gpu()</span></code> by default. Which of them this method selects is
determined by the type of input arrays. Implementations of
<code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionNode</span></code> must implement either CPU/GPU methods or this
method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> – Tuple of input array(s).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of output array(s).</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Implementations of <code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionNode</span></code> must take care that the
return value must be a tuple even if it returns only one array.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.deterministic_embed_id.</code><code class="sig-name descname">EmbedIDGrad</code><span class="sig-paren">(</span><em class="sig-param">w_shape</em>, <em class="sig-param">ignore_label=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/deterministic_embed_id.html#EmbedIDGrad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.function_node.FunctionNode</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad.backward">
<code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">indexes</em>, <em class="sig-param">grads</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/deterministic_embed_id.html#EmbedIDGrad.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes gradients w.r.t. specified inputs given output gradients.</p>
<p>This method is used to compute one step of the backpropagation
corresponding to the forward computation of this function node.
Given the gradients w.r.t. output variables, this method computes the
gradients w.r.t. specified input variables. Note that this method does
not need to compute any input gradients not specified by
<code class="docutils literal notranslate"><span class="pre">target_input_indices</span></code>.</p>
<p>Unlike <code class="xref py py-meth docutils literal notranslate"><span class="pre">Function.backward()</span></code>,
gradients are given as  <code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code> objects and this
method itself has to return input gradients as
<code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code> objects. It enables the function node to
return the input gradients with the full computational history, in
which case it supports <em>differentiable backpropagation</em> or
<em>higher-order differentiation</em>.</p>
<p>The default implementation returns <code class="docutils literal notranslate"><span class="pre">None</span></code> s, which means the
function is not differentiable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_input_indexes</strong> (<em>tuple of int</em>) – Sorted indices of the input
variables w.r.t. which the gradients are required. It is
guaranteed that this tuple contains at least one element.</p></li>
<li><p><strong>grad_outputs</strong> (tuple of <code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code>s) – Gradients
w.r.t. the output variables.
If the gradient w.r.t. an output variable is not
given, the corresponding element is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of variables that represent the gradients w.r.t. specified
input variables. The length of the tuple can be same as either
<code class="docutils literal notranslate"><span class="pre">len(target_input_indexes)</span></code> or the number of inputs. In the
latter case, the elements not specified by <code class="docutils literal notranslate"><span class="pre">target_input_indexes</span></code>
will be discarded.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-meth docutils literal notranslate"><span class="pre">backward_accumulate()</span></code> provides an alternative interface that
allows you to implement the backward computation fused with the
gradient accumulation.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/deterministic_embed_id.html#EmbedIDGrad.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output arrays from the input arrays.</p>
<p>It delegates the procedure to <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_cpu()</span></code> or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_gpu()</span></code> by default. Which of them this method selects is
determined by the type of input arrays. Implementations of
<code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionNode</span></code> must implement either CPU/GPU methods or this
method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> – Tuple of input array(s).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of output array(s).</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Implementations of <code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionNode</span></code> must take care that the
return value must be a tuple even if it returns only one array.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.embed_id">
<code class="sig-prename descclassname">espnet.nets.chainer_backend.deterministic_embed_id.</code><code class="sig-name descname">embed_id</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">W</em>, <em class="sig-param">ignore_label=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/deterministic_embed_id.html#embed_id"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.embed_id" title="Permalink to this definition">¶</a></dt>
<dd><p>Efficient linear function for one-hot input.</p>
<p>This function implements so called <em>word embeddings</em>. It takes two
arguments: a set of IDs (words) <code class="docutils literal notranslate"><span class="pre">x</span></code> in <span class="math notranslate nohighlight">\(B\)</span> dimensional integer
vector, and a set of all ID (word) embeddings <code class="docutils literal notranslate"><span class="pre">W</span></code> in <span class="math notranslate nohighlight">\(V \\times d\)</span>
float32 matrix. It outputs <span class="math notranslate nohighlight">\(B \\times d\)</span> matrix whose <code class="docutils literal notranslate"><span class="pre">i</span></code>-th
column is the <code class="docutils literal notranslate"><span class="pre">x[i]</span></code>-th column of <code class="docutils literal notranslate"><span class="pre">W</span></code>.
This function is only differentiable on the input <code class="docutils literal notranslate"><span class="pre">W</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>chainer.Variable | np.ndarray</em>) – Batch vectors of IDs. Each
element must be signed integer.</p></li>
<li><p><strong>W</strong> (<em>chainer.Variable | np.ndarray</em>) – Distributed representation
of each ID (a.k.a. word embeddings).</p></li>
<li><p><strong>ignore_label</strong> (<em>int</em>) – If ignore_label is an int value, i-th column
of return value is filled with 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Embedded variable.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
<p class="rubric"><code class="xref py py-class docutils literal notranslate"><span class="pre">EmbedID</span></code></p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">array([2, 1], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">W</span>
<span class="go">array([[ 0.,  0.,  0.],</span>
<span class="go">       [ 1.,  1.,  1.],</span>
<span class="go">       [ 2.,  2.,  2.]], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F</span><span class="o">.</span><span class="n">embed_id</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
<span class="go">array([[ 2.,  2.,  2.],</span>
<span class="go">       [ 1.,  1.,  1.]], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F</span><span class="o">.</span><span class="n">embed_id</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">ignore_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
<span class="go">array([[ 2.,  2.,  2.],</span>
<span class="go">       [ 0.,  0.,  0.]], dtype=float32)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-init">
<span id="id19"></span><h2>espnet.nets.chainer_backend.__init__<a class="headerlink" href="#espnet-nets-chainer-backend-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-chainer-backend-e2e-asr">
<span id="id20"></span><h2>espnet.nets.chainer_backend.e2e_asr<a class="headerlink" href="#espnet-nets-chainer-backend-e2e-asr" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.e2e_asr"></span><p>RNN sequence-to-sequence speech recognition model (chainer).</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.e2e_asr.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">flag_return=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.chainer_backend.asr_interface.ChainerASRInterface" title="espnet.nets.chainer_backend.asr_interface.ChainerASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.chainer_backend.asr_interface.ChainerASRInterface</span></code></a></p>
<p>E2E module for chainer backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>args</strong> (<em>parser.args</em>) – Training config.</p></li>
<li><p><strong>flag_return</strong> (<em>bool</em>) – If True, train() would return
additional metrics in addition to the training
loss.</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>List</em>) – List of padded input sequences. [(T1, idim), (T2, idim), …]</p></li>
<li><p><strong>ilens</strong> (<em>np.ndarray</em>) – Batch of lengths of input sequences. (B)</p></li>
<li><p><strong>ys</strong> (<em>List</em>) – List of character id sequence tensor. [(L1), (L2), (L3), …]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Attention weights. (B, Lmax, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.custom_converter">
<em class="property">static </em><code class="sig-name descname">custom_converter</code><span class="sig-paren">(</span><em class="sig-param">subsampling_factor=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr.html#E2E.custom_converter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.custom_converter" title="Permalink to this definition">¶</a></dt>
<dd><p>Get customconverter of the model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.custom_parallel_updater">
<em class="property">static </em><code class="sig-name descname">custom_parallel_updater</code><span class="sig-paren">(</span><em class="sig-param">iters</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">converter</em>, <em class="sig-param">devices</em>, <em class="sig-param">accum_grad=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr.html#E2E.custom_parallel_updater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.custom_parallel_updater" title="Permalink to this definition">¶</a></dt>
<dd><p>Get custom_parallel_updater of the model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.custom_updater">
<em class="property">static </em><code class="sig-name descname">custom_updater</code><span class="sig-paren">(</span><em class="sig-param">iters</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">converter</em>, <em class="sig-param">device=-1</em>, <em class="sig-param">accum_grad=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr.html#E2E.custom_updater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.custom_updater" title="Permalink to this definition">¶</a></dt>
<dd><p>Get custom_updater of the model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>chainer.Variable</em>) – Batch of padded character ids. (B, Tmax)</p></li>
<li><p><strong>ilens</strong> (<em>chainer.Variable</em>) – Batch of length of each input batch. (B,)</p></li>
<li><p><strong>ys</strong> (<em>chainer.Variable</em>) – Batch of padded target features. (B, Lmax, odim)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Loss that calculated by attention and ctc loss.
float (optional): Ctc loss.
float (optional): Attention loss.
float (optional): Accuracy.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr.html#E2E.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr.html#E2E.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E greedy/beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>chainer.Variable</em>) – Input tensor for recognition.</p></li>
<li><p><strong>recog_args</strong> (<em>parser.args</em>) – Arguments of config file.</p></li>
<li><p><strong>char_list</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of Characters.</p></li>
<li><p><strong>rnnlm</strong> (<em>Module</em>) – RNNLM module defined at <cite>espnet.lm.chainer_backend.lm</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Result of recognition.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[Dict[str, Any]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-asr-interface">
<span id="id21"></span><h2>espnet.nets.chainer_backend.asr_interface<a class="headerlink" href="#espnet-nets-chainer-backend-asr-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.asr_interface"></span><p>ASR Interface module.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.asr_interface.ChainerASRInterface">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.asr_interface.</code><code class="sig-name descname">ChainerASRInterface</code><span class="sig-paren">(</span><em class="sig-param">**links</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/asr_interface.html#ChainerASRInterface"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.asr_interface.ChainerASRInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>ASR Interface for ESPnet model implementation.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.asr_interface.ChainerASRInterface.custom_converter">
<em class="property">static </em><code class="sig-name descname">custom_converter</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kw</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/asr_interface.html#ChainerASRInterface.custom_converter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.asr_interface.ChainerASRInterface.custom_converter" title="Permalink to this definition">¶</a></dt>
<dd><p>Get customconverter of the model (Chainer only).</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.asr_interface.ChainerASRInterface.custom_parallel_updater">
<em class="property">static </em><code class="sig-name descname">custom_parallel_updater</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kw</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/asr_interface.html#ChainerASRInterface.custom_parallel_updater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.asr_interface.ChainerASRInterface.custom_parallel_updater" title="Permalink to this definition">¶</a></dt>
<dd><p>Get custom_parallel_updater of the model (Chainer only).</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.asr_interface.ChainerASRInterface.custom_updater">
<em class="property">static </em><code class="sig-name descname">custom_updater</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kw</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/asr_interface.html#ChainerASRInterface.custom_updater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.asr_interface.ChainerASRInterface.custom_updater" title="Permalink to this definition">¶</a></dt>
<dd><p>Get custom_updater of the model (Chainer only).</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.asr_interface.ChainerASRInterface.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/asr_interface.html#ChainerASRInterface.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.asr_interface.ChainerASRInterface.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-e2e-asr-transformer">
<span id="id22"></span><h2>espnet.nets.chainer_backend.e2e_asr_transformer<a class="headerlink" href="#espnet-nets-chainer-backend-e2e-asr-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.e2e_asr_transformer"></span><p>Transformer-based model for End-to-end ASR.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.e2e_asr_transformer.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">ignore_id=-1</em>, <em class="sig-param">flag_return=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.chainer_backend.asr_interface.ChainerASRInterface" title="espnet.nets.chainer_backend.asr_interface.ChainerASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.chainer_backend.asr_interface.ChainerASRInterface</span></code></a></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimmensions.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Output dimmensions.</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – Training config.</p></li>
<li><p><strong>ignore_id</strong> (<em>int</em><em>, </em><em>optional</em>) – Id for ignoring a character.</p></li>
<li><p><strong>flag_return</strong> (<em>bool</em><em>, </em><em>optional</em>) – If true, return a list with (loss,</p></li>
<li><p><strong>loss_att</strong><strong>, </strong><strong>acc</strong><strong>) </strong><strong>in forward. Otherwise</strong><strong>, </strong><strong>return loss.</strong> (<em>loss_ctc</em><em>,</em>) – </p></li>
</ul>
</dd>
</dl>
<p>Initialize the transformer.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Customize flags for transformer setup.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>parser</strong> (<em>Namespace</em>) – Training config.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Attention plot function.</p>
<p>Redirects to PlotAttentionReport</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>PlotAttentionReport</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>List</em><em>[</em><em>tuple</em><em>(</em><em>)</em><em>]</em>) – List of padded input sequences.
[(T1, idim), (T2, idim), …]</p></li>
<li><p><strong>ilens</strong> (<em>ndarray</em>) – Batch of lengths of input sequences. (B)</p></li>
<li><p><strong>ys</strong> (<em>List</em>) – List of character id sequence tensor. [(L1), (L2), (L3), …]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Attention weights. (B, Lmax, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.calculate_attentions">
<code class="sig-name descname">calculate_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">x_mask</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.calculate_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.calculate_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate Attentions.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.custom_converter">
<em class="property">static </em><code class="sig-name descname">custom_converter</code><span class="sig-paren">(</span><em class="sig-param">subsampling_factor=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.custom_converter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.custom_converter" title="Permalink to this definition">¶</a></dt>
<dd><p>Get customconverter of the model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.custom_parallel_updater">
<em class="property">static </em><code class="sig-name descname">custom_parallel_updater</code><span class="sig-paren">(</span><em class="sig-param">iters</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">converter</em>, <em class="sig-param">devices</em>, <em class="sig-param">accum_grad=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.custom_parallel_updater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.custom_parallel_updater" title="Permalink to this definition">¶</a></dt>
<dd><p>Get custom_parallel_updater of the model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.custom_updater">
<em class="property">static </em><code class="sig-name descname">custom_updater</code><span class="sig-paren">(</span><em class="sig-param">iters</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">converter</em>, <em class="sig-param">device=-1</em>, <em class="sig-param">accum_grad=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.custom_updater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.custom_updater" title="Permalink to this definition">¶</a></dt>
<dd><p>Get custom_updater of the model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">calculate_attentions=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>chainer.Variable</em>) – Batch of padded character ids. (B, Tmax)</p></li>
<li><p><strong>ilens</strong> (<em>chainer.Variable</em>) – Batch of length of each input batch. (B,)</p></li>
<li><p><strong>ys</strong> (<em>chainer.Variable</em>) – Batch of padded target features. (B, Lmax, odim)</p></li>
<li><p><strong>calculate_attentions</strong> (<em>bool</em>) – If true, return value is the output of encoder.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Training loss.
float (optional): Training loss for ctc.
float (optional): Training loss for attention.
float (optional): Accuracy.
chainer.Variable (Optional): Output of the encoder.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">x_block</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E recognition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – Input acouctic feature (B, T, D) or (T, D).</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – Argment namespace contraining options.</p></li>
<li><p><strong>char_list</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of characters.</p></li>
<li><p><strong>rnnlm</strong> (<em>chainer.Chain</em>) – Language model module defined at</p></li>
<li><p><strong>espnet.lm.chainer_backend.lm.</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.recognize_beam">
<code class="sig-name descname">recognize_beam</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">lpz</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.recognize_beam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.recognize_beam" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h</strong> (<em>ndarray</em>) – Encoder output features (B, T, D) or (T, D).</p></li>
<li><p><strong>lpz</strong> (<em>ndarray</em>) – Log probabilities from CTC.</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – Argment namespace contraining options.</p></li>
<li><p><strong>char_list</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of characters.</p></li>
<li><p><strong>rnnlm</strong> (<em>chainer.Chain</em>) – Language model module defined at</p></li>
<li><p><strong>espnet.lm.chainer_backend.lm.</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/e2e_asr_transformer.html#E2E.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the Weight according to the give initialize-type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> (<em>Namespace</em>) – Transformer config.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-nets-utils">
<span id="id23"></span><h2>espnet.nets.chainer_backend.nets_utils<a class="headerlink" href="#espnet-nets-chainer-backend-nets-utils" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.nets_utils"></span></section>
<section id="espnet-nets-chainer-backend-transformer-attention">
<span id="id24"></span><h2>espnet.nets.chainer_backend.transformer.attention<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-attention" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.attention"></span><p>Class Declaration of Transformer’s Attention.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.attention.MultiHeadAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.attention.</code><code class="sig-name descname">MultiHeadAttention</code><span class="sig-paren">(</span><em class="sig-param">n_units</em>, <em class="sig-param">h=8</em>, <em class="sig-param">dropout=0.1</em>, <em class="sig-param">initialW=None</em>, <em class="sig-param">initial_bias=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/attention.html#MultiHeadAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.attention.MultiHeadAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Multi Head Attention Layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_units</strong> (<em>int</em>) – Number of input units.</p></li>
<li><p><strong>h</strong> (<em>int</em>) – Number of attention heads.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>initialW</strong> – Initializer to initialize the weight.</p></li>
<li><p><strong>initial_bias</strong> – Initializer to initialize the bias.</p></li>
<li><p><strong>h</strong> – the number of heads</p></li>
<li><p><strong>n_units</strong> – the number of features</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout rate</p></li>
</ul>
</dd>
</dl>
<p>Initialize MultiHeadAttention.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.attention.MultiHeadAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">e_var</em>, <em class="sig-param">s_var=None</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">batch=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/attention.html#MultiHeadAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.attention.MultiHeadAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Core function of the Multi-head attention layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>e_var</strong> (<em>chainer.Variable</em>) – Variable of input array.</p></li>
<li><p><strong>s_var</strong> (<em>chainer.Variable</em>) – Variable of source array from encoder.</p></li>
<li><p><strong>mask</strong> (<em>chainer.Variable</em>) – Attention mask.</p></li>
<li><p><strong>batch</strong> (<em>int</em>) – Batch size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Outout of multi-head attention layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-embedding">
<span id="id25"></span><h2>espnet.nets.chainer_backend.transformer.embedding<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-embedding" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.embedding"></span><p>Class Declaration of Transformer’s Positional Encoding.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.embedding.PositionalEncoding">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.embedding.</code><code class="sig-name descname">PositionalEncoding</code><span class="sig-paren">(</span><em class="sig-param">n_units</em>, <em class="sig-param">dropout=0.1</em>, <em class="sig-param">length=5000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/embedding.html#PositionalEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.embedding.PositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Positional encoding module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_units</strong> (<em>int</em>) – embedding dim</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout rate</p></li>
<li><p><strong>length</strong> (<em>int</em>) – maximum input length</p></li>
</ul>
</dd>
</dl>
<p>Initialize Positional Encoding.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.embedding.PositionalEncoding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">e</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/embedding.html#PositionalEncoding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.embedding.PositionalEncoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward Positional Encoding.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-mask">
<span id="id26"></span><h2>espnet.nets.chainer_backend.transformer.mask<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-mask" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.mask"></span><p>Create mask for subsequent steps.</p>
<dl class="function">
<dt id="espnet.nets.chainer_backend.transformer.mask.make_history_mask">
<code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.mask.</code><code class="sig-name descname">make_history_mask</code><span class="sig-paren">(</span><em class="sig-param">xp</em>, <em class="sig-param">block</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/mask.html#make_history_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.mask.make_history_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare the history mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>block</strong> (<em>ndarray</em>) – Block with dimensions: (B x S).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>History mask with dimensions (B, S, S).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, np.ndarray</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-decoder">
<span id="id27"></span><h2>espnet.nets.chainer_backend.transformer.decoder<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-decoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.decoder"></span><p>Class Declaration of Transformer’s Decoder.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.decoder.Decoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.decoder.</code><code class="sig-name descname">Decoder</code><span class="sig-paren">(</span><em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">initialW=None</em>, <em class="sig-param">initial_bias=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/decoder.html#Decoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.decoder.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Decoder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) – Number of ecoder layers.</p></li>
<li><p><strong>n_units</strong> (<em>int</em>) – Number of attention units.</p></li>
<li><p><strong>d_units</strong> (<em>int</em>) – Dimension of input vector of decoder.</p></li>
<li><p><strong>h</strong> (<em>int</em>) – Number of attention heads.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>initialW</strong> (<em>Initializer</em>) – Initializer to initialize the weight.</p></li>
<li><p><strong>initial_bias</strong> (<em>Initializer</em>) – Initializer to initialize the bias.</p></li>
</ul>
</dd>
</dl>
<p>Initialize Decoder.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.decoder.Decoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ys_pad</em>, <em class="sig-param">source</em>, <em class="sig-param">x_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/decoder.html#Decoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.decoder.Decoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>e</strong> (<em>xp.array</em>) – input token ids, int64 (batch, maxlen_out)</p></li>
<li><p><strong>yy_mask</strong> (<em>xp.array</em>) – input token mask, uint8  (batch, maxlen_out)</p></li>
<li><p><strong>source</strong> (<em>xp.array</em>) – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>xy_mask</strong> (<em>xp.array</em>) – encoded memory mask, uint8  (batch, maxlen_in)</p></li>
</ul>
</dd>
<dt class="field-even">Return e</dt>
<dd class="field-even"><p>decoded token score before softmax (batch, maxlen_out, token)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.decoder.Decoder.make_attention_mask">
<code class="sig-name descname">make_attention_mask</code><span class="sig-paren">(</span><em class="sig-param">source_block</em>, <em class="sig-param">target_block</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/decoder.html#Decoder.make_attention_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.decoder.Decoder.make_attention_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare the attention mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source_block</strong> (<em>ndarray</em>) – Source block with dimensions: (B x S).</p></li>
<li><p><strong>target_block</strong> (<em>ndarray</em>) – Target block with dimensions: (B x T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mask with dimensions (B, S, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.decoder.Decoder.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">e</em>, <em class="sig-param">yy_mask</em>, <em class="sig-param">source</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/decoder.html#Decoder.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.decoder.Decoder.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>Process recognition function.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-encoder">
<span id="id28"></span><h2>espnet.nets.chainer_backend.transformer.encoder<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-encoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.encoder"></span><p>Class Declaration of Transformer’s Encoder.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.encoder.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.encoder.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">attention_dim=256</em>, <em class="sig-param">attention_heads=4</em>, <em class="sig-param">linear_units=2048</em>, <em class="sig-param">num_blocks=6</em>, <em class="sig-param">dropout_rate=0.1</em>, <em class="sig-param">positional_dropout_rate=0.1</em>, <em class="sig-param">attention_dropout_rate=0.0</em>, <em class="sig-param">input_layer='conv2d'</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.chainer_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">initialW=None</em>, <em class="sig-param">initial_bias=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/encoder.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.encoder.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_type</strong> (<em>str</em>) – Sampling type. <cite>input_type</cite> must be <cite>conv2d</cite> or ‘linear’ currently.</p></li>
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of inputs.</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) – Number of encoder layers.</p></li>
<li><p><strong>n_units</strong> (<em>int</em>) – Number of input/output dimension of a FeedForward layer.</p></li>
<li><p><strong>d_units</strong> (<em>int</em>) – Number of units of hidden layer in a FeedForward layer.</p></li>
<li><p><strong>h</strong> (<em>int</em>) – Number of attention heads.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout rate</p></li>
</ul>
</dd>
</dl>
<p>Initialize Encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – Training config.</p></li>
<li><p><strong>initialW</strong> (<em>int</em><em>, </em><em>optional</em>) – Initializer to initialize the weight.</p></li>
<li><p><strong>initial_bias</strong> (<em>bool</em><em>, </em><em>optional</em>) – Initializer to initialize the bias.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.encoder.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">e</em>, <em class="sig-param">ilens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/encoder.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.encoder.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Encoder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>e</strong> (<em>chainer.Variable</em>) – Batch of padded character. (B, Tmax)</p></li>
<li><p><strong>ilens</strong> (<em>chainer.Variable</em>) – Batch of length of each input batch. (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Computed variable of encoder.
numpy.array: Mask.
chainer.Variable: Batch of lengths of each encoder outputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-subsampling">
<span id="id29"></span><h2>espnet.nets.chainer_backend.transformer.subsampling<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-subsampling" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.subsampling"></span><p>Class Declaration of Transformer’s Input layers.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.subsampling.Conv2dSubsampling">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.subsampling.</code><code class="sig-name descname">Conv2dSubsampling</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">idim</em>, <em class="sig-param">dims</em>, <em class="sig-param">dropout=0.1</em>, <em class="sig-param">initialW=None</em>, <em class="sig-param">initial_bias=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/subsampling.html#Conv2dSubsampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.subsampling.Conv2dSubsampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Convolutional 2D subsampling (to 1/4 length).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – input dim</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – output dim</p></li>
<li><p><strong>dropout_rate</strong> (<em>flaot</em>) – dropout rate</p></li>
</ul>
</dd>
</dl>
<p>Initialize Conv2dSubsampling.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.subsampling.Conv2dSubsampling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/subsampling.html#Conv2dSubsampling.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.subsampling.Conv2dSubsampling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Subsample x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>chainer.Variable</em>) – input tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>subsampled x and mask</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.subsampling.LinearSampling">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.subsampling.</code><code class="sig-name descname">LinearSampling</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">dims</em>, <em class="sig-param">dropout=0.1</em>, <em class="sig-param">initialW=None</em>, <em class="sig-param">initial_bias=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/subsampling.html#LinearSampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.subsampling.LinearSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Linear 1D subsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – input dim</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – output dim</p></li>
<li><p><strong>dropout_rate</strong> (<em>flaot</em>) – dropout rate</p></li>
</ul>
</dd>
</dl>
<p>Initialize LinearSampling.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.subsampling.LinearSampling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/subsampling.html#LinearSampling.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.subsampling.LinearSampling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Subsample x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>chainer.Variable</em>) – input tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>subsampled x and mask</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-layer-norm">
<span id="id30"></span><h2>espnet.nets.chainer_backend.transformer.layer_norm<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-layer-norm" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.layer_norm"></span><p>Class Declaration of Transformer’s Label Smootion loss.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.layer_norm.LayerNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.layer_norm.</code><code class="sig-name descname">LayerNorm</code><span class="sig-paren">(</span><em class="sig-param">dims</em>, <em class="sig-param">eps=1e-12</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/layer_norm.html#LayerNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.layer_norm.LayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.links.normalization.layer_normalization.LayerNormalization</span></code></p>
<p>Redirect to L.LayerNormalization.</p>
<p>Initialize LayerNorm.</p>
</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-ctc">
<span id="id31"></span><h2>espnet.nets.chainer_backend.transformer.ctc<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-ctc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.ctc"></span><p>Class Declaration of Transformer’s CTC.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.ctc.CTC">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.ctc.</code><code class="sig-name descname">CTC</code><span class="sig-paren">(</span><em class="sig-param">odim</em>, <em class="sig-param">eprojs</em>, <em class="sig-param">dropout_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/ctc.html#CTC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.ctc.CTC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Chainer implementation of ctc layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>eprojs</strong> (<em>int | None</em>) – Dimension of input vectors from encoder.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Initialize CTC.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.ctc.CTC.log_softmax">
<code class="sig-name descname">log_softmax</code><span class="sig-paren">(</span><em class="sig-param">hs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/ctc.html#CTC.log_softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.ctc.CTC.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Log_softmax of frame activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hs</strong> (<em>list of chainer.Variable | N-dimension array</em>) – Input variable from encoder.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A n-dimension float array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.ctc.WarpCTC">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.ctc.</code><code class="sig-name descname">WarpCTC</code><span class="sig-paren">(</span><em class="sig-param">odim</em>, <em class="sig-param">eprojs</em>, <em class="sig-param">dropout_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/ctc.html#WarpCTC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.ctc.WarpCTC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Chainer implementation of warp-ctc layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>eproj</strong> (<em>int | None</em>) – Dimension of input vector from encoder.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Initialize WarpCTC.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.ctc.WarpCTC.argmax">
<code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/ctc.html#WarpCTC.argmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.ctc.WarpCTC.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Argmax of frame activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>variable hs_pad</strong> (<em>chainer</em>) – 3d tensor (B, Tmax, eprojs)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>argmax applied 2d tensor (B, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.ctc.WarpCTC.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/ctc.html#WarpCTC.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.ctc.WarpCTC.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Core function of the Warp-CTC layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs</strong> (<em>iterable of chainer.Variable | N-dimension array</em>) – Input variable from encoder.</p></li>
<li><p><strong>ys</strong> (<em>iterable of N-dimension array</em>) – Input variable of decoder.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A variable holding a scalar value of the CTC loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.ctc.WarpCTC.log_softmax">
<code class="sig-name descname">log_softmax</code><span class="sig-paren">(</span><em class="sig-param">hs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/ctc.html#WarpCTC.log_softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.ctc.WarpCTC.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Log_softmax of frame activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hs</strong> (<em>list of chainer.Variable | N-dimension array</em>) – Input variable from encoder.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A n-dimension float array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-encoder-layer">
<span id="id32"></span><h2>espnet.nets.chainer_backend.transformer.encoder_layer<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-encoder-layer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.encoder_layer"></span><p>Class Declaration of Transformer’s Encoder Block.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.encoder_layer.EncoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.encoder_layer.</code><code class="sig-name descname">EncoderLayer</code><span class="sig-paren">(</span><em class="sig-param">n_units</em>, <em class="sig-param">d_units=0</em>, <em class="sig-param">h=8</em>, <em class="sig-param">dropout=0.1</em>, <em class="sig-param">initialW=None</em>, <em class="sig-param">initial_bias=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/encoder_layer.html#EncoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.encoder_layer.EncoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Single encoder layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_units</strong> (<em>int</em>) – Number of input/output dimension of a FeedForward layer.</p></li>
<li><p><strong>d_units</strong> (<em>int</em>) – Number of units of hidden layer in a FeedForward layer.</p></li>
<li><p><strong>h</strong> (<em>int</em>) – Number of attention heads.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout rate</p></li>
</ul>
</dd>
</dl>
<p>Initialize EncoderLayer.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.encoder_layer.EncoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">e</em>, <em class="sig-param">xx_mask</em>, <em class="sig-param">batch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/encoder_layer.html#EncoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.encoder_layer.EncoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward Positional Encoding.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-init">
<span id="id33"></span><h2>espnet.nets.chainer_backend.transformer.__init__<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-chainer-backend-transformer-label-smoothing-loss">
<span id="id34"></span><h2>espnet.nets.chainer_backend.transformer.label_smoothing_loss<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-label-smoothing-loss" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.label_smoothing_loss"></span><p>Class Declaration of Transformer’s Label Smootion loss.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.label_smoothing_loss.LabelSmoothingLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.label_smoothing_loss.</code><code class="sig-name descname">LabelSmoothingLoss</code><span class="sig-paren">(</span><em class="sig-param">smoothing</em>, <em class="sig-param">n_target_vocab</em>, <em class="sig-param">normalize_length=False</em>, <em class="sig-param">ignore_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/label_smoothing_loss.html#LabelSmoothingLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.label_smoothing_loss.LabelSmoothingLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Label Smoothing Loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smoothing</strong> (<em>float</em>) – smoothing rate (0.0 means the conventional CE).</p></li>
<li><p><strong>n_target_vocab</strong> (<em>int</em>) – number of classes.</p></li>
<li><p><strong>normalize_length</strong> (<em>bool</em>) – normalize loss by sequence length if True.</p></li>
</ul>
</dd>
</dl>
<p>Initialize Loss.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.label_smoothing_loss.LabelSmoothingLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ys_block</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/label_smoothing_loss.html#LabelSmoothingLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.label_smoothing_loss.LabelSmoothingLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward Loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys_block</strong> (<em>chainer.Variable</em>) – Predicted labels.</p></li>
<li><p><strong>ys_pad</strong> (<em>chainer.Variable</em>) – Target (true) labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Training loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-positionwise-feed-forward">
<span id="id35"></span><h2>espnet.nets.chainer_backend.transformer.positionwise_feed_forward<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-positionwise-feed-forward" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.positionwise_feed_forward"></span><p>Class Declaration of Transformer’s Positionwise Feedforward.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.positionwise_feed_forward.</code><code class="sig-name descname">PositionwiseFeedForward</code><span class="sig-paren">(</span><em class="sig-param">n_units</em>, <em class="sig-param">d_units=0</em>, <em class="sig-param">dropout=0.1</em>, <em class="sig-param">initialW=None</em>, <em class="sig-param">initial_bias=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/positionwise_feed_forward.html#PositionwiseFeedForward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Positionwise feed forward.</p>
<p>:param : param int idim: input dimenstion
:param : param int hidden_units: number of hidden units
:param : param float dropout_rate: dropout rate</p>
<p>Initialize PositionwiseFeedForward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_units</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>d_units</strong> (<em>int</em><em>, </em><em>optional</em>) – Output dimension of hidden layer.</p></li>
<li><p><strong>dropout</strong> (<em>float</em><em>, </em><em>optional</em>) – Dropout ratio.</p></li>
<li><p><strong>initialW</strong> (<em>int</em><em>, </em><em>optional</em>) – Initializer to initialize the weight.</p></li>
<li><p><strong>initial_bias</strong> (<em>bool</em><em>, </em><em>optional</em>) – Initializer to initialize the bias.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-training">
<span id="id36"></span><h2>espnet.nets.chainer_backend.transformer.training<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-training" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.training"></span><p>Class Declaration of Transformer’s Training Subprocess.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.training.CustomConverter">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.training.</code><code class="sig-name descname">CustomConverter</code><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#CustomConverter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.CustomConverter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Custom Converter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>subsampling_factor</strong> (<em>int</em>) – The subsampling factor.</p>
</dd>
</dl>
<p>Initialize subsampling.</p>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.training.CustomParallelUpdater">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.training.</code><code class="sig-name descname">CustomParallelUpdater</code><span class="sig-paren">(</span><em class="sig-param">train_iters</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">converter</em>, <em class="sig-param">devices</em>, <em class="sig-param">accum_grad=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#CustomParallelUpdater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.CustomParallelUpdater" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.training.updaters.multiprocess_parallel_updater.MultiprocessParallelUpdater</span></code></p>
<p>Custom Parallel Updater for chainer.</p>
<p>Defines the main update routine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_iter</strong> (<em>iterator | dict</em><em>[</em><em>str</em><em>, </em><em>iterator</em><em>]</em>) – Dataset iterator for the
training dataset. It can also be a dictionary that maps strings to
iterators. If this is just an iterator, then the iterator is
registered by the name <code class="docutils literal notranslate"><span class="pre">'main'</span></code>.</p></li>
<li><p><strong>optimizer</strong> (<em>optimizer | dict</em><em>[</em><em>str</em><em>, </em><em>optimizer</em><em>]</em>) – Optimizer to update
parameters. It can also be a dictionary that maps strings to
optimizers. If this is just an optimizer, then the optimizer is
registered by the name <code class="docutils literal notranslate"><span class="pre">'main'</span></code>.</p></li>
<li><p><strong>converter</strong> (<em>espnet.asr.chainer_backend.asr.CustomConverter</em>) – Converter
function to build input arrays. Each batch extracted by the main
iterator and the <code class="docutils literal notranslate"><span class="pre">device</span></code> option are passed to this function.
<code class="xref py py-func docutils literal notranslate"><span class="pre">chainer.dataset.concat_examples()</span></code> is used by default.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em>) – Device to which the training data is sent. Negative value
indicates the host memory (CPU).</p></li>
<li><p><strong>accum_grad</strong> (<em>int</em>) – The number of gradient accumulation. if set to 2, the network
parameters will be updated once in twice,
i.e. actual batchsize will be doubled.</p></li>
</ul>
</dd>
</dl>
<p>Initialize custom parallel updater.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.training.CustomParallelUpdater.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#CustomParallelUpdater.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.CustomParallelUpdater.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update step for Custom Parallel Updater.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.training.CustomParallelUpdater.update_core">
<code class="sig-name descname">update_core</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#CustomParallelUpdater.update_core"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.CustomParallelUpdater.update_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Process main update routine for Custom Parallel Updater.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.training.CustomUpdater">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.training.</code><code class="sig-name descname">CustomUpdater</code><span class="sig-paren">(</span><em class="sig-param">train_iter</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">converter</em>, <em class="sig-param">device</em>, <em class="sig-param">accum_grad=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#CustomUpdater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.CustomUpdater" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.training.updaters.standard_updater.StandardUpdater</span></code></p>
<p>Custom updater for chainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_iter</strong> (<em>iterator | dict</em><em>[</em><em>str</em><em>, </em><em>iterator</em><em>]</em>) – Dataset iterator for the
training dataset. It can also be a dictionary that maps strings to
iterators. If this is just an iterator, then the iterator is
registered by the name <code class="docutils literal notranslate"><span class="pre">'main'</span></code>.</p></li>
<li><p><strong>optimizer</strong> (<em>optimizer | dict</em><em>[</em><em>str</em><em>, </em><em>optimizer</em><em>]</em>) – Optimizer to update
parameters. It can also be a dictionary that maps strings to
optimizers. If this is just an optimizer, then the optimizer is
registered by the name <code class="docutils literal notranslate"><span class="pre">'main'</span></code>.</p></li>
<li><p><strong>converter</strong> (<em>espnet.asr.chainer_backend.asr.CustomConverter</em>) – Converter
function to build input arrays. Each batch extracted by the main
iterator and the <code class="docutils literal notranslate"><span class="pre">device</span></code> option are passed to this function.
<code class="xref py py-func docutils literal notranslate"><span class="pre">chainer.dataset.concat_examples()</span></code> is used by default.</p></li>
<li><p><strong>device</strong> (<em>int</em><em> or </em><em>dict</em>) – The destination device info to send variables. In the
case of cpu or single gpu, <cite>device=-1 or 0</cite>, respectively.
In the case of multi-gpu, <cite>device={“main”:0, “sub_1”: 1, …}</cite>.</p></li>
<li><p><strong>accum_grad</strong> (<em>int</em>) – The number of gradient accumulation. if set to 2, the network
parameters will be updated once in twice,
i.e. actual batchsize will be doubled.</p></li>
</ul>
</dd>
</dl>
<p>Initialize Custom Updater.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.training.CustomUpdater.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#CustomUpdater.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.CustomUpdater.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update step for Custom Updater.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.training.CustomUpdater.update_core">
<code class="sig-name descname">update_core</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#CustomUpdater.update_core"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.CustomUpdater.update_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Process main update routine for Custom Updater.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.training.VaswaniRule">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.training.</code><code class="sig-name descname">VaswaniRule</code><span class="sig-paren">(</span><em class="sig-param">attr</em>, <em class="sig-param">d</em>, <em class="sig-param">warmup_steps=4000</em>, <em class="sig-param">init=None</em>, <em class="sig-param">target=None</em>, <em class="sig-param">optimizer=None</em>, <em class="sig-param">scale=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#VaswaniRule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.VaswaniRule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.training.extension.Extension</span></code></p>
<p>Trainer extension to shift an optimizer attribute magically by Vaswani.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr</strong> (<em>str</em>) – Name of the attribute to shift.</p></li>
<li><p><strong>rate</strong> (<em>float</em>) – Rate of the exponential shift. This value is multiplied
to the attribute at each call.</p></li>
<li><p><strong>init</strong> (<em>float</em>) – Initial value of the attribute. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the
extension extracts the attribute at the first call and uses it as
the initial value.</p></li>
<li><p><strong>target</strong> (<em>float</em>) – Target value of the attribute. If the attribute reaches
this value, the shift stops.</p></li>
<li><p><strong>optimizer</strong> (<em>Optimizer</em>) – Target optimizer to adjust the
attribute. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the main optimizer of the updater is
used.</p></li>
</ul>
</dd>
</dl>
<p>Initialize Vaswani rule extension.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.training.VaswaniRule.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">trainer</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#VaswaniRule.initialize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.VaswaniRule.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize Optimizer values.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.training.VaswaniRule.serialize">
<code class="sig-name descname">serialize</code><span class="sig-paren">(</span><em class="sig-param">serializer</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#VaswaniRule.serialize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.VaswaniRule.serialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Serialize extension.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.transformer.training.sum_sqnorm">
<code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.training.</code><code class="sig-name descname">sum_sqnorm</code><span class="sig-paren">(</span><em class="sig-param">arr</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/training.html#sum_sqnorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.training.sum_sqnorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the norm of the array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>arr</strong> (<em>numpy.ndarray</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Sum of the norm calculated from the given array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Float</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-transformer-decoder-layer">
<span id="id37"></span><h2>espnet.nets.chainer_backend.transformer.decoder_layer<a class="headerlink" href="#espnet-nets-chainer-backend-transformer-decoder-layer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.transformer.decoder_layer"></span><p>Class Declaration of Transformer’s Decoder Block.</p>
<dl class="class">
<dt id="espnet.nets.chainer_backend.transformer.decoder_layer.DecoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.transformer.decoder_layer.</code><code class="sig-name descname">DecoderLayer</code><span class="sig-paren">(</span><em class="sig-param">n_units</em>, <em class="sig-param">d_units=0</em>, <em class="sig-param">h=8</em>, <em class="sig-param">dropout=0.1</em>, <em class="sig-param">initialW=None</em>, <em class="sig-param">initial_bias=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/decoder_layer.html#DecoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.decoder_layer.DecoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Single decoder layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_units</strong> (<em>int</em>) – Number of input/output dimension of a FeedForward layer.</p></li>
<li><p><strong>d_units</strong> (<em>int</em>) – Number of units of hidden layer in a FeedForward layer.</p></li>
<li><p><strong>h</strong> (<em>int</em>) – Number of attention heads.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout rate</p></li>
</ul>
</dd>
</dl>
<p>Initialize DecoderLayer.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.transformer.decoder_layer.DecoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">e</em>, <em class="sig-param">s</em>, <em class="sig-param">xy_mask</em>, <em class="sig-param">yy_mask</em>, <em class="sig-param">batch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/transformer/decoder_layer.html#DecoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.transformer.decoder_layer.DecoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Encoder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>e</strong> (<em>chainer.Variable</em>) – Batch of padded features. (B, Lmax)</p></li>
<li><p><strong>s</strong> (<em>chainer.Variable</em>) – Batch of padded character. (B, Tmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Computed variable of decoder.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-rnn-init">
<span id="id38"></span><h2>espnet.nets.chainer_backend.rnn.__init__<a class="headerlink" href="#espnet-nets-chainer-backend-rnn-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.rnn.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-chainer-backend-rnn-attentions">
<span id="id39"></span><h2>espnet.nets.chainer_backend.rnn.attentions<a class="headerlink" href="#espnet-nets-chainer-backend-rnn-attentions" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.rnn.attentions"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.attentions.AttDot">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.attentions.</code><code class="sig-name descname">AttDot</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/attentions.html#AttDot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.attentions.AttDot" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Compute attention based on dot product.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int | None</em>) – Dimension of input vectors from encoder.</p></li>
<li><p><strong>dunits</strong> (<em>int | None</em>) – Dimension of input vectors for decoder.</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – Dimension of input vectors for attention.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.attentions.AttDot.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/attentions.html#AttDot.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.attentions.AttDot.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset states.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.attentions.AttLoc">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.attentions.</code><code class="sig-name descname">AttLoc</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/attentions.html#AttLoc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.attentions.AttLoc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Compute location-based attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int | None</em>) – Dimension of input vectors from encoder.</p></li>
<li><p><strong>dunits</strong> (<em>int | None</em>) – Dimension of input vectors for decoder.</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – Dimension of input vectors for attention.</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – Number of channels of output arrays from convolutional layer.</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – Size of filters of convolutional layer.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.attentions.AttLoc.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/attentions.html#AttLoc.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.attentions.AttLoc.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset states.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.attentions.NoAtt">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.attentions.</code><code class="sig-name descname">NoAtt</code><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/attentions.html#NoAtt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.attentions.NoAtt" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Compute non-attention layer.</p>
<p>This layer is a dummy attention layer to be compatible with other
attention-based models.</p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.attentions.NoAtt.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/attentions.html#NoAtt.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.attentions.NoAtt.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset states.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.rnn.attentions.att_for">
<code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.attentions.</code><code class="sig-name descname">att_for</code><span class="sig-paren">(</span><em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/attentions.html#att_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.attentions.att_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an attention layer given the program arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> (<em>Namespace</em>) – The arguments.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The corresponding attention module.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Chain</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-rnn-decoders">
<span id="id40"></span><h2>espnet.nets.chainer_backend.rnn.decoders<a class="headerlink" href="#espnet-nets-chainer-backend-rnn-decoders" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.rnn.decoders"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.decoders.Decoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.decoders.</code><code class="sig-name descname">Decoder</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">odim</em>, <em class="sig-param">dtype</em>, <em class="sig-param">dlayers</em>, <em class="sig-param">dunits</em>, <em class="sig-param">sos</em>, <em class="sig-param">eos</em>, <em class="sig-param">att</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">labeldist=None</em>, <em class="sig-param">lsm_weight=0.0</em>, <em class="sig-param">sampling_probability=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/decoders.html#Decoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.decoders.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Decoder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – Dimension of input variables from encoder.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>dtype</strong> (<em>str</em>) – Decoder type.</p></li>
<li><p><strong>dlayers</strong> (<em>int</em>) – Number of layers for decoder.</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – Dimension of input vector of decoder.</p></li>
<li><p><strong>sos</strong> (<em>int</em>) – Number to indicate the start of sequences.</p></li>
<li><p><strong>eos</strong> (<em>int</em>) – Number to indicate the end of sequences.</p></li>
<li><p><strong>att</strong> (<em>Module</em>) – Attention module defined at
<cite>espnet.espnet.nets.chainer_backend.attentions</cite>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level.</p></li>
<li><p><strong>char_list</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of all characters.</p></li>
<li><p><strong>labeldist</strong> (<em>numpy.array</em>) – Distributed array of counted transcript length.</p></li>
<li><p><strong>lsm_weight</strong> (<em>float</em>) – Weight to use when calculating the training loss.</p></li>
<li><p><strong>sampling_probability</strong> (<em>float</em>) – Threshold for scheduled sampling.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.decoders.Decoder.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">hs</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/decoders.html#Decoder.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.decoders.Decoder.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all of attentions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs</strong> (<em>list of chainer.Variable | N-dimensional array</em>) – Input variable from encoder.</p></li>
<li><p><strong>ys</strong> (<em>list of chainer.Variable | N-dimensional array</em>) – Input variable of decoder.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of attention weights.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Variable</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.decoders.Decoder.recognize_beam">
<code class="sig-name descname">recognize_beam</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">lpz</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/decoders.html#Decoder.recognize_beam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.decoders.Decoder.recognize_beam" title="Permalink to this definition">¶</a></dt>
<dd><p>Beam search implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h</strong> (<em>chainer.Variable</em>) – One of the output from the encoder.</p></li>
<li><p><strong>lpz</strong> (<em>chainer.Variable | None</em>) – Result of net propagation.</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – The argument.</p></li>
<li><p><strong>char_list</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of all characters.</p></li>
<li><p><strong>rnnlm</strong> (<em>Module</em>) – RNNLM module. Defined at <cite>espnet.lm.chainer_backend.lm</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Result of recognition.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[Dict[str,Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.decoders.Decoder.rnn_forward">
<code class="sig-name descname">rnn_forward</code><span class="sig-paren">(</span><em class="sig-param">ey</em>, <em class="sig-param">z_list</em>, <em class="sig-param">c_list</em>, <em class="sig-param">z_prev</em>, <em class="sig-param">c_prev</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/decoders.html#Decoder.rnn_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.decoders.Decoder.rnn_forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.rnn.decoders.decoder_for">
<code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.decoders.</code><code class="sig-name descname">decoder_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">odim</em>, <em class="sig-param">sos</em>, <em class="sig-param">eos</em>, <em class="sig-param">att</em>, <em class="sig-param">labeldist</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/decoders.html#decoder_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.decoders.decoder_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the decoding layer corresponding to the args.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>Namespace</em>) – The program arguments.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>sos</strong> (<em>int</em>) – Number to indicate the start of sequences.</p></li>
<li><p><strong>eos</strong> (<em>int</em>) – </p></li>
<li><p><strong>att</strong> (<em>Module</em>) – Attention module defined at <cite>espnet.nets.chainer_backend.attentions</cite>.</p></li>
<li><p><strong>labeldist</strong> (<em>numpy.array</em>) – Distributed array of length od transcript.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The decoder module.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>chainer.Chain</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-rnn-encoders">
<span id="id41"></span><h2>espnet.nets.chainer_backend.rnn.encoders<a class="headerlink" href="#espnet-nets-chainer-backend-rnn-encoders" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.rnn.encoders"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.encoders.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.encoders.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">etype</em>, <em class="sig-param">idim</em>, <em class="sig-param">elayers</em>, <em class="sig-param">eunits</em>, <em class="sig-param">eprojs</em>, <em class="sig-param">subsample</em>, <em class="sig-param">dropout</em>, <em class="sig-param">in_channel=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/encoders.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.encoders.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Encoder network class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>etype</strong> (<em>str</em>) – Type of encoder network.</p></li>
<li><p><strong>idim</strong> (<em>int</em>) – Number of dimensions of encoder network.</p></li>
<li><p><strong>elayers</strong> (<em>int</em>) – Number of layers of encoder network.</p></li>
<li><p><strong>eunits</strong> (<em>int</em>) – Number of lstm units of encoder network.</p></li>
<li><p><strong>eprojs</strong> (<em>int</em>) – Number of projection units of encoder network.</p></li>
<li><p><strong>subsample</strong> (<em>np.array</em>) – Subsampling number. e.g. 1_2_2_2_1</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.encoders.RNN">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.encoders.</code><code class="sig-name descname">RNN</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">elayers</em>, <em class="sig-param">cdim</em>, <em class="sig-param">hdim</em>, <em class="sig-param">dropout</em>, <em class="sig-param">typ='lstm'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/encoders.html#RNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.encoders.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>RNN Module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the imput.</p></li>
<li><p><strong>elayers</strong> (<em>int</em>) – Number of encoder layers.</p></li>
<li><p><strong>cdim</strong> (<em>int</em>) – Number of rnn units.</p></li>
<li><p><strong>hdim</strong> (<em>int</em>) – Number of projection units.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>typ</strong> (<em>str</em>) – Rnn type.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.encoders.RNNP">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.encoders.</code><code class="sig-name descname">RNNP</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">elayers</em>, <em class="sig-param">cdim</em>, <em class="sig-param">hdim</em>, <em class="sig-param">subsample</em>, <em class="sig-param">dropout</em>, <em class="sig-param">typ='blstm'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/encoders.html#RNNP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.encoders.RNNP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>RNN with projection layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of inputs.</p></li>
<li><p><strong>elayers</strong> (<em>int</em>) – Number of encoder layers.</p></li>
<li><p><strong>cdim</strong> (<em>int</em>) – Number of rnn units. (resulted in cdim * 2 if bidirectional)</p></li>
<li><p><strong>hdim</strong> (<em>int</em>) – Number of projection units.</p></li>
<li><p><strong>subsample</strong> (<em>np.ndarray</em>) – List to use sabsample the input array.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>typ</strong> (<em>str</em>) – The RNN type.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.encoders.VGG2L">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.encoders.</code><code class="sig-name descname">VGG2L</code><span class="sig-paren">(</span><em class="sig-param">in_channel=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/encoders.html#VGG2L"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.encoders.VGG2L" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>VGG motibated cnn layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>in_channel</strong> (<em>int</em>) – Number of channels.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.rnn.encoders.encoder_for">
<code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.encoders.</code><code class="sig-name descname">encoder_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">idim</em>, <em class="sig-param">subsample</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/encoders.html#encoder_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.encoders.encoder_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the Encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of input array.</p></li>
<li><p><strong>subsample</strong> (<em>numpy.array</em>) – Subsample number. egs).1_2_2_2_1</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Return</dt><dd><p>chainer.nn.Module: Encoder module.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-chainer-backend-rnn-training">
<span id="id42"></span><h2>espnet.nets.chainer_backend.rnn.training<a class="headerlink" href="#espnet-nets-chainer-backend-rnn-training" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.rnn.training"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.training.CustomConverter">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.training.</code><code class="sig-name descname">CustomConverter</code><span class="sig-paren">(</span><em class="sig-param">subsampling_factor=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/training.html#CustomConverter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.training.CustomConverter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Custom Converter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>subsampling_factor</strong> (<em>int</em>) – The subsampling factor.</p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.training.CustomParallelUpdater">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.training.</code><code class="sig-name descname">CustomParallelUpdater</code><span class="sig-paren">(</span><em class="sig-param">train_iters</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">converter</em>, <em class="sig-param">devices</em>, <em class="sig-param">accum_grad=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/training.html#CustomParallelUpdater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.training.CustomParallelUpdater" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.training.updaters.multiprocess_parallel_updater.MultiprocessParallelUpdater</span></code></p>
<p>Custom Parallel Updater for chainer.</p>
<p>Defines the main update routine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_iter</strong> (<em>iterator | dict</em><em>[</em><em>str</em><em>, </em><em>iterator</em><em>]</em>) – Dataset iterator for the
training dataset. It can also be a dictionary that maps strings to
iterators. If this is just an iterator, then the iterator is
registered by the name <code class="docutils literal notranslate"><span class="pre">'main'</span></code>.</p></li>
<li><p><strong>optimizer</strong> (<em>optimizer | dict</em><em>[</em><em>str</em><em>, </em><em>optimizer</em><em>]</em>) – Optimizer to update
parameters. It can also be a dictionary that maps strings to
optimizers. If this is just an optimizer, then the optimizer is
registered by the name <code class="docutils literal notranslate"><span class="pre">'main'</span></code>.</p></li>
<li><p><strong>converter</strong> (<em>espnet.asr.chainer_backend.asr.CustomConverter</em>) – Converter
function to build input arrays. Each batch extracted by the main
iterator and the <code class="docutils literal notranslate"><span class="pre">device</span></code> option are passed to this function.
<code class="xref py py-func docutils literal notranslate"><span class="pre">chainer.dataset.concat_examples()</span></code> is used by default.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em>) – Device to which the training data is sent.
Negative value
indicates the host memory (CPU).</p></li>
<li><p><strong>accum_grad</strong> (<em>int</em>) – The number of gradient accumulation. if set to 2,
the network parameters will be updated once in twice,
i.e. actual batchsize will be doubled.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.training.CustomParallelUpdater.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/training.html#CustomParallelUpdater.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.training.CustomParallelUpdater.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the parameters of the target model.</p>
<p>This method implements an update formula for the training task,
including data loading, forward/backward computations, and actual
updates of parameters.</p>
<p>This method is called once at each iteration of the training loop.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.training.CustomParallelUpdater.update_core">
<code class="sig-name descname">update_core</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/training.html#CustomParallelUpdater.update_core"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.training.CustomParallelUpdater.update_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Main Update routine of the custom parallel updater.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.rnn.training.CustomUpdater">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.training.</code><code class="sig-name descname">CustomUpdater</code><span class="sig-paren">(</span><em class="sig-param">train_iter</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">converter</em>, <em class="sig-param">device</em>, <em class="sig-param">accum_grad=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/training.html#CustomUpdater"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.training.CustomUpdater" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.training.updaters.standard_updater.StandardUpdater</span></code></p>
<p>Custom updater for chainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_iter</strong> (<em>iterator | dict</em><em>[</em><em>str</em><em>, </em><em>iterator</em><em>]</em>) – Dataset iterator for the
training dataset. It can also be a dictionary that maps strings to
iterators. If this is just an iterator, then the iterator is
registered by the name <code class="docutils literal notranslate"><span class="pre">'main'</span></code>.</p></li>
<li><p><strong>optimizer</strong> (<em>optimizer | dict</em><em>[</em><em>str</em><em>, </em><em>optimizer</em><em>]</em>) – Optimizer to update
parameters. It can also be a dictionary that maps strings to
optimizers. If this is just an optimizer, then the optimizer is
registered by the name <code class="docutils literal notranslate"><span class="pre">'main'</span></code>.</p></li>
<li><p><strong>converter</strong> (<em>espnet.asr.chainer_backend.asr.CustomConverter</em>) – Converter
function to build input arrays. Each batch extracted by the main
iterator and the <code class="docutils literal notranslate"><span class="pre">device</span></code> option are passed to this function.
<code class="xref py py-func docutils literal notranslate"><span class="pre">chainer.dataset.concat_examples()</span></code> is used by default.</p></li>
<li><p><strong>device</strong> (<em>int</em><em> or </em><em>dict</em>) – The destination device info to send variables. In the
case of cpu or single gpu, <cite>device=-1 or 0</cite>, respectively.
In the case of multi-gpu, <cite>device={“main”:0, “sub_1”: 1, …}</cite>.</p></li>
<li><p><strong>accum_grad</strong> (<em>int</em>) – The number of gradient accumulation. if set to 2, the network
parameters will be updated once in twice,
i.e. actual batchsize will be doubled.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.training.CustomUpdater.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/training.html#CustomUpdater.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.training.CustomUpdater.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the parameters of the target model.</p>
<p>This method implements an update formula for the training task,
including data loading, forward/backward computations, and actual
updates of parameters.</p>
<p>This method is called once at each iteration of the training loop.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.rnn.training.CustomUpdater.update_core">
<code class="sig-name descname">update_core</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/training.html#CustomUpdater.update_core"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.training.CustomUpdater.update_core" title="Permalink to this definition">¶</a></dt>
<dd><p>Main update routine for Custom Updater.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.rnn.training.sum_sqnorm">
<code class="sig-prename descclassname">espnet.nets.chainer_backend.rnn.training.</code><code class="sig-name descname">sum_sqnorm</code><span class="sig-paren">(</span><em class="sig-param">arr</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/chainer_backend/rnn/training.html#sum_sqnorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.chainer_backend.rnn.training.sum_sqnorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the norm of the array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>arr</strong> (<em>numpy.ndarray</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Sum of the norm calculated from the given array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Float</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-scorers-length-bonus">
<span id="id43"></span><h2>espnet.nets.scorers.length_bonus<a class="headerlink" href="#espnet-nets-scorers-length-bonus" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.scorers.length_bonus"></span><p>Length bonus module.</p>
<dl class="class">
<dt id="espnet.nets.scorers.length_bonus.LengthBonus">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.scorers.length_bonus.</code><code class="sig-name descname">LengthBonus</code><span class="sig-paren">(</span><em class="sig-param">n_vocab: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/length_bonus.html#LengthBonus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.length_bonus.LengthBonus" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a></p>
<p>Length bonus in beam search.</p>
<p>Initialize class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n_vocab</strong> (<em>int</em>) – The number of tokens in vocabulary for beam search</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.scorers.length_bonus.LengthBonus.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet/nets/scorers/length_bonus.html#LengthBonus.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.length_bonus.LengthBonus.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorers.length_bonus.LengthBonus.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/length_bonus.html#LengthBonus.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.length_bonus.LengthBonus.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</p></li>
<li><p><strong>state</strong> – Scorer state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – 2D encoder feature that generates ys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>torch.float32 scores for next token (n_vocab)
and None</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-scorers-ngram">
<span id="id44"></span><h2>espnet.nets.scorers.ngram<a class="headerlink" href="#espnet-nets-scorers-ngram" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.scorers.ngram"></span><p>Ngram lm implement.</p>
<dl class="class">
<dt id="espnet.nets.scorers.ngram.NgramFullScorer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.scorers.ngram.</code><code class="sig-name descname">NgramFullScorer</code><span class="sig-paren">(</span><em class="sig-param">ngram_model</em>, <em class="sig-param">token_list</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ngram.html#NgramFullScorer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ngram.NgramFullScorer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorers.ngram.Ngrambase" title="espnet.nets.scorers.ngram.Ngrambase"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorers.ngram.Ngrambase</span></code></a>, <a class="reference internal" href="#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a></p>
<p>Fullscorer for ngram.</p>
<p>Initialize Ngrambase.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ngram_model</strong> – ngram model path</p></li>
<li><p><strong>token_list</strong> – token list from dict or model.json</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.scorers.ngram.NgramFullScorer.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ngram.html#NgramFullScorer.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ngram.NgramFullScorer.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score interface for both full and partial scorer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> – previous char</p></li>
<li><p><strong>state</strong> – previous state</p></li>
<li><p><strong>x</strong> – encoded feature</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.scorers.ngram.NgramPartScorer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.scorers.ngram.</code><code class="sig-name descname">NgramPartScorer</code><span class="sig-paren">(</span><em class="sig-param">ngram_model</em>, <em class="sig-param">token_list</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ngram.html#NgramPartScorer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ngram.NgramPartScorer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorers.ngram.Ngrambase" title="espnet.nets.scorers.ngram.Ngrambase"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorers.ngram.Ngrambase</span></code></a>, <a class="reference internal" href="#espnet.nets.scorer_interface.PartialScorerInterface" title="espnet.nets.scorer_interface.PartialScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.PartialScorerInterface</span></code></a></p>
<p>Partialscorer for ngram.</p>
<p>Initialize Ngrambase.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ngram_model</strong> – ngram model path</p></li>
<li><p><strong>token_list</strong> – token list from dict or model.json</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.scorers.ngram.NgramPartScorer.score_partial">
<code class="sig-name descname">score_partial</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">next_token</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ngram.html#NgramPartScorer.score_partial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ngram.NgramPartScorer.score_partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Score interface for both full and partial scorer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> – previous char</p></li>
<li><p><strong>next_token</strong> – next token need to be score</p></li>
<li><p><strong>state</strong> – previous state</p></li>
<li><p><strong>x</strong> – encoded feature</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorers.ngram.NgramPartScorer.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">i</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ngram.html#NgramPartScorer.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ngram.NgramPartScorer.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Empty select state for scorer interface.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.scorers.ngram.Ngrambase">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.scorers.ngram.</code><code class="sig-name descname">Ngrambase</code><span class="sig-paren">(</span><em class="sig-param">ngram_model</em>, <em class="sig-param">token_list</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ngram.html#Ngrambase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ngram.Ngrambase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Ngram base implemented through ScorerInterface.</p>
<p>Initialize Ngrambase.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ngram_model</strong> – ngram model path</p></li>
<li><p><strong>token_list</strong> – token list from dict or model.json</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.scorers.ngram.Ngrambase.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ngram.html#Ngrambase.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ngram.Ngrambase.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize tmp state.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorers.ngram.Ngrambase.score_partial_">
<code class="sig-name descname">score_partial_</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">next_token</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ngram.html#Ngrambase.score_partial_"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ngram.Ngrambase.score_partial_" title="Permalink to this definition">¶</a></dt>
<dd><p>Score interface for both full and partial scorer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> – previous char</p></li>
<li><p><strong>next_token</strong> – next token need to be score</p></li>
<li><p><strong>state</strong> – previous state</p></li>
<li><p><strong>x</strong> – encoded feature</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-scorers-ctc">
<span id="id45"></span><h2>espnet.nets.scorers.ctc<a class="headerlink" href="#espnet-nets-scorers-ctc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.scorers.ctc"></span><p>ScorerInterface implementation for CTC.</p>
<dl class="class">
<dt id="espnet.nets.scorers.ctc.CTCPrefixScorer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.scorers.ctc.</code><code class="sig-name descname">CTCPrefixScorer</code><span class="sig-paren">(</span><em class="sig-param">ctc: torch.nn.modules.module.Module</em>, <em class="sig-param">eos: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ctc.html#CTCPrefixScorer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ctc.CTCPrefixScorer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorer_interface.BatchPartialScorerInterface" title="espnet.nets.scorer_interface.BatchPartialScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchPartialScorerInterface</span></code></a></p>
<p>Decoder interface wrapper for CTCPrefixScore.</p>
<p>Initialize class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ctc</strong> (<em>torch.nn.Module</em>) – The CTC implementation.
For example, <a class="reference internal" href="#espnet.nets.pytorch_backend.ctc.CTC" title="espnet.nets.pytorch_backend.ctc.CTC"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.ctc.CTC</span></code></a></p></li>
<li><p><strong>eos</strong> (<em>int</em>) – The end-of-sequence id.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.scorers.ctc.CTCPrefixScorer.batch_init_state">
<code class="sig-name descname">batch_init_state</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ctc.html#CTCPrefixScorer.batch_init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ctc.CTCPrefixScorer.batch_init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an initial state for decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoded feature tensor</p>
</dd>
</dl>
<p>Returns: initial state</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorers.ctc.CTCPrefixScorer.batch_score_partial">
<code class="sig-name descname">batch_score_partial</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">ids</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ctc.html#CTCPrefixScorer.batch_score_partial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ctc.CTCPrefixScorer.batch_score_partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D prefix token</p></li>
<li><p><strong>ids</strong> (<em>torch.Tensor</em>) – torch.int64 next token to score</p></li>
<li><p><strong>state</strong> – decoder state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – 2D encoder feature that generates ys</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of a score tensor for y that has a shape <cite>(len(next_tokens),)</cite>
and next state for ys</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorers.ctc.CTCPrefixScorer.extend_prob">
<code class="sig-name descname">extend_prob</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ctc.html#CTCPrefixScorer.extend_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ctc.CTCPrefixScorer.extend_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Extend probs for decoding.</p>
<p>This extension is for streaming decoding
as in Eq (14) in <a class="reference external" href="https://arxiv.org/abs/2006.14941">https://arxiv.org/abs/2006.14941</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoded feature tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorers.ctc.CTCPrefixScorer.extend_state">
<code class="sig-name descname">extend_state</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ctc.html#CTCPrefixScorer.extend_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ctc.CTCPrefixScorer.extend_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Extend state for decoding.</p>
<p>This extension is for streaming decoding
as in Eq (14) in <a class="reference external" href="https://arxiv.org/abs/2006.14941">https://arxiv.org/abs/2006.14941</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> – The states of hyps</p>
</dd>
</dl>
<p>Returns: exteded state</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorers.ctc.CTCPrefixScorer.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ctc.html#CTCPrefixScorer.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ctc.CTCPrefixScorer.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an initial state for decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoded feature tensor</p>
</dd>
</dl>
<p>Returns: initial state</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorers.ctc.CTCPrefixScorer.score_partial">
<code class="sig-name descname">score_partial</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">ids</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ctc.html#CTCPrefixScorer.score_partial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ctc.CTCPrefixScorer.score_partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D prefix token</p></li>
<li><p><strong>next_tokens</strong> (<em>torch.Tensor</em>) – torch.int64 next token to score</p></li>
<li><p><strong>state</strong> – decoder state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – 2D encoder feature that generates ys</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of a score tensor for y that has a shape <cite>(len(next_tokens),)</cite>
and next state for ys</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.scorers.ctc.CTCPrefixScorer.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">i</em>, <em class="sig-param">new_id=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/scorers/ctc.html#CTCPrefixScorer.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.scorers.ctc.CTCPrefixScorer.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Select state with relative ids in the main beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state</strong> – Decoder state for prefix tokens</p></li>
<li><p><strong>i</strong> (<em>int</em>) – Index to select a state in the main beam search</p></li>
<li><p><strong>new_id</strong> (<em>int</em>) – New label id to select a state if necessary</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>pruned state</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>state</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-scorers-init">
<span id="id46"></span><h2>espnet.nets.scorers.__init__<a class="headerlink" href="#espnet-nets-scorers-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.scorers.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-initialization">
<span id="id47"></span><h2>espnet.nets.pytorch_backend.initialization<a class="headerlink" href="#espnet-nets-pytorch-backend-initialization" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.initialization"></span><p>Initialization functions for RNN sequence-to-sequence models.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.initialization.lecun_normal_init_parameters">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.initialization.</code><code class="sig-name descname">lecun_normal_init_parameters</code><span class="sig-paren">(</span><em class="sig-param">module</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/initialization.html#lecun_normal_init_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.initialization.lecun_normal_init_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize parameters in the LeCun’s manner.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.initialization.set_forget_bias_to_one">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.initialization.</code><code class="sig-name descname">set_forget_bias_to_one</code><span class="sig-paren">(</span><em class="sig-param">bias</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/initialization.html#set_forget_bias_to_one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.initialization.set_forget_bias_to_one" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a bias vector in the forget gate with one.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.initialization.uniform_init_parameters">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.initialization.</code><code class="sig-name descname">uniform_init_parameters</code><span class="sig-paren">(</span><em class="sig-param">module</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/initialization.html#uniform_init_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.initialization.uniform_init_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize parameters with an uniform distribution.</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-asr-conformer">
<span id="id48"></span><h2>espnet.nets.pytorch_backend.e2e_asr_conformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr-conformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr_conformer"></span><p>Conformer speech recognition model (pytorch).</p>
<p>It is a fusion of <cite>e2e_asr_transformer.py</cite>
Refer to: <a class="reference external" href="https://arxiv.org/abs/2005.08100">https://arxiv.org/abs/2005.08100</a></p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_conformer.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_conformer.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">ignore_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_conformer.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_conformer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E" title="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.e2e_asr_transformer.E2E</span></code></a></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_conformer.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_conformer.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_conformer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_conformer.E2E.add_conformer_arguments">
<em class="property">static </em><code class="sig-name descname">add_conformer_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_conformer.html#E2E.add_conformer_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_conformer.E2E.add_conformer_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for conformer model.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-mt-transformer">
<span id="id49"></span><h2>espnet.nets.pytorch_backend.e2e_mt_transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-mt-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_mt_transformer"></span><p>Transformer text translation model (pytorch).</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_mt_transformer.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">ignore_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt_transformer.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.mt_interface.MTInterface" title="espnet.nets.mt_interface.MTInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.mt_interface.MTInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt_transformer.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Return PlotAttentionReport.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt_transformer.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weights (B, H, Lmax, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt_transformer.html#E2E.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source sentences.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt_transformer.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of source sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>attention loss value</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>accuracy in attention decoder</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt_transformer.html#E2E.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize parameters.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.scorers">
<code class="sig-name descname">scorers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt_transformer.html#E2E.scorers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.scorers" title="Permalink to this definition">¶</a></dt>
<dd><p>Scorers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.target_forcing">
<code class="sig-name descname">target_forcing</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ys_pad=None</em>, <em class="sig-param">tgt_lang=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt_transformer.html#E2E.target_forcing"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.target_forcing" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepend target language IDs to source sentences for multilingual MT.</p>
<p>These tags are prepended in source/target sentences as pre-processing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>source text without language IDs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>target text without language IDs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>target language IDs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor (B, 1)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.translate">
<code class="sig-name descname">translate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt_transformer.html#E2E.translate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt_transformer.E2E.translate" title="Permalink to this definition">¶</a></dt>
<dd><p>Translate source text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>list</em>) – input source text feature (T,)</p></li>
<li><p><strong>trans_args</strong> (<em>Namespace</em>) – argment Namespace contraining options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-asr-mix-transformer">
<span id="id50"></span><h2>espnet.nets.pytorch_backend.e2e_asr_mix_transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr-mix-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr_mix_transformer"></span><p>Transformer speech recognition model for single-channel multi-speaker mixture speech.</p>
<dl class="simple">
<dt>It is a fusion of <cite>e2e_asr_mix.py</cite> and <cite>e2e_asr_transformer.py</cite>. Refer to:</dt><dd><p><a class="reference external" href="https://arxiv.org/pdf/2002.03921.pdf">https://arxiv.org/pdf/2002.03921.pdf</a></p>
</dd>
</dl>
<ol class="arabic simple">
<li><dl class="simple">
<dt>The Transformer-based Encoder now consists of three stages:</dt><dd><p>(a): Enc_mix: encoding input mixture speech;
(b): Enc_SD: separating mixed speech representations;
(c): Enc_rec: transforming each separated speech representation.</p>
</dd>
</dl>
</li>
<li><p>PIT is used in CTC to determine the permutation with minimum loss.</p></li>
</ol>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_mix_transformer.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">ignore_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix_transformer.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E" title="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.e2e_asr_transformer.E2E</span></code></a>, <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix_transformer.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.decoder_and_attention">
<code class="sig-name descname">decoder_and_attention</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em>, <em class="sig-param">hs_mask</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">batch_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix_transformer.html#E2E.decoder_and_attention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.decoder_and_attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward decoder and attention loss.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix_transformer.html#E2E.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode acoustic features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>ndarray</em>) – source acoustic feature (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoder outputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix_transformer.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of source sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences
(B, num_spkrs, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ctc loass value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy in attention decoder</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.recog">
<code class="sig-name descname">recog</code><span class="sig-paren">(</span><em class="sig-param">enc_output</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em>, <em class="sig-param">use_jit=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix_transformer.html#E2E.recog"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.recog" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize input speech of each speaker.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_output</strong> (<em>ndnarray</em>) – encoder outputs (B, T, D) or (T, D)</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argment Namespace contraining options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em>, <em class="sig-param">use_jit=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix_transformer.html#E2E.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix_transformer.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize input speech of each speaker.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndnarray</em>) – input acoustic feature (B, T, D) or (T, D)</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argment Namespace contraining options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-st">
<span id="id51"></span><h2>espnet.nets.pytorch_backend.e2e_st<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-st" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_st"></span><p>RNN sequence-to-sequence speech translation model (pytorch).</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_st.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.st_interface.STInterface" title="espnet.nets.st_interface.STInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.st_interface.STInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.attention_add_arguments">
<em class="property">static </em><code class="sig-name descname">attention_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.attention_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.attention_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for the attention.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">ys_pad_src</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
<li><p><strong>ys_pad_src</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weights with the following shape,
1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
2) other case =&gt; attention weights (B, Lmax, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.calculate_all_ctc_probs">
<code class="sig-name descname">calculate_all_ctc_probs</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">ys_pad_src</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.calculate_all_ctc_probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.calculate_all_ctc_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E CTC probability calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>:param torch.Tensor</dt><dd><p>ys_pad_src: batch of padded token id sequence tensor (B, Lmax)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>CTC probability (B, Tmax, vocab)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.decoder_add_arguments">
<em class="property">static </em><code class="sig-name descname">decoder_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.decoder_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.decoder_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for the decoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode acoustic features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>ndarray</em>) – input acoustic feature (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoder outputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.encoder_add_arguments">
<em class="property">static </em><code class="sig-name descname">encoder_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.encoder_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.encoder_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for the encoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">ys_pad_src</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.forward_asr">
<code class="sig-name descname">forward_asr</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em>, <em class="sig-param">hlens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.forward_asr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.forward_asr" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass in the auxiliary ASR task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax, idim)</p></li>
<li><p><strong>hlens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ASR attention loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy in ASR attention decoder</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ASR CTC loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>character error rate from CTC prediction</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>character error rate from attetion decoder prediction</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>word error rate from attetion decoder prediction</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.forward_mt">
<code class="sig-name descname">forward_mt</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.forward_mt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.forward_mt" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass in the auxiliary MT task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax, idim)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MT loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy in MT decoder</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.init_like_chainer">
<code class="sig-name descname">init_like_chainer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.init_like_chainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.init_like_chainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize weight like chainer.</p>
<p>chainer basically uses LeCun way: W ~ Normal(0, fan_in ** -0.5), b = 0
pytorch basically uses W, b ~ Uniform(-fan_in**-0.5, fan_in**-0.5)
however, there are two exceptions as far as I know.
- EmbedID.W ~ Normal(0, 1)
- LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.scorers">
<code class="sig-name descname">scorers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.scorers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.scorers" title="Permalink to this definition">¶</a></dt>
<dd><p>Scorers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.subsample_frames">
<code class="sig-name descname">subsample_frames</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.subsample_frames"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.subsample_frames" title="Permalink to this definition">¶</a></dt>
<dd><p>Subsample speeh frames in the encoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.translate">
<code class="sig-name descname">translate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.translate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.translate" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – input acoustic feature (T, D)</p></li>
<li><p><strong>trans_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.E2E.translate_batch">
<code class="sig-name descname">translate_batch</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#E2E.translate_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.E2E.translate_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E batch beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>list</em>) – list of input acoustic feature arrays [(T_1, D), (T_2, D), …]</p></li>
<li><p><strong>trans_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_st.Reporter">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_st.</code><code class="sig-name descname">Reporter</code><span class="sig-paren">(</span><em class="sig-param">**links</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#Reporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>A chainer reporter wrapper.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st.Reporter.report">
<code class="sig-name descname">report</code><span class="sig-paren">(</span><em class="sig-param">loss_asr</em>, <em class="sig-param">loss_mt</em>, <em class="sig-param">loss_st</em>, <em class="sig-param">acc_asr</em>, <em class="sig-param">acc_mt</em>, <em class="sig-param">acc</em>, <em class="sig-param">cer_ctc</em>, <em class="sig-param">cer</em>, <em class="sig-param">wer</em>, <em class="sig-param">bleu</em>, <em class="sig-param">mtl_loss</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st.html#Reporter.report"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st.Reporter.report" title="Permalink to this definition">¶</a></dt>
<dd><p>Report at every step.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-mt">
<span id="id52"></span><h2>espnet.nets.pytorch_backend.e2e_mt<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-mt" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_mt"></span><p>RNN sequence-to-sequence text translation model (pytorch).</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_mt.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.mt_interface.MTInterface" title="espnet.nets.mt_interface.MTInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.mt_interface.MTInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.attention_add_arguments">
<em class="property">static </em><code class="sig-name descname">attention_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.attention_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.attention_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for the attention.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weights with the following shape,
1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
2) other case =&gt; attention weights (B, Lmax, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.decoder_add_arguments">
<em class="property">static </em><code class="sig-name descname">decoder_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.decoder_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.decoder_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for the decoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.encoder_add_arguments">
<em class="property">static </em><code class="sig-name descname">encoder_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.encoder_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.encoder_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for the encoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.init_like_fairseq">
<code class="sig-name descname">init_like_fairseq</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.init_like_fairseq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.init_like_fairseq" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize weight like Fairseq.</p>
<p>Fairseq basically uses W, b, EmbedID.W ~ Uniform(-0.1, 0.1),</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.target_language_biasing">
<code class="sig-name descname">target_language_biasing</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.target_language_biasing"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.target_language_biasing" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepend target language IDs to source sentences for multilingual MT.</p>
<p>These tags are prepended in source/target sentences as pre-processing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>source text without language IDs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>target text without language IDs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>target language IDs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor (B, 1)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.translate">
<code class="sig-name descname">translate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.translate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.translate" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – input source text feature (B, T, D)</p></li>
<li><p><strong>trans_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.E2E.translate_batch">
<code class="sig-name descname">translate_batch</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#E2E.translate_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.E2E.translate_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E batch beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>list</em>) – list of input source text feature arrays [(T_1, D), (T_2, D), …]</p></li>
<li><p><strong>trans_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_mt.Reporter">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_mt.</code><code class="sig-name descname">Reporter</code><span class="sig-paren">(</span><em class="sig-param">**links</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#Reporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>A chainer reporter wrapper.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_mt.Reporter.report">
<code class="sig-name descname">report</code><span class="sig-paren">(</span><em class="sig-param">loss</em>, <em class="sig-param">acc</em>, <em class="sig-param">ppl</em>, <em class="sig-param">bleu</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_mt.html#Reporter.report"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_mt.Reporter.report" title="Permalink to this definition">¶</a></dt>
<dd><p>Report at every step.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-ctc">
<span id="id53"></span><h2>espnet.nets.pytorch_backend.ctc<a class="headerlink" href="#espnet-nets-pytorch-backend-ctc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.ctc"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.ctc.CTC">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.ctc.</code><code class="sig-name descname">CTC</code><span class="sig-paren">(</span><em class="sig-param">odim</em>, <em class="sig-param">eprojs</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">ctc_type='warpctc'</em>, <em class="sig-param">reduce=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/ctc.html#CTC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>CTC module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>eprojs</strong> (<em>int</em>) – number of encoder projection units</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout rate (0.0 ~ 1.0)</p></li>
<li><p><strong>ctc_type</strong> (<em>str</em>) – builtin or warpctc</p></li>
<li><p><strong>reduce</strong> (<em>bool</em>) – reduce the CTC loss into a scalar</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.argmax">
<code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/ctc.html#CTC.argmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>argmax of frame activations</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hs_pad</strong> (<em>torch.Tensor</em>) – 3d tensor (B, Tmax, eprojs)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>argmax applied 2d tensor (B, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.forced_align">
<code class="sig-name descname">forced_align</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">y</em>, <em class="sig-param">blank_id=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/ctc.html#CTC.forced_align"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.forced_align" title="Permalink to this definition">¶</a></dt>
<dd><p>forced alignment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h</strong> (<em>torch.Tensor</em>) – hidden state sequence, 2d tensor (T, D)</p></li>
<li><p><strong>y</strong> (<em>int</em>) – id sequence tensor 1d tensor (L)</p></li>
<li><p><strong>y</strong> – blank symbol index</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>best alignment results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em>, <em class="sig-param">hlens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/ctc.html#CTC.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>CTC forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> (<em>torch.Tensor</em>) – batch of padded hidden state sequences (B, Tmax, D)</p></li>
<li><p><strong>hlens</strong> (<em>torch.Tensor</em>) – batch of lengths of hidden state sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ctc loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.log_softmax">
<code class="sig-name descname">log_softmax</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/ctc.html#CTC.log_softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>log_softmax of frame activations</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hs_pad</strong> (<em>torch.Tensor</em>) – 3d tensor (B, Tmax, eprojs)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>log softmax applied 3d tensor (B, Tmax, odim)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.loss_fn">
<code class="sig-name descname">loss_fn</code><span class="sig-paren">(</span><em class="sig-param">th_pred</em>, <em class="sig-param">th_target</em>, <em class="sig-param">th_ilen</em>, <em class="sig-param">th_olen</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/ctc.html#CTC.loss_fn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.loss_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.softmax">
<code class="sig-name descname">softmax</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/ctc.html#CTC.softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>softmax of frame activations</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hs_pad</strong> (<em>torch.Tensor</em>) – 3d tensor (B, Tmax, eprojs)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>log softmax applied 3d tensor (B, Tmax, odim)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.ctc.ctc_for">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.ctc.</code><code class="sig-name descname">ctc_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">odim</em>, <em class="sig-param">reduce=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/ctc.html#ctc_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.ctc_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the CTC module for the given args and output dimension</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> (<em>Namespace</em>) – the program args</p>
</dd>
</dl>
<p>:param int odim : The output dimension
:param bool reduce : return the CTC loss in a scalar
:return: the corresponding CTC module</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-tts-tacotron2">
<span id="id54"></span><h2>espnet.nets.pytorch_backend.e2e_tts_tacotron2<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-tts-tacotron2" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_tts_tacotron2"></span><p>Tacotron 2 related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_tts_tacotron2.</code><code class="sig-name descname">GuidedAttentionLoss</code><span class="sig-paren">(</span><em class="sig-param">sigma=0.4</em>, <em class="sig-param">alpha=1.0</em>, <em class="sig-param">reset_always=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_tacotron2.html#GuidedAttentionLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Guided attention loss function module.</p>
<p>This module calculates the guided attention loss described
in <a class="reference external" href="https://arxiv.org/abs/1710.08969">Efficiently Trainable Text-to-Speech System Based
on Deep Convolutional Networks with Guided Attention</a>,
which forces the attention to be diagonal.</p>
<p>Initialize guided attention loss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma</strong> (<em>float</em><em>, </em><em>optional</em>) – Standard deviation to control
how close attention to a diagonal.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) – Scaling coefficient (lambda).</p></li>
<li><p><strong>reset_always</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to always reset masks.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">att_ws</em>, <em class="sig-param">ilens</em>, <em class="sig-param">olens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_tacotron2.html#GuidedAttentionLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>att_ws</strong> (<em>Tensor</em>) – Batch of attention weights (B, T_max_out, T_max_in).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of input lengths (B,).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of output lengths (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Guided attention loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_tts_tacotron2.</code><code class="sig-name descname">Tacotron2</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_tacotron2.html#Tacotron2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.tts_interface.TTSInterface" title="espnet.nets.tts_interface.TTSInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.tts_interface.TTSInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Tacotron2 module for end-to-end text-to-speech (E2E-TTS).</p>
<p>This is a module of Spectrogram prediction network in Tacotron2 described
in <a class="reference external" href="https://arxiv.org/abs/1712.05884">Natural TTS Synthesis
by Conditioning WaveNet on Mel Spectrogram Predictions</a>,
which converts the sequence of characters
into the sequence of Mel-filterbanks.</p>
<p>Initialize Tacotron2 module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>args</strong> (<em>Namespace</em><em>, </em><em>optional</em>) – <ul>
<li><p>spk_embed_dim (int): Dimension of the speaker embedding.</p></li>
<li><p>embed_dim (int): Dimension of character embedding.</p></li>
<li><p>elayers (int): The number of encoder blstm layers.</p></li>
<li><p>eunits (int): The number of encoder blstm units.</p></li>
<li><p>econv_layers (int): The number of encoder conv layers.</p></li>
<li><p>econv_filts (int): The number of encoder conv filter size.</p></li>
<li><p>econv_chans (int): The number of encoder conv filter channels.</p></li>
<li><p>dlayers (int): The number of decoder lstm layers.</p></li>
<li><p>dunits (int): The number of decoder lstm units.</p></li>
<li><p>prenet_layers (int): The number of prenet layers.</p></li>
<li><p>prenet_units (int): The number of prenet units.</p></li>
<li><p>postnet_layers (int): The number of postnet layers.</p></li>
<li><p>postnet_filts (int): The number of postnet filter size.</p></li>
<li><p>postnet_chans (int): The number of postnet filter channels.</p></li>
<li><p>output_activation (int): The name of activation function for outputs.</p></li>
<li><p>adim (int): The number of dimension of mlp in attention.</p></li>
<li><p>aconv_chans (int): The number of attention conv filter channels.</p></li>
<li><p>aconv_filts (int): The number of attention conv filter size.</p></li>
<li><p>cumulate_att_w (bool): Whether to cumulate previous attention weight.</p></li>
<li><p>use_batch_norm (bool): Whether to use batch normalization.</p></li>
<li><dl class="simple">
<dt>use_concate (int): Whether to concatenate encoder embedding</dt><dd><p>with decoder lstm outputs.</p>
</dd>
</dl>
</li>
<li><p>dropout_rate (float): Dropout rate.</p></li>
<li><p>zoneout_rate (float): Zoneout rate.</p></li>
<li><p>reduction_factor (int): Reduction factor.</p></li>
<li><p>spk_embed_dim (int): Number of speaker embedding dimenstions.</p></li>
<li><dl class="simple">
<dt>spc_dim (int): Number of spectrogram embedding dimenstions</dt><dd><p>(only for use_cbhg=True).</p>
</dd>
</dl>
</li>
<li><p>use_cbhg (bool): Whether to use CBHG module.</p></li>
<li><p>cbhg_conv_bank_layers (int): The number of convoluional banks in CBHG.</p></li>
<li><dl class="simple">
<dt>cbhg_conv_bank_chans (int): The number of channels of</dt><dd><p>convolutional bank in CBHG.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>cbhg_proj_filts (int):</dt><dd><p>The number of filter size of projection layeri in CBHG.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>cbhg_proj_chans (int):</dt><dd><p>The number of channels of projection layer in CBHG.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>cbhg_highway_layers (int):</dt><dd><p>The number of layers of highway network in CBHG.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>cbhg_highway_units (int):</dt><dd><p>The number of units of highway network in CBHG.</p>
</dd>
</dl>
</li>
<li><p>cbhg_gru_units (int): The number of units of GRU in CBHG.</p></li>
<li><dl class="simple">
<dt>use_masking (bool):</dt><dd><p>Whether to apply masking for padded part in loss calculation.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>use_weighted_masking (bool):</dt><dd><p>Whether to apply weighted masking in loss calculation.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>bce_pos_weight (float):</dt><dd><p>Weight of positive sample of stop token (only for use_masking=True).</p>
</dd>
</dl>
</li>
<li><p>use-guided-attn-loss (bool): Whether to use guided attention loss.</p></li>
<li><p>guided-attn-loss-sigma (float) Sigma in guided attention loss.</p></li>
<li><p>guided-attn-loss-lamdba (float): Lambda in guided attention loss.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_tacotron2.html#Tacotron2.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add model-specific arguments to the parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.base_plot_keys">
<em class="property">property </em><code class="sig-name descname">base_plot_keys</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.base_plot_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>Return base key names to plot during training.</p>
<p>keys should match what <cite>chainer.reporter</cite> reports.
If you add the key <cite>loss</cite>, the reporter will report <cite>main/loss</cite>
and <cite>validation/main/loss</cite> values.
also <cite>loss.png</cite> will be created as a figure visulizing <cite>main/loss</cite>
and <cite>validation/main/loss</cite> values.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of strings which are base keys to plot during training.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">keep_tensor=False</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_tacotron2.html#Tacotron2.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all of the attention weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded character ids (B, Tmax).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors (B, spk_embed_dim).</p></li>
<li><p><strong>keep_tensor</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to keep original tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of attention weights (B, Lmax, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Union[ndarray, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">labels</em>, <em class="sig-param">olens</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">extras=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_tacotron2.html#Tacotron2.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded character ids (B, Tmax).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors (B, spk_embed_dim).</p></li>
<li><p><strong>extras</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of groundtruth spectrograms (B, Lmax, spc_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">inference_args</em>, <em class="sig-param">spemb=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_tacotron2.html#Tacotron2.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate the sequence of features given the sequences of characters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input sequence of characters (T,).</p></li>
<li><p><strong>inference_args</strong> (<em>Namespace</em>) – <ul>
<li><p>threshold (float): Threshold in inference.</p></li>
<li><p>minlenratio (float): Minimum length ratio in inference.</p></li>
<li><p>maxlenratio (float): Maximum length ratio in inference.</p></li>
</ul>
</p></li>
<li><p><strong>spemb</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Speaker embedding vector (spk_embed_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequence of features (L, odim).
Tensor: Output sequence of stop probabilities (L,).
Tensor: Attention weights (L, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_tts_tacotron2.</code><code class="sig-name descname">Tacotron2Loss</code><span class="sig-paren">(</span><em class="sig-param">use_masking=True</em>, <em class="sig-param">use_weighted_masking=False</em>, <em class="sig-param">bce_pos_weight=20.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_tacotron2.html#Tacotron2Loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Loss function module for Tacotron2.</p>
<p>Initialize Tactoron2 loss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_masking</strong> (<em>bool</em>) – Whether to apply masking
for padded part in loss calculation.</p></li>
<li><p><strong>use_weighted_masking</strong> (<em>bool</em>) – Whether to apply weighted masking in loss calculation.</p></li>
<li><p><strong>bce_pos_weight</strong> (<em>float</em>) – Weight of positive sample of stop token.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">after_outs</em>, <em class="sig-param">before_outs</em>, <em class="sig-param">logits</em>, <em class="sig-param">ys</em>, <em class="sig-param">labels</em>, <em class="sig-param">olens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_tacotron2.html#Tacotron2Loss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>after_outs</strong> (<em>Tensor</em>) – Batch of outputs after postnets (B, Lmax, odim).</p></li>
<li><p><strong>before_outs</strong> (<em>Tensor</em>) – Batch of outputs before postnets (B, Lmax, odim).</p></li>
<li><p><strong>logits</strong> (<em>Tensor</em>) – Batch of stop logits (B, Lmax).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>labels</strong> (<em>LongTensor</em>) – Batch of the sequences of stop token labels (B, Lmax).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>L1 loss value.
Tensor: Mean square error loss value.
Tensor: Binary cross entropy loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-wavenet">
<span id="id55"></span><h2>espnet.nets.pytorch_backend.wavenet<a class="headerlink" href="#espnet-nets-pytorch-backend-wavenet" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.wavenet"></span><p>This code is based on <a class="reference external" href="https://github.com/kan-bayashi/PytorchWaveNetVocoder">https://github.com/kan-bayashi/PytorchWaveNetVocoder</a>.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.wavenet.CausalConv1d">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.wavenet.</code><code class="sig-name descname">CausalConv1d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#CausalConv1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.CausalConv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>1D dilated causal convolution.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.wavenet.CausalConv1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#CausalConv1d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.CausalConv1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor with the shape (B, in_channels, T).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor with the shape (B, out_channels, T)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.wavenet.OneHot">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.wavenet.</code><code class="sig-name descname">OneHot</code><span class="sig-paren">(</span><em class="sig-param">depth</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#OneHot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.OneHot" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convert to one-hot vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>depth</strong> (<em>int</em>) – Dimension of one-hot vector.</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.wavenet.OneHot.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#OneHot.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.OneHot.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>LongTensor</em>) – long tensor variable with the shape  (B, T)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>float tensor variable with the shape (B, depth, T)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.wavenet.UpSampling">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.wavenet.</code><code class="sig-name descname">UpSampling</code><span class="sig-paren">(</span><em class="sig-param">upsampling_factor</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#UpSampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.UpSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Upsampling layer with deconvolution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>upsampling_factor</strong> (<em>int</em>) – Upsampling factor.</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.wavenet.UpSampling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#UpSampling.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.UpSampling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor with the shape  (B, C, T)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor with the shape (B, C, T’) where T’ = T * upsampling_factor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.wavenet.WaveNet">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.wavenet.</code><code class="sig-name descname">WaveNet</code><span class="sig-paren">(</span><em class="sig-param">n_quantize=256</em>, <em class="sig-param">n_aux=28</em>, <em class="sig-param">n_resch=512</em>, <em class="sig-param">n_skipch=256</em>, <em class="sig-param">dilation_depth=10</em>, <em class="sig-param">dilation_repeat=3</em>, <em class="sig-param">kernel_size=2</em>, <em class="sig-param">upsampling_factor=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#WaveNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.WaveNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Conditional wavenet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_quantize</strong> (<em>int</em>) – Number of quantization.</p></li>
<li><p><strong>n_aux</strong> (<em>int</em>) – Number of aux feature dimension.</p></li>
<li><p><strong>n_resch</strong> (<em>int</em>) – Number of filter channels for residual block.</p></li>
<li><p><strong>n_skipch</strong> (<em>int</em>) – Number of filter channels for skip connection.</p></li>
<li><p><strong>dilation_depth</strong> (<em>int</em>) – Number of dilation depth
(e.g. if set 10, max dilation = 2^(10-1)).</p></li>
<li><p><strong>dilation_repeat</strong> (<em>int</em>) – Number of dilation repeat.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Filter size of dilated causal convolution.</p></li>
<li><p><strong>upsampling_factor</strong> (<em>int</em>) – Upsampling factor.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.wavenet.WaveNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">h</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#WaveNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.WaveNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>LongTensor</em>) – Quantized input waveform tensor with the shape  (B, T).</p></li>
<li><p><strong>h</strong> (<em>Tensor</em>) – Auxiliary feature tensor with the shape  (B, n_aux, T).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Logits with the shape (B, T, n_quantize).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.wavenet.WaveNet.generate">
<code class="sig-name descname">generate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">h</em>, <em class="sig-param">n_samples</em>, <em class="sig-param">interval=None</em>, <em class="sig-param">mode='sampling'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#WaveNet.generate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.WaveNet.generate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a waveform with fast genration algorithm.</p>
<p>This generation based on <a class="reference external" href="https://arxiv.org/abs/1611.09482">Fast WaveNet Generation Algorithm</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>LongTensor</em>) – Initial waveform tensor with the shape  (T,).</p></li>
<li><p><strong>h</strong> (<em>Tensor</em>) – Auxiliary feature tensor with the shape  (n_samples + T, n_aux).</p></li>
<li><p><strong>n_samples</strong> (<em>int</em>) – Number of samples to be generated.</p></li>
<li><p><strong>interval</strong> (<em>int</em><em>, </em><em>optional</em>) – Log interval.</p></li>
<li><p><strong>mode</strong> (<em>str</em><em>, </em><em>optional</em>) – “sampling” or “argmax”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Generated quantized waveform (n_samples).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.wavenet.decode_mu_law">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.wavenet.</code><code class="sig-name descname">decode_mu_law</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">mu=256</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#decode_mu_law"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.decode_mu_law" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform mu-law decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – Quantized audio signal with the range from 0 to mu - 1.</p></li>
<li><p><strong>mu</strong> (<em>int</em>) – Quantized level.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Audio signal with the range from -1 to 1.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.wavenet.encode_mu_law">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.wavenet.</code><code class="sig-name descname">encode_mu_law</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mu=256</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#encode_mu_law"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.encode_mu_law" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform mu-law encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – Audio signal with the range from -1 to 1.</p></li>
<li><p><strong>mu</strong> (<em>int</em>) – Quantized level.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Quantized audio signal with the range from 0 to mu - 1.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.wavenet.initialize">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.wavenet.</code><code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">m</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/wavenet.html#initialize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.wavenet.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Initilize conv layers with xavier.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>m</strong> (<em>torch.nn.Module</em>) – Torch module.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-asr-transducer">
<span id="id56"></span><h2>espnet.nets.pytorch_backend.e2e_asr_transducer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr-transducer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr_transducer"></span><p>Transducer speech recognition model (pytorch).</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_transducer.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">odim: int</em>, <em class="sig-param">args: argparse.Namespace</em>, <em class="sig-param">ignore_id: int = -1</em>, <em class="sig-param">blank_id: int = 0</em>, <em class="sig-param">training: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module for Transducer models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> – Dimension of inputs.</p></li>
<li><p><strong>odim</strong> – Dimension of outputs.</p></li>
<li><p><strong>args</strong> – Namespace containing model options.</p></li>
<li><p><strong>ignore_id</strong> – Padding symbol ID.</p></li>
<li><p><strong>blank_id</strong> – Blank symbol ID.</p></li>
<li><p><strong>training</strong> – Whether the model is initialized in training or inference mode.</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object for Transducer model.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for Transducer model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Get attention plot class.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.auxiliary_task_add_arguments">
<em class="property">static </em><code class="sig-name descname">auxiliary_task_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.auxiliary_task_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.auxiliary_task_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for auxiliary task.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_len: torch.Tensor</em>, <em class="sig-param">labels: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; numpy.ndarray<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats</strong> – Feature sequences. (B, F, D_feats)</p></li>
<li><p><strong>feats_len</strong> – Feature sequences lengths. (B,)</p></li>
<li><p><strong>labels</strong> – Label ID sequences. (B, L)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Attention weights with the following shape,</dt><dd><ol class="arabic simple">
<li><p>multi-head case =&gt; attention weights. (B, D_att, U, T),</p></li>
<li><p>other case =&gt; attention weights. (B, U, T)</p></li>
</ol>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ret</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.decoder_add_custom_arguments">
<em class="property">static </em><code class="sig-name descname">decoder_add_custom_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.decoder_add_custom_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.decoder_add_custom_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for Custom decoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.decoder_add_general_arguments">
<em class="property">static </em><code class="sig-name descname">decoder_add_general_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.decoder_add_general_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.decoder_add_general_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add general arguments for decoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.decoder_add_rnn_arguments">
<em class="property">static </em><code class="sig-name descname">decoder_add_rnn_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.decoder_add_rnn_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.decoder_add_rnn_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for RNN decoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.default_parameters">
<code class="sig-name descname">default_parameters</code><span class="sig-paren">(</span><em class="sig-param">args: argparse.Namespace</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.default_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.default_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/reset parameters for Transducer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> – Namespace containing model options.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encode_custom">
<code class="sig-name descname">encode_custom</code><span class="sig-paren">(</span><em class="sig-param">feats: numpy.ndarray</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.encode_custom"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encode_custom" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode acoustic features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>feats</strong> – Feature sequence. (F, D_feats)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded feature sequence. (T, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>enc_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encode_rnn">
<code class="sig-name descname">encode_rnn</code><span class="sig-paren">(</span><em class="sig-param">feats: numpy.ndarray</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.encode_rnn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encode_rnn" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode acoustic features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>feats</strong> – Feature sequence. (F, D_feats)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded feature sequence. (T, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>enc_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encoder_add_custom_arguments">
<em class="property">static </em><code class="sig-name descname">encoder_add_custom_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.encoder_add_custom_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encoder_add_custom_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for Custom encoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encoder_add_general_arguments">
<em class="property">static </em><code class="sig-name descname">encoder_add_general_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.encoder_add_general_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encoder_add_general_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add general arguments for encoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encoder_add_rnn_arguments">
<em class="property">static </em><code class="sig-name descname">encoder_add_rnn_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.encoder_add_rnn_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.encoder_add_rnn_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for RNN encoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_len: torch.Tensor</em>, <em class="sig-param">labels: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats</strong> – Feature sequences. (B, F, D_feats)</p></li>
<li><p><strong>feats_len</strong> – Feature sequences lengths. (B,)</p></li>
<li><p><strong>labels</strong> – Label ID sequences. (B, L)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Transducer loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>loss</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">feats: numpy.ndarray</em>, <em class="sig-param">beam_search: espnet.nets.beam_search_transducer.BeamSearchTransducer</em><span class="sig-paren">)</span> &#x2192; List<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize input features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats</strong> – Feature sequence. (F, D_feats)</p></li>
<li><p><strong>beam_search</strong> – Beam search class.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.training_add_custom_arguments">
<em class="property">static </em><code class="sig-name descname">training_add_custom_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.training_add_custom_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.training_add_custom_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for Custom architecture training.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.transducer_add_arguments">
<em class="property">static </em><code class="sig-name descname">transducer_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser: argparse.ArgumentParser</em><span class="sig-paren">)</span> &#x2192; argparse.ArgumentParser<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#E2E.transducer_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.E2E.transducer_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for Transducer model.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.Reporter">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_transducer.</code><code class="sig-name descname">Reporter</code><span class="sig-paren">(</span><em class="sig-param">**links</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#Reporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>A chainer reporter wrapper for Transducer models.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transducer.Reporter.report">
<code class="sig-name descname">report</code><span class="sig-paren">(</span><em class="sig-param">loss: float</em>, <em class="sig-param">loss_trans: float</em>, <em class="sig-param">loss_ctc: float</em>, <em class="sig-param">loss_aux_trans: float</em>, <em class="sig-param">loss_symm_kl_div: float</em>, <em class="sig-param">loss_lm: float</em>, <em class="sig-param">cer: float</em>, <em class="sig-param">wer: float</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transducer.html#Reporter.report"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transducer.Reporter.report" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate reporter attributes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> – Model loss.</p></li>
<li><p><strong>loss_trans</strong> – Main Transducer loss.</p></li>
<li><p><strong>loss_ctc</strong> – CTC loss.</p></li>
<li><p><strong>loss_aux_trans</strong> – Auxiliary Transducer loss.</p></li>
<li><p><strong>loss_symm_kl_div</strong> – Symmetric KL-divergence loss.</p></li>
<li><p><strong>loss_lm</strong> – Label smoothing loss.</p></li>
<li><p><strong>cer</strong> – Character Error Rate.</p></li>
<li><p><strong>wer</strong> – Word Error Rate.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-tts-transformer">
<span id="id57"></span><h2>espnet.nets.pytorch_backend.e2e_tts_transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-tts-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_tts_transformer"></span><p>TTS-Transformer related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_tts_transformer.</code><code class="sig-name descname">GuidedMultiHeadAttentionLoss</code><span class="sig-paren">(</span><em class="sig-param">sigma=0.4</em>, <em class="sig-param">alpha=1.0</em>, <em class="sig-param">reset_always=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_transformer.html#GuidedMultiHeadAttentionLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss" title="espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss</span></code></a></p>
<p>Guided attention loss function module for multi head attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma</strong> (<em>float</em><em>, </em><em>optional</em>) – Standard deviation to control</p></li>
<li><p><strong>close attention to a diagonal.</strong> (<em>how</em>) – </p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) – Scaling coefficient (lambda).</p></li>
<li><p><strong>reset_always</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to always reset masks.</p></li>
</ul>
</dd>
</dl>
<p>Initialize guided attention loss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma</strong> (<em>float</em><em>, </em><em>optional</em>) – Standard deviation to control
how close attention to a diagonal.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) – Scaling coefficient (lambda).</p></li>
<li><p><strong>reset_always</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to always reset masks.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">att_ws</em>, <em class="sig-param">ilens</em>, <em class="sig-param">olens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_transformer.html#GuidedMultiHeadAttentionLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>att_ws</strong> (<em>Tensor</em>) – Batch of multi head attention weights (B, H, T_max_out, T_max_in).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of input lengths (B,).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of output lengths (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Guided attention loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.TTSPlot">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_tts_transformer.</code><code class="sig-name descname">TTSPlot</code><span class="sig-paren">(</span><em class="sig-param">att_vis_fn</em>, <em class="sig-param">data</em>, <em class="sig-param">outdir</em>, <em class="sig-param">converter</em>, <em class="sig-param">transform</em>, <em class="sig-param">device</em>, <em class="sig-param">reverse=False</em>, <em class="sig-param">ikey='input'</em>, <em class="sig-param">iaxis=0</em>, <em class="sig-param">okey='output'</em>, <em class="sig-param">oaxis=0</em>, <em class="sig-param">subsampling_factor=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_transformer.html#TTSPlot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.TTSPlot" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport" title="espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport</span></code></a></p>
<p>Attention plot module for TTS-Transformer.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.TTSPlot.plotfn">
<code class="sig-name descname">plotfn</code><span class="sig-paren">(</span><em class="sig-param">data_dict</em>, <em class="sig-param">uttid_list</em>, <em class="sig-param">attn_dict</em>, <em class="sig-param">outdir</em>, <em class="sig-param">suffix='png'</em>, <em class="sig-param">savefn=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_transformer.html#TTSPlot.plotfn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.TTSPlot.plotfn" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot multi head attentions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_dict</strong> (<em>dict</em>) – Utts info from json file.</p></li>
<li><p><strong>uttid_list</strong> (<em>list</em>) – List of utt_id.</p></li>
<li><p><strong>attn_dict</strong> (<em>dict</em>) – Multi head attention dict.
Values should be numpy.ndarray (H, L, T)</p></li>
<li><p><strong>outdir</strong> (<em>str</em>) – Directory name to save figures.</p></li>
<li><p><strong>suffix</strong> (<em>str</em>) – Filename suffix including image type (e.g., png).</p></li>
<li><p><strong>savefn</strong> (<em>function</em>) – Function to save figures.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_tts_transformer.</code><code class="sig-name descname">Transformer</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_transformer.html#Transformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.tts_interface.TTSInterface" title="espnet.nets.tts_interface.TTSInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.tts_interface.TTSInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Text-to-Speech Transformer module.</p>
<p>This is a module of text-to-speech Transformer described
in <a class="reference external" href="https://arxiv.org/pdf/1809.08895.pdf">Neural Speech Synthesis with Transformer Network</a>,
which convert the sequence of characters
or phonemes into the sequence of Mel-filterbanks.</p>
<p>Initialize TTS-Transformer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>args</strong> (<em>Namespace</em><em>, </em><em>optional</em>) – <ul>
<li><p>embed_dim (int): Dimension of character embedding.</p></li>
<li><dl class="simple">
<dt>eprenet_conv_layers (int):</dt><dd><p>Number of encoder prenet convolution layers.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>eprenet_conv_chans (int):</dt><dd><p>Number of encoder prenet convolution channels.</p>
</dd>
</dl>
</li>
<li><p>eprenet_conv_filts (int): Filter size of encoder prenet convolution.</p></li>
<li><p>dprenet_layers (int): Number of decoder prenet layers.</p></li>
<li><p>dprenet_units (int): Number of decoder prenet hidden units.</p></li>
<li><p>elayers (int): Number of encoder layers.</p></li>
<li><p>eunits (int): Number of encoder hidden units.</p></li>
<li><p>adim (int): Number of attention transformation dimensions.</p></li>
<li><p>aheads (int): Number of heads for multi head attention.</p></li>
<li><p>dlayers (int): Number of decoder layers.</p></li>
<li><p>dunits (int): Number of decoder hidden units.</p></li>
<li><p>postnet_layers (int): Number of postnet layers.</p></li>
<li><p>postnet_chans (int): Number of postnet channels.</p></li>
<li><p>postnet_filts (int): Filter size of postnet.</p></li>
<li><dl class="simple">
<dt>use_scaled_pos_enc (bool):</dt><dd><p>Whether to use trainable scaled positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>use_batch_norm (bool):</dt><dd><p>Whether to use batch normalization in encoder prenet.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>encoder_normalize_before (bool):</dt><dd><p>Whether to perform layer normalization before encoder block.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_normalize_before (bool):</dt><dd><p>Whether to perform layer normalization before decoder block.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>encoder_concat_after (bool): Whether to concatenate attention</dt><dd><p>layer’s input and output in encoder.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_concat_after (bool): Whether to concatenate attention</dt><dd><p>layer’s input and output in decoder.</p>
</dd>
</dl>
</li>
<li><p>reduction_factor (int): Reduction factor.</p></li>
<li><p>spk_embed_dim (int): Number of speaker embedding dimenstions.</p></li>
<li><p>spk_embed_integration_type: How to integrate speaker embedding.</p></li>
<li><p>transformer_init (float): How to initialize transformer parameters.</p></li>
<li><p>transformer_lr (float): Initial value of learning rate.</p></li>
<li><p>transformer_warmup_steps (int): Optimizer warmup steps.</p></li>
<li><dl class="simple">
<dt>transformer_enc_dropout_rate (float):</dt><dd><p>Dropout rate in encoder except attention &amp; positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_enc_positional_dropout_rate (float):</dt><dd><p>Dropout rate after encoder positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_enc_attn_dropout_rate (float):</dt><dd><p>Dropout rate in encoder self-attention module.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_dec_dropout_rate (float):</dt><dd><p>Dropout rate in decoder except attention &amp; positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_dec_positional_dropout_rate (float):</dt><dd><p>Dropout rate after decoder positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_dec_attn_dropout_rate (float):</dt><dd><p>Dropout rate in deocoder self-attention module.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_enc_dec_attn_dropout_rate (float):</dt><dd><p>Dropout rate in encoder-deocoder attention module.</p>
</dd>
</dl>
</li>
<li><p>eprenet_dropout_rate (float): Dropout rate in encoder prenet.</p></li>
<li><p>dprenet_dropout_rate (float): Dropout rate in decoder prenet.</p></li>
<li><p>postnet_dropout_rate (float): Dropout rate in postnet.</p></li>
<li><dl class="simple">
<dt>use_masking (bool):</dt><dd><p>Whether to apply masking for padded part in loss calculation.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>use_weighted_masking (bool):</dt><dd><p>Whether to apply weighted masking in loss calculation.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>bce_pos_weight (float): Positive sample weight in bce calculation</dt><dd><p>(only for use_masking=true).</p>
</dd>
</dl>
</li>
<li><p>loss_type (str): How to calculate loss.</p></li>
<li><p>use_guided_attn_loss (bool): Whether to use guided attention loss.</p></li>
<li><dl class="simple">
<dt>num_heads_applied_guided_attn (int):</dt><dd><p>Number of heads in each layer to apply guided attention loss.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>num_layers_applied_guided_attn (int):</dt><dd><p>Number of layers to apply guided attention loss.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>modules_applied_guided_attn (list):</dt><dd><p>List of module names to apply guided attention loss.</p>
</dd>
</dl>
</li>
<li><p>guided-attn-loss-sigma (float) Sigma in guided attention loss.</p></li>
<li><p>guided-attn-loss-lambda (float): Lambda in guided attention loss.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_transformer.html#Transformer.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add model-specific arguments to the parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Return plot class for attention weight plot.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.base_plot_keys">
<em class="property">property </em><code class="sig-name descname">base_plot_keys</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.base_plot_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>Return base key names to plot during training.</p>
<p>keys should match what <cite>chainer.reporter</cite> reports.
If you add the key <cite>loss</cite>, the reporter will report <cite>main/loss</cite>
and <cite>validation/main/loss</cite> values.
also <cite>loss.png</cite> will be created as a figure visulizing <cite>main/loss</cite>
and <cite>validation/main/loss</cite> values.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of strings which are base keys to plot during training.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">olens</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">skip_output=False</em>, <em class="sig-param">keep_tensor=False</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_transformer.html#Transformer.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all of the attention weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded character ids (B, Tmax).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors (B, spk_embed_dim).</p></li>
<li><p><strong>skip_output</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to skip calculate the final output.</p></li>
<li><p><strong>keep_tensor</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to keep original tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict of attention weights and outputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">labels</em>, <em class="sig-param">olens</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_transformer.html#Transformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded character ids (B, Tmax).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors (B, spk_embed_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">inference_args</em>, <em class="sig-param">spemb=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_transformer.html#Transformer.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate the sequence of features given the sequences of characters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input sequence of characters (T,).</p></li>
<li><p><strong>inference_args</strong> (<em>Namespace</em>) – <ul>
<li><p>threshold (float): Threshold in inference.</p></li>
<li><p>minlenratio (float): Minimum length ratio in inference.</p></li>
<li><p>maxlenratio (float): Maximum length ratio in inference.</p></li>
</ul>
</p></li>
<li><p><strong>spemb</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Speaker embedding vector (spk_embed_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequence of features (L, odim).
Tensor: Output sequence of stop probabilities (L,).
Tensor: Encoder-decoder (source) attention weights (#layers, #heads, L, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-gtn-ctc">
<span id="id58"></span><h2>espnet.nets.pytorch_backend.gtn_ctc<a class="headerlink" href="#espnet-nets-pytorch-backend-gtn-ctc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.gtn_ctc"></span><p>GTN CTC implementation.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.gtn_ctc.GTNCTCLossFunction">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.gtn_ctc.</code><code class="sig-name descname">GTNCTCLossFunction</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/gtn_ctc.html#GTNCTCLossFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.gtn_ctc.GTNCTCLossFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>GTN CTC module.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.gtn_ctc.GTNCTCLossFunction.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_output</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/gtn_ctc.html#GTNCTCLossFunction.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.gtn_ctc.GTNCTCLossFunction.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Backward computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>grad_output</strong> (<em>torch.tensor</em>) – backward passed gradient value</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>cumulative gradient output</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(torch.Tensor, None, None, None)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.gtn_ctc.GTNCTCLossFunction.create_ctc_graph">
<em class="property">static </em><code class="sig-name descname">create_ctc_graph</code><span class="sig-paren">(</span><em class="sig-param">target</em>, <em class="sig-param">blank_idx</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/gtn_ctc.html#GTNCTCLossFunction.create_ctc_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.gtn_ctc.GTNCTCLossFunction.create_ctc_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Build gtn graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>list</em>) – single target sequence</p></li>
<li><p><strong>blank_idx</strong> (<em>int</em>) – index of blank token</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>gtn graph of target sequence</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>gtn.Graph</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.gtn_ctc.GTNCTCLossFunction.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">log_probs</em>, <em class="sig-param">targets</em>, <em class="sig-param">ilens</em>, <em class="sig-param">blank_idx=0</em>, <em class="sig-param">reduction='none'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/gtn_ctc.html#GTNCTCLossFunction.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.gtn_ctc.GTNCTCLossFunction.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_probs</strong> (<em>torch.tensor</em>) – batched log softmax probabilities (B, Tmax, oDim)</p></li>
<li><p><strong>targets</strong> (<em>list</em>) – batched target sequences, list of lists</p></li>
<li><p><strong>blank_idx</strong> (<em>int</em>) – index of blank token</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ctc loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-tts-fastspeech">
<span id="id59"></span><h2>espnet.nets.pytorch_backend.e2e_tts_fastspeech<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-tts-fastspeech" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_tts_fastspeech"></span><p>FastSpeech related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_tts_fastspeech.</code><code class="sig-name descname">FeedForwardTransformer</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_fastspeech.html#FeedForwardTransformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.tts_interface.TTSInterface" title="espnet.nets.tts_interface.TTSInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.tts_interface.TTSInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Feed Forward Transformer for TTS a.k.a. FastSpeech.</p>
<p>This is a module of FastSpeech,
feed-forward Transformer with duration predictor described in
<a class="reference external" href="https://arxiv.org/pdf/1905.09263.pdf">FastSpeech: Fast, Robust and Controllable Text to Speech</a>,
which does not require any auto-regressive
processing during inference,
resulting in fast decoding compared with auto-regressive Transformer.</p>
<p>Initialize feed-forward Transformer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>args</strong> (<em>Namespace</em><em>, </em><em>optional</em>) – <ul>
<li><p>elayers (int): Number of encoder layers.</p></li>
<li><p>eunits (int): Number of encoder hidden units.</p></li>
<li><p>adim (int): Number of attention transformation dimensions.</p></li>
<li><p>aheads (int): Number of heads for multi head attention.</p></li>
<li><p>dlayers (int): Number of decoder layers.</p></li>
<li><p>dunits (int): Number of decoder hidden units.</p></li>
<li><dl class="simple">
<dt>use_scaled_pos_enc (bool):</dt><dd><p>Whether to use trainable scaled positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>encoder_normalize_before (bool):</dt><dd><p>Whether to perform layer normalization before encoder block.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_normalize_before (bool):</dt><dd><p>Whether to perform layer normalization before decoder block.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>encoder_concat_after (bool): Whether to concatenate attention</dt><dd><p>layer’s input and output in encoder.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_concat_after (bool): Whether to concatenate attention</dt><dd><p>layer’s input and output in decoder.</p>
</dd>
</dl>
</li>
<li><p>duration_predictor_layers (int): Number of duration predictor layers.</p></li>
<li><p>duration_predictor_chans (int): Number of duration predictor channels.</p></li>
<li><dl class="simple">
<dt>duration_predictor_kernel_size (int):</dt><dd><p>Kernel size of duration predictor.</p>
</dd>
</dl>
</li>
<li><p>spk_embed_dim (int): Number of speaker embedding dimensions.</p></li>
<li><p>spk_embed_integration_type: How to integrate speaker embedding.</p></li>
<li><p>teacher_model (str): Teacher auto-regressive transformer model path.</p></li>
<li><p>reduction_factor (int): Reduction factor.</p></li>
<li><p>transformer_init (float): How to initialize transformer parameters.</p></li>
<li><p>transformer_lr (float): Initial value of learning rate.</p></li>
<li><p>transformer_warmup_steps (int): Optimizer warmup steps.</p></li>
<li><dl class="simple">
<dt>transformer_enc_dropout_rate (float):</dt><dd><p>Dropout rate in encoder except attention &amp; positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_enc_positional_dropout_rate (float):</dt><dd><p>Dropout rate after encoder positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_enc_attn_dropout_rate (float):</dt><dd><p>Dropout rate in encoder self-attention module.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_dec_dropout_rate (float):</dt><dd><p>Dropout rate in decoder except attention &amp; positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_dec_positional_dropout_rate (float):</dt><dd><p>Dropout rate after decoder positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_dec_attn_dropout_rate (float):</dt><dd><p>Dropout rate in deocoder self-attention module.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_enc_dec_attn_dropout_rate (float):</dt><dd><p>Dropout rate in encoder-deocoder attention module.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>use_masking (bool):</dt><dd><p>Whether to apply masking for padded part in loss calculation.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>use_weighted_masking (bool):</dt><dd><p>Whether to apply weighted masking in loss calculation.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transfer_encoder_from_teacher:</dt><dd><p>Whether to transfer encoder using teacher encoder parameters.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transferred_encoder_module:</dt><dd><p>Encoder module to be initialized using teacher parameters.</p>
</dd>
</dl>
</li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_fastspeech.html#FeedForwardTransformer.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add model-specific arguments to the parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Return plot class for attention weight plot.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.base_plot_keys">
<em class="property">property </em><code class="sig-name descname">base_plot_keys</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.base_plot_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>Return base key names to plot during training.</p>
<p>keys should match what <cite>chainer.reporter</cite> reports.
If you add the key <cite>loss</cite>,
the reporter will report <cite>main/loss</cite> and <cite>validation/main/loss</cite> values.
also <cite>loss.png</cite> will be created as a figure visulizing <cite>main/loss</cite>
and <cite>validation/main/loss</cite> values.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of strings which are base keys to plot during training.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">olens</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">extras=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_fastspeech.html#FeedForwardTransformer.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all of the attention weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded character ids (B, Tmax).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors (B, spk_embed_dim).</p></li>
<li><p><strong>extras</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of precalculated durations (B, Tmax, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict of attention weights and outputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">olens</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">extras=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_fastspeech.html#FeedForwardTransformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded character ids (B, Tmax).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors (B, spk_embed_dim).</p></li>
<li><p><strong>extras</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of precalculated durations (B, Tmax, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">inference_args</em>, <em class="sig-param">spemb=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_fastspeech.html#FeedForwardTransformer.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformer.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate the sequence of features given the sequences of characters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input sequence of characters (T,).</p></li>
<li><p><strong>inference_args</strong> (<em>Namespace</em>) – Dummy for compatibility.</p></li>
<li><p><strong>spemb</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Speaker embedding vector (spk_embed_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequence of features (L, odim).
None: Dummy for compatibility.
None: Dummy for compatibility.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_tts_fastspeech.</code><code class="sig-name descname">FeedForwardTransformerLoss</code><span class="sig-paren">(</span><em class="sig-param">use_masking=True</em>, <em class="sig-param">use_weighted_masking=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_fastspeech.html#FeedForwardTransformerLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Loss function module for feed-forward Transformer.</p>
<p>Initialize feed-forward Transformer loss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_masking</strong> (<em>bool</em>) – Whether to apply masking for padded part in loss calculation.</p></li>
<li><p><strong>use_weighted_masking</strong> (<em>bool</em>) – Whether to weighted masking in loss calculation.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">after_outs</em>, <em class="sig-param">before_outs</em>, <em class="sig-param">d_outs</em>, <em class="sig-param">ys</em>, <em class="sig-param">ds</em>, <em class="sig-param">ilens</em>, <em class="sig-param">olens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_tts_fastspeech.html#FeedForwardTransformerLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_fastspeech.FeedForwardTransformerLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>after_outs</strong> (<em>Tensor</em>) – Batch of outputs after postnets (B, Lmax, odim).</p></li>
<li><p><strong>before_outs</strong> (<em>Tensor</em>) – Batch of outputs before postnets (B, Lmax, odim).</p></li>
<li><p><strong>d_outs</strong> (<em>Tensor</em>) – Batch of outputs of duration predictor (B, Tmax).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of target features (B, Lmax, odim).</p></li>
<li><p><strong>ds</strong> (<em>Tensor</em>) – Batch of durations (B, Tmax).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of the lengths of each input (B,).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>L1 loss value.
Tensor: Duration predictor loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-init">
<span id="id60"></span><h2>espnet.nets.pytorch_backend.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-e2e-st-conformer">
<span id="id61"></span><h2>espnet.nets.pytorch_backend.e2e_st_conformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-st-conformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_st_conformer"></span><p>Conformer speech translation model (pytorch).</p>
<p>It is a fusion of <cite>e2e_st_transformer.py</cite>
Refer to: <a class="reference external" href="https://arxiv.org/abs/2005.08100">https://arxiv.org/abs/2005.08100</a></p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_st_conformer.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_st_conformer.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">ignore_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_conformer.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_conformer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E" title="espnet.nets.pytorch_backend.e2e_st_transformer.E2E"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.e2e_st_transformer.E2E</span></code></a></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_conformer.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_conformer.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_conformer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_conformer.E2E.add_conformer_arguments">
<em class="property">static </em><code class="sig-name descname">add_conformer_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_conformer.html#E2E.add_conformer_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_conformer.E2E.add_conformer_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for conformer model.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-asr">
<span id="id62"></span><h2>espnet.nets.pytorch_backend.e2e_asr<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr"></span><p>RNN sequence-to-sequence speech recognition model (pytorch).</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.attention_add_arguments">
<em class="property">static </em><code class="sig-name descname">attention_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.attention_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.attention_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for the attention.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weights with the following shape,
1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
2) other case =&gt; attention weights (B, Lmax, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.calculate_all_ctc_probs">
<code class="sig-name descname">calculate_all_ctc_probs</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.calculate_all_ctc_probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.calculate_all_ctc_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E CTC probability calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>CTC probability (B, Tmax, vocab)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.decoder_add_arguments">
<em class="property">static </em><code class="sig-name descname">decoder_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.decoder_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.decoder_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for the decoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode acoustic features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>ndarray</em>) – input acoustic feature (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoder outputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.encoder_add_arguments">
<em class="property">static </em><code class="sig-name descname">encoder_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.encoder_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.encoder_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for the encoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.enhance">
<code class="sig-name descname">enhance</code><span class="sig-paren">(</span><em class="sig-param">xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.enhance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.enhance" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward only in the frontend stage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>xs</strong> (<em>ndarray</em>) – input acoustic feature (T, C, F)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>enhaned feature</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.init_like_chainer">
<code class="sig-name descname">init_like_chainer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.init_like_chainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.init_like_chainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize weight like chainer.</p>
<p>chainer basically uses LeCun way: W ~ Normal(0, fan_in ** -0.5), b = 0
pytorch basically uses W, b ~ Uniform(-fan_in**-0.5, fan_in**-0.5)
however, there are two exceptions as far as I know.
- EmbedID.W ~ Normal(0, 1)
- LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – input acoustic feature (T, D)</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.recognize_batch">
<code class="sig-name descname">recognize_batch</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.recognize_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.recognize_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E batch beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>list</em>) – list of input acoustic feature arrays [(T_1, D), (T_2, D), …]</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.scorers">
<code class="sig-name descname">scorers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.scorers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.scorers" title="Permalink to this definition">¶</a></dt>
<dd><p>Scorers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.subsample_frames">
<code class="sig-name descname">subsample_frames</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#E2E.subsample_frames"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.subsample_frames" title="Permalink to this definition">¶</a></dt>
<dd><p>Subsample speeh frames in the encoder.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr.Reporter">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr.</code><code class="sig-name descname">Reporter</code><span class="sig-paren">(</span><em class="sig-param">**links</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#Reporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>A chainer reporter wrapper.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.Reporter.report">
<code class="sig-name descname">report</code><span class="sig-paren">(</span><em class="sig-param">loss_ctc</em>, <em class="sig-param">loss_att</em>, <em class="sig-param">acc</em>, <em class="sig-param">cer_ctc</em>, <em class="sig-param">cer</em>, <em class="sig-param">wer</em>, <em class="sig-param">mtl_loss</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr.html#Reporter.report"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.Reporter.report" title="Permalink to this definition">¶</a></dt>
<dd><p>Report at every step.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-asr-mulenc">
<span id="id63"></span><h2>espnet.nets.pytorch_backend.e2e_asr_mulenc<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr-mulenc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr_mulenc"></span><p>Define e2e module for multi-encoder network. <a class="reference external" href="https://arxiv.org/pdf/1811.04903.pdf">https://arxiv.org/pdf/1811.04903.pdf</a>.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_mulenc.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idims</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idims</strong> (<em>List</em>) – List of dimensions of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Initialize this class with python-level args.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idims</strong> (<em>list</em>) – list of the number of an input feature dim.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – The number of output vocab.</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – arguments</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for multi-encoder setting.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.attention_add_arguments">
<em class="property">static </em><code class="sig-name descname">attention_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.attention_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.attention_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for attentions in multi-encoder setting.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs_pad_list</em>, <em class="sig-param">ilens_list</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad_list</strong> (<em>List</em>) – list of batch (torch.Tensor) of padded input sequences
[(B, Tmax_1, idim), (B, Tmax_2, idim),..]</p></li>
<li><p><strong>ilens_list</strong> (<em>List</em>) – list of batch (torch.Tensor) of lengths of input sequences [(B), (B), ..]</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>attention weights with the following shape,
1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
2) multi-encoder case</p>
<blockquote>
<div><p>=&gt; [(B, Lmax, Tmax1), (B, Lmax, Tmax2), …, (B, Lmax, NumEncs)]</p>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>other case =&gt; attention weights (B, Lmax, Tmax).</p></li>
</ol>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray or list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.calculate_all_ctc_probs">
<code class="sig-name descname">calculate_all_ctc_probs</code><span class="sig-paren">(</span><em class="sig-param">xs_pad_list</em>, <em class="sig-param">ilens_list</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.calculate_all_ctc_probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.calculate_all_ctc_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E CTC probability calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad_list</strong> (<em>List</em>) – list of batch (torch.Tensor) of padded input sequences
[(B, Tmax_1, idim), (B, Tmax_2, idim),..]</p></li>
<li><p><strong>ilens_list</strong> (<em>List</em>) – list of batch (torch.Tensor) of lengths of input sequences [(B), (B), ..]</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>CTC probability (B, Tmax, vocab)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray or list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.ctc_add_arguments">
<em class="property">static </em><code class="sig-name descname">ctc_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.ctc_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.ctc_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for ctc in multi-encoder setting.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.decoder_add_arguments">
<em class="property">static </em><code class="sig-name descname">decoder_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.decoder_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.decoder_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for decoder in multi-encoder setting.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">x_list</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode feature.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x_list</strong> (<em>list</em>) – input feature [(T1, D), (T2, D), … ]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>list</dt><dd><p>encoded feature [(T1, D), (T2, D), … ]</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.encoder_add_arguments">
<em class="property">static </em><code class="sig-name descname">encoder_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.encoder_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.encoder_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for encoders in multi-encoder setting.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad_list</em>, <em class="sig-param">ilens_list</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad_list</strong> (<em>List</em>) – list of batch (torch.Tensor) of padded input sequences
[(B, Tmax_1, idim), (B, Tmax_2, idim),..]</p></li>
<li><p><strong>ilens_list</strong> (<em>List</em>) – list of batch (torch.Tensor) of lengths of input sequences [(B), (B), ..]</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.init_like_chainer">
<code class="sig-name descname">init_like_chainer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.init_like_chainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.init_like_chainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize weight like chainer.</p>
<p>chainer basically uses LeCun way: W ~ Normal(0, fan_in ** -0.5), b = 0
pytorch basically uses W, b ~ Uniform(-fan_in**-0.5, fan_in**-0.5)</p>
<p>however, there are two exceptions as far as I know.
- EmbedID.W ~ Normal(0, 1)
- LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">x_list</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>of ndarray x</strong> (<em>list</em>) – list of input acoustic feature [(T1, D), (T2,D),…]</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.recognize_batch">
<code class="sig-name descname">recognize_batch</code><span class="sig-paren">(</span><em class="sig-param">xs_list</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.recognize_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.recognize_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_list</strong> (<em>list</em>) – list of list of input acoustic feature arrays
[[(T1_1, D), (T1_2, D), …],[(T2_1, D), (T2_2, D), …], …]</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.scorers">
<code class="sig-name descname">scorers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#E2E.scorers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.E2E.scorers" title="Permalink to this definition">¶</a></dt>
<dd><p>Get scorers for <cite>beam_search</cite> (optional).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>dict of <cite>ScorerInterface</cite> objects</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict[str, <a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface">ScorerInterface</a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.Reporter">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_mulenc.</code><code class="sig-name descname">Reporter</code><span class="sig-paren">(</span><em class="sig-param">**links</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#Reporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Define a chainer reporter wrapper.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mulenc.Reporter.report">
<code class="sig-name descname">report</code><span class="sig-paren">(</span><em class="sig-param">loss_ctc_list</em>, <em class="sig-param">loss_att</em>, <em class="sig-param">acc</em>, <em class="sig-param">cer_ctc_list</em>, <em class="sig-param">cer</em>, <em class="sig-param">wer</em>, <em class="sig-param">mtl_loss</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mulenc.html#Reporter.report"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mulenc.Reporter.report" title="Permalink to this definition">¶</a></dt>
<dd><p>Define a chainer reporter function.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-st-transformer">
<span id="id64"></span><h2>espnet.nets.pytorch_backend.e2e_st_transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-st-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_st_transformer"></span><p>Transformer speech recognition model (pytorch).</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_st_transformer.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">ignore_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.st_interface.STInterface" title="espnet.nets.st_interface.STInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.st_interface.STInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Return PlotAttentionReport.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">ys_pad_src</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
<li><p><strong>ys_pad_src</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weights (B, H, Lmax, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.calculate_all_ctc_probs">
<code class="sig-name descname">calculate_all_ctc_probs</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">ys_pad_src</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.calculate_all_ctc_probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.calculate_all_ctc_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E CTC probability calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
<li><p><strong>ys_pad_src</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>CTC probability (B, Tmax, vocab)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source acoustic features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>ndarray</em>) – source acoustic feature (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoder outputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">ys_pad_src</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of source sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
<li><p><strong>ys_pad_src</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ctc loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy in attention decoder</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.forward_asr">
<code class="sig-name descname">forward_asr</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em>, <em class="sig-param">hs_mask</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.forward_asr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.forward_asr" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass in the auxiliary ASR task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax, idim)</p></li>
<li><p><strong>hs_mask</strong> (<em>torch.Tensor</em>) – batch of input token mask (B, Lmax)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ASR attention loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy in ASR attention decoder</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ASR CTC loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>character error rate from CTC prediction</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>character error rate from attetion decoder prediction</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>word error rate from attetion decoder prediction</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.forward_mt">
<code class="sig-name descname">forward_mt</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ys_in_pad</em>, <em class="sig-param">ys_out_pad</em>, <em class="sig-param">ys_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.forward_mt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.forward_mt" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass in the auxiliary MT task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax, idim)</p></li>
<li><p><strong>ys_in_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
<li><p><strong>ys_out_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
<li><p><strong>ys_mask</strong> (<em>torch.Tensor</em>) – batch of input token mask (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MT loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy in MT decoder</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize parameters.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.scorers">
<code class="sig-name descname">scorers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.scorers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.scorers" title="Permalink to this definition">¶</a></dt>
<dd><p>Scorers.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_st_transformer.E2E.translate">
<code class="sig-name descname">translate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">trans_args</em>, <em class="sig-param">char_list=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_st_transformer.html#E2E.translate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_st_transformer.E2E.translate" title="Permalink to this definition">¶</a></dt>
<dd><p>Translate input speech.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndnarray</em>) – input acoustic feature (B, T, D) or (T, D)</p></li>
<li><p><strong>trans_args</strong> (<em>Namespace</em>) – argment Namespace contraining options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-vc-transformer">
<span id="id65"></span><h2>espnet.nets.pytorch_backend.e2e_vc_transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-vc-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_vc_transformer"></span><p>Voice Transformer Network (Transformer-VC) related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_vc_transformer.</code><code class="sig-name descname">Transformer</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_transformer.html#Transformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.tts_interface.TTSInterface" title="espnet.nets.tts_interface.TTSInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.tts_interface.TTSInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>VC Transformer module.</p>
<p>This is a module of the Voice Transformer Network
(a.k.a. VTN or Transformer-VC) described in
<a class="reference external" href="https://arxiv.org/pdf/1912.06813.pdf">Voice Transformer Network: Sequence-to-Sequence
Voice Conversion Using Transformer with
Text-to-Speech Pretraining</a>,
which convert the sequence of acoustic features
into the sequence of acoustic features.</p>
<p>Initialize Transformer-VC module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>args</strong> (<em>Namespace</em><em>, </em><em>optional</em>) – <ul>
<li><dl class="simple">
<dt>eprenet_conv_layers (int):</dt><dd><p>Number of encoder prenet convolution layers.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>eprenet_conv_chans (int):</dt><dd><p>Number of encoder prenet convolution channels.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>eprenet_conv_filts (int):</dt><dd><p>Filter size of encoder prenet convolution.</p>
</dd>
</dl>
</li>
<li><p>transformer_input_layer (str): Input layer before the encoder.</p></li>
<li><p>dprenet_layers (int): Number of decoder prenet layers.</p></li>
<li><p>dprenet_units (int): Number of decoder prenet hidden units.</p></li>
<li><p>elayers (int): Number of encoder layers.</p></li>
<li><p>eunits (int): Number of encoder hidden units.</p></li>
<li><p>adim (int): Number of attention transformation dimensions.</p></li>
<li><p>aheads (int): Number of heads for multi head attention.</p></li>
<li><p>dlayers (int): Number of decoder layers.</p></li>
<li><p>dunits (int): Number of decoder hidden units.</p></li>
<li><p>postnet_layers (int): Number of postnet layers.</p></li>
<li><p>postnet_chans (int): Number of postnet channels.</p></li>
<li><p>postnet_filts (int): Filter size of postnet.</p></li>
<li><dl class="simple">
<dt>use_scaled_pos_enc (bool):</dt><dd><p>Whether to use trainable scaled positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>use_batch_norm (bool):</dt><dd><p>Whether to use batch normalization in encoder prenet.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>encoder_normalize_before (bool):</dt><dd><p>Whether to perform layer normalization before encoder block.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_normalize_before (bool):</dt><dd><p>Whether to perform layer normalization before decoder block.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>encoder_concat_after (bool): Whether to concatenate</dt><dd><p>attention layer’s input and output in encoder.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>decoder_concat_after (bool): Whether to concatenate</dt><dd><p>attention layer’s input and output in decoder.</p>
</dd>
</dl>
</li>
<li><p>reduction_factor (int): Reduction factor (for decoder).</p></li>
<li><p>encoder_reduction_factor (int): Reduction factor (for encoder).</p></li>
<li><p>spk_embed_dim (int): Number of speaker embedding dimenstions.</p></li>
<li><p>spk_embed_integration_type: How to integrate speaker embedding.</p></li>
<li><p>transformer_init (float): How to initialize transformer parameters.</p></li>
<li><p>transformer_lr (float): Initial value of learning rate.</p></li>
<li><p>transformer_warmup_steps (int): Optimizer warmup steps.</p></li>
<li><dl class="simple">
<dt>transformer_enc_dropout_rate (float):</dt><dd><p>Dropout rate in encoder except attention &amp; positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_enc_positional_dropout_rate (float):</dt><dd><p>Dropout rate after encoder positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_enc_attn_dropout_rate (float):</dt><dd><p>Dropout rate in encoder self-attention module.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_dec_dropout_rate (float):</dt><dd><p>Dropout rate in decoder except attention &amp; positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_dec_positional_dropout_rate (float):</dt><dd><p>Dropout rate after decoder positional encoding.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_dec_attn_dropout_rate (float):</dt><dd><p>Dropout rate in deocoder self-attention module.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>transformer_enc_dec_attn_dropout_rate (float):</dt><dd><p>Dropout rate in encoder-deocoder attention module.</p>
</dd>
</dl>
</li>
<li><p>eprenet_dropout_rate (float): Dropout rate in encoder prenet.</p></li>
<li><p>dprenet_dropout_rate (float): Dropout rate in decoder prenet.</p></li>
<li><p>postnet_dropout_rate (float): Dropout rate in postnet.</p></li>
<li><dl class="simple">
<dt>use_masking (bool):</dt><dd><p>Whether to apply masking for padded part in loss calculation.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>use_weighted_masking (bool):</dt><dd><p>Whether to apply weighted masking in loss calculation.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>bce_pos_weight (float): Positive sample weight in bce calculation</dt><dd><p>(only for use_masking=true).</p>
</dd>
</dl>
</li>
<li><p>loss_type (str): How to calculate loss.</p></li>
<li><p>use_guided_attn_loss (bool): Whether to use guided attention loss.</p></li>
<li><dl class="simple">
<dt>num_heads_applied_guided_attn (int):</dt><dd><p>Number of heads in each layer to apply guided attention loss.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>num_layers_applied_guided_attn (int):</dt><dd><p>Number of layers to apply guided attention loss.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>modules_applied_guided_attn (list):</dt><dd><p>List of module names to apply guided attention loss.</p>
</dd>
</dl>
</li>
<li><p>guided-attn-loss-sigma (float) Sigma in guided attention loss.</p></li>
<li><p>guided-attn-loss-lambda (float): Lambda in guided attention loss.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_transformer.html#Transformer.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add model-specific arguments to the parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Return plot class for attention weight plot.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.base_plot_keys">
<em class="property">property </em><code class="sig-name descname">base_plot_keys</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.base_plot_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>Return base key names to plot during training.</p>
<p>keys should match what <cite>chainer.reporter</cite> reports.
If you add the key <cite>loss</cite>, the reporter will report <cite>main/loss</cite></p>
<blockquote>
<div><p>and <cite>validation/main/loss</cite> values.</p>
</div></blockquote>
<dl class="simple">
<dt>also <cite>loss.png</cite> will be created as a figure visulizing <cite>main/loss</cite></dt><dd><p>and <cite>validation/main/loss</cite> values.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of strings which are base keys to plot during training.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">olens</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">skip_output=False</em>, <em class="sig-param">keep_tensor=False</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_transformer.html#Transformer.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all of the attention weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded acoustic features (B, Tmax, idim).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors
(B, spk_embed_dim).</p></li>
<li><p><strong>skip_output</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to skip calculate the final output.</p></li>
<li><p><strong>keep_tensor</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to keep original tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict of attention weights and outputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">labels</em>, <em class="sig-param">olens</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_transformer.html#Transformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded acoustic features (B, Tmax, idim).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors
(B, spk_embed_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">inference_args</em>, <em class="sig-param">spemb=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_transformer.html#Transformer.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_transformer.Transformer.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate the sequence of features given the sequences of acoustic features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input sequence of acoustic features (T, idim).</p></li>
<li><p><strong>inference_args</strong> (<em>Namespace</em>) – <ul>
<li><p>threshold (float): Threshold in inference.</p></li>
<li><p>minlenratio (float): Minimum length ratio in inference.</p></li>
<li><p>maxlenratio (float): Maximum length ratio in inference.</p></li>
</ul>
</p></li>
<li><p><strong>spemb</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Speaker embedding vector (spk_embed_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequence of features (L, odim).
Tensor: Output sequence of stop probabilities (L,).
Tensor: Encoder-decoder (source) attention weights (#layers, #heads, L, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-asr-mix">
<span id="id66"></span><h2>espnet.nets.pytorch_backend.e2e_asr_mix<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr-mix" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr_mix"></span><p>This script is used to construct End-to-End models of multi-speaker ASR.</p>
<dl class="simple">
<dt>Copyright 2017 Johns Hopkins University (Shinji Watanabe)</dt><dd><p>Apache 2.0  (<a class="reference external" href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a>)</p>
</dd>
</dl>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_mix.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Initialize multi-speaker E2E module.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, num_spkrs, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weights with the following shape,
1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
2) other case =&gt; attention weights (B, Lmax, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.encoder_mix_add_arguments">
<em class="property">static </em><code class="sig-name descname">encoder_mix_add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E.encoder_mix_add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.encoder_mix_add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for multi-speaker encoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.enhance">
<code class="sig-name descname">enhance</code><span class="sig-paren">(</span><em class="sig-param">xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E.enhance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.enhance" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward only the frontend stage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>xs</strong> (<em>ndarray</em>) – input acoustic feature (T, C, F)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, num_spkrs, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ctc loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy in attention decoder</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.init_like_chainer">
<code class="sig-name descname">init_like_chainer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E.init_like_chainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.init_like_chainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize weight like chainer.</p>
<p>chainer basically uses LeCun way: W ~ Normal(0, fan_in ** -0.5), b = 0
pytorch basically uses W, b ~ Uniform(-fan_in**-0.5, fan_in**-0.5)</p>
<p>however, there are two exceptions as far as I know.
- EmbedID.W ~ Normal(0, 1)
- LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – input acoustic feature (T, D)</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.recognize_batch">
<code class="sig-name descname">recognize_batch</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#E2E.recognize_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.recognize_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>ndarray</em>) – input acoustic feature (T, D)</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.EncoderMix">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_mix.</code><code class="sig-name descname">EncoderMix</code><span class="sig-paren">(</span><em class="sig-param">etype</em>, <em class="sig-param">idim</em>, <em class="sig-param">elayers_sd</em>, <em class="sig-param">elayers_rec</em>, <em class="sig-param">eunits</em>, <em class="sig-param">eprojs</em>, <em class="sig-param">subsample</em>, <em class="sig-param">dropout</em>, <em class="sig-param">num_spkrs=2</em>, <em class="sig-param">in_channel=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#EncoderMix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.EncoderMix" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encoder module for the case of multi-speaker mixture speech.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>etype</strong> (<em>str</em>) – type of encoder network</p></li>
<li><p><strong>idim</strong> (<em>int</em>) – number of dimensions of encoder network</p></li>
<li><p><strong>elayers_sd</strong> (<em>int</em>) – number of layers of speaker differentiate part in encoder network</p></li>
<li><p><strong>elayers_rec</strong> (<em>int</em>) – number of layers of shared recognition part in encoder network</p></li>
<li><p><strong>eunits</strong> (<em>int</em>) – number of lstm units of encoder network</p></li>
<li><p><strong>eprojs</strong> (<em>int</em>) – number of projection units of encoder network</p></li>
<li><p><strong>subsample</strong> (<em>np.ndarray</em>) – list of subsampling numbers</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout rate</p></li>
<li><p><strong>in_channel</strong> (<em>int</em>) – number of input channels</p></li>
<li><p><strong>num_spkrs</strong> (<em>int</em>) – number of number of speakers</p></li>
</ul>
</dd>
</dl>
<p>Initialize the encoder of single-channel multi-speaker ASR.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.EncoderMix.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#EncoderMix.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.EncoderMix.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodermix forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, D)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list: batch of hidden state sequences [num_spkrs x (B, Tmax, eprojs)]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.PIT">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_mix.</code><code class="sig-name descname">PIT</code><span class="sig-paren">(</span><em class="sig-param">num_spkrs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#PIT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.PIT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Permutation Invariant Training (PIT) module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>num_spkrs</strong> (<em>int</em>) – number of speakers for PIT process (2 or 3)</p>
</dd>
</dl>
<p>Initialize PIT module.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.PIT.min_pit_sample">
<code class="sig-name descname">min_pit_sample</code><span class="sig-paren">(</span><em class="sig-param">loss</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#PIT.min_pit_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.PIT.min_pit_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the PIT loss for each sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>torch.Tensor loss</strong> (<em>1-D</em>) – list of losses for one sample,
including [h1r1, h1r2, h2r1, h2r2] or
[h1r1, h1r2, h1r3, h2r1, h2r2, h2r3, h3r1, h3r2, h3r3]</p>
</dd>
</dl>
<p>:return minimum loss of best permutation
:rtype torch.Tensor (1)
:return the best permutation
:rtype List: len=2</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.PIT.permutationDFS">
<code class="sig-name descname">permutationDFS</code><span class="sig-paren">(</span><em class="sig-param">source</em>, <em class="sig-param">start</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#PIT.permutationDFS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.PIT.permutationDFS" title="Permalink to this definition">¶</a></dt>
<dd><p>Get permutations with DFS.</p>
<blockquote>
<div><p>The final result is all permutations of the ‘source’ sequence.
e.g. [[1, 2], [2, 1]] or</p>
<blockquote>
<div><p>[[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 2, 1], [3, 1, 2]]</p>
</div></blockquote>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<em>np.ndarray</em>) – (num_spkrs, 1), e.g. [1, 2, …, N]</p></li>
<li><p><strong>start</strong> (<em>int</em>) – the start point to permute</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.PIT.pit_process">
<code class="sig-name descname">pit_process</code><span class="sig-paren">(</span><em class="sig-param">losses</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#PIT.pit_process"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.PIT.pit_process" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the PIT loss for a batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>losses</strong> (<em>torch.Tensor</em>) – losses (B, 1|4|9)</p>
</dd>
</dl>
<p>:return minimum losses of a batch with best permutation
:rtype torch.Tensor (B)
:return the best permutation
:rtype torch.LongTensor (B, 1|2|3)</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.encoder_for">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_mix.</code><code class="sig-name descname">encoder_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">idim</em>, <em class="sig-param">subsample</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_mix.html#encoder_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.encoder_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct the encoder.</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-asr-transformer">
<span id="id67"></span><h2>espnet.nets.pytorch_backend.e2e_asr_transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr_transformer"></span><p>Transformer speech recognition model (pytorch).</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_transformer.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">ignore_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.attention_plot_class">
<em class="property">property </em><code class="sig-name descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Return PlotAttentionReport.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weights (B, H, Lmax, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.calculate_all_ctc_probs">
<code class="sig-name descname">calculate_all_ctc_probs</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E.calculate_all_ctc_probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.calculate_all_ctc_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E CTC probability calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded token id sequence tensor (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>CTC probability (B, Tmax, vocab)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode acoustic features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>ndarray</em>) – source acoustic feature (T, D)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoder outputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of source sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ctc loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy in attention decoder</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.get_total_subsampling_factor">
<code class="sig-name descname">get_total_subsampling_factor</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E.get_total_subsampling_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.get_total_subsampling_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Get total subsampling factor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em>, <em class="sig-param">use_jit=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize input speech.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndnarray</em>) – input acoustic feature (B, T, D) or (T, D)</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argment Namespace contraining options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize parameters.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.scorers">
<code class="sig-name descname">scorers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_transformer.html#E2E.scorers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.scorers" title="Permalink to this definition">¶</a></dt>
<dd><p>Scorers.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-nets-utils">
<span id="id68"></span><h2>espnet.nets.pytorch_backend.nets_utils<a class="headerlink" href="#espnet-nets-pytorch-backend-nets-utils" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.nets_utils"></span><p>Network related utility tools.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.get_activation">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">get_activation</code><span class="sig-paren">(</span><em class="sig-param">act</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#get_activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.get_activation" title="Permalink to this definition">¶</a></dt>
<dd><p>Return activation function.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.get_subsample">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">get_subsample</code><span class="sig-paren">(</span><em class="sig-param">train_args</em>, <em class="sig-param">mode</em>, <em class="sig-param">arch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#get_subsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.get_subsample" title="Permalink to this definition">¶</a></dt>
<dd><p>Parse the subsampling factors from the args for the specified <cite>mode</cite> and <cite>arch</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_args</strong> – argument Namespace containing options.</p></li>
<li><p><strong>mode</strong> – one of (‘asr’, ‘mt’, ‘st’)</p></li>
<li><p><strong>arch</strong> – one of (‘rnn’, ‘rnn-t’, ‘rnn_mix’, ‘rnn_mulenc’, ‘transformer’)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>subsampling factors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>np.ndarray / List[np.ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.make_non_pad_mask">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">make_non_pad_mask</code><span class="sig-paren">(</span><em class="sig-param">lengths</em>, <em class="sig-param">xs=None</em>, <em class="sig-param">length_dim=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#make_non_pad_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.make_non_pad_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Make mask tensor containing indices of non-padded part.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lengths</strong> (<em>LongTensor</em><em> or </em><em>List</em>) – Batch of lengths (B,).</p></li>
<li><p><strong>xs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – The reference tensor.
If set, masks will be the same shape as this tensor.</p></li>
<li><p><strong>length_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Dimension indicator of the above tensor.
See the example.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>mask tensor containing indices of padded part.</dt><dd><p>dtype=torch.uint8 in PyTorch 1.2-
dtype=torch.bool in PyTorch 1.2+ (including 1.2)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ByteTensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>With only lengths.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
<span class="go">masks = [[1, 1, 1, 1 ,1],</span>
<span class="go">         [1, 1, 1, 0, 0],</span>
<span class="go">         [1, 1, 0, 0, 0]]</span>
</pre></div>
</div>
<p>With the reference tensor.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
<span class="go">tensor([[[1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1]],</span>
<span class="go">        [[1, 1, 1, 0],</span>
<span class="go">         [1, 1, 1, 0]],</span>
<span class="go">        [[1, 1, 0, 0],</span>
<span class="go">         [1, 1, 0, 0]]], dtype=torch.uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
<span class="go">tensor([[[1, 1, 1, 1, 1, 0],</span>
<span class="go">         [1, 1, 1, 1, 1, 0]],</span>
<span class="go">        [[1, 1, 1, 0, 0, 0],</span>
<span class="go">         [1, 1, 1, 0, 0, 0]],</span>
<span class="go">        [[1, 1, 0, 0, 0, 0],</span>
<span class="go">         [1, 1, 0, 0, 0, 0]]], dtype=torch.uint8)</span>
</pre></div>
</div>
<p>With the reference tensor and dimension indicator.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([[[1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [0, 0, 0, 0, 0, 0]],</span>
<span class="go">        [[1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0]],</span>
<span class="go">        [[1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([[[1, 1, 1, 1, 1, 0],</span>
<span class="go">         [1, 1, 1, 1, 1, 0],</span>
<span class="go">         [1, 1, 1, 1, 1, 0],</span>
<span class="go">         [1, 1, 1, 1, 1, 0],</span>
<span class="go">         [1, 1, 1, 1, 1, 0],</span>
<span class="go">         [1, 1, 1, 1, 1, 0]],</span>
<span class="go">        [[1, 1, 1, 0, 0, 0],</span>
<span class="go">         [1, 1, 1, 0, 0, 0],</span>
<span class="go">         [1, 1, 1, 0, 0, 0],</span>
<span class="go">         [1, 1, 1, 0, 0, 0],</span>
<span class="go">         [1, 1, 1, 0, 0, 0],</span>
<span class="go">         [1, 1, 1, 0, 0, 0]],</span>
<span class="go">        [[1, 1, 0, 0, 0, 0],</span>
<span class="go">         [1, 1, 0, 0, 0, 0],</span>
<span class="go">         [1, 1, 0, 0, 0, 0],</span>
<span class="go">         [1, 1, 0, 0, 0, 0],</span>
<span class="go">         [1, 1, 0, 0, 0, 0],</span>
<span class="go">         [1, 1, 0, 0, 0, 0]]], dtype=torch.uint8)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.make_pad_mask">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">make_pad_mask</code><span class="sig-paren">(</span><em class="sig-param">lengths</em>, <em class="sig-param">xs=None</em>, <em class="sig-param">length_dim=-1</em>, <em class="sig-param">maxlen=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#make_pad_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.make_pad_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Make mask tensor containing indices of padded part.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lengths</strong> (<em>LongTensor</em><em> or </em><em>List</em>) – Batch of lengths (B,).</p></li>
<li><p><strong>xs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – The reference tensor.
If set, masks will be the same shape as this tensor.</p></li>
<li><p><strong>length_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Dimension indicator of the above tensor.
See the example.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Mask tensor containing indices of padded part.</dt><dd><p>dtype=torch.uint8 in PyTorch 1.2-
dtype=torch.bool in PyTorch 1.2+ (including 1.2)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>With only lengths.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
<span class="go">masks = [[0, 0, 0, 0 ,0],</span>
<span class="go">         [0, 0, 0, 1, 1],</span>
<span class="go">         [0, 0, 1, 1, 1]]</span>
</pre></div>
</div>
<p>With the reference tensor.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
<span class="go">tensor([[[0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0]],</span>
<span class="go">        [[0, 0, 0, 1],</span>
<span class="go">         [0, 0, 0, 1]],</span>
<span class="go">        [[0, 0, 1, 1],</span>
<span class="go">         [0, 0, 1, 1]]], dtype=torch.uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
<span class="go">tensor([[[0, 0, 0, 0, 0, 1],</span>
<span class="go">         [0, 0, 0, 0, 0, 1]],</span>
<span class="go">        [[0, 0, 0, 1, 1, 1],</span>
<span class="go">         [0, 0, 0, 1, 1, 1]],</span>
<span class="go">        [[0, 0, 1, 1, 1, 1],</span>
<span class="go">         [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)</span>
</pre></div>
</div>
<p>With the reference tensor and dimension indicator.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([[[0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [1, 1, 1, 1, 1, 1]],</span>
<span class="go">        [[0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1]],</span>
<span class="go">        [[0, 0, 0, 0, 0, 0],</span>
<span class="go">         [0, 0, 0, 0, 0, 0],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1],</span>
<span class="go">         [1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">tensor([[[0, 0, 0, 0, 0, 1],</span>
<span class="go">         [0, 0, 0, 0, 0, 1],</span>
<span class="go">         [0, 0, 0, 0, 0, 1],</span>
<span class="go">         [0, 0, 0, 0, 0, 1],</span>
<span class="go">         [0, 0, 0, 0, 0, 1],</span>
<span class="go">         [0, 0, 0, 0, 0, 1]],</span>
<span class="go">        [[0, 0, 0, 1, 1, 1],</span>
<span class="go">         [0, 0, 0, 1, 1, 1],</span>
<span class="go">         [0, 0, 0, 1, 1, 1],</span>
<span class="go">         [0, 0, 0, 1, 1, 1],</span>
<span class="go">         [0, 0, 0, 1, 1, 1],</span>
<span class="go">         [0, 0, 0, 1, 1, 1]],</span>
<span class="go">        [[0, 0, 1, 1, 1, 1],</span>
<span class="go">         [0, 0, 1, 1, 1, 1],</span>
<span class="go">         [0, 0, 1, 1, 1, 1],</span>
<span class="go">         [0, 0, 1, 1, 1, 1],</span>
<span class="go">         [0, 0, 1, 1, 1, 1],</span>
<span class="go">         [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.mask_by_length">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">mask_by_length</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">lengths</em>, <em class="sig-param">fill=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#mask_by_length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.mask_by_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Mask tensor according to length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of input tensor (B, <cite>*</cite>).</p></li>
<li><p><strong>lengths</strong> (<em>LongTensor</em><em> or </em><em>List</em>) – Batch of lengths (B,).</p></li>
<li><p><strong>fill</strong> (<em>int</em><em> or </em><em>float</em>) – Value to fill masked part.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of masked input tensor (B, <cite>*</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">tensor([[1, 2, 3, 4, 5],</span>
<span class="go">        [1, 2, 3, 4, 5],</span>
<span class="go">        [1, 2, 3, 4, 5]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask_by_length</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>
<span class="go">tensor([[1, 2, 3, 4, 5],</span>
<span class="go">        [1, 2, 3, 0, 0],</span>
<span class="go">        [1, 2, 0, 0, 0]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.pad_list">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">pad_list</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">pad_value</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#pad_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.pad_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform padding for the list of tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>List</em>) – List of Tensors [(T_1, <cite>*</cite>), (T_2, <cite>*</cite>), …, (T_B, <cite>*</cite>)].</p></li>
<li><p><strong>pad_value</strong> (<em>float</em>) – Value for padding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Padded tensor (B, Tmax, <cite>*</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">[tensor([1., 1., 1., 1.]), tensor([1., 1.]), tensor([1.])]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pad_list</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="go">tensor([[1., 1., 1., 1.],</span>
<span class="go">        [1., 1., 0., 0.],</span>
<span class="go">        [1., 0., 0., 0.]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.rename_state_dict">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">rename_state_dict</code><span class="sig-paren">(</span><em class="sig-param">old_prefix: str, new_prefix: str, state_dict: Dict[str, torch.Tensor]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#rename_state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.rename_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Replace keys of old prefix with new prefix in state dict.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.th_accuracy">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">th_accuracy</code><span class="sig-paren">(</span><em class="sig-param">pad_outputs</em>, <em class="sig-param">pad_targets</em>, <em class="sig-param">ignore_label</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#th_accuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.th_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pad_outputs</strong> (<em>Tensor</em>) – Prediction tensors (B * Lmax, D).</p></li>
<li><p><strong>pad_targets</strong> (<em>LongTensor</em>) – Target label tensors (B, Lmax, D).</p></li>
<li><p><strong>ignore_label</strong> (<em>int</em>) – Ignore label id.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Accuracy value (0.0 - 1.0).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.to_device">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">to_device</code><span class="sig-paren">(</span><em class="sig-param">m</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#to_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Send tensor into the device of the module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> (<em>torch.nn.Module</em>) – Torch module.</p></li>
<li><p><strong>x</strong> (<em>Tensor</em>) – Torch tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Torch tensor located in the same place as torch module.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.to_torch_tensor">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="sig-name descname">to_torch_tensor</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/nets_utils.html#to_torch_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.to_torch_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Change to torch.Tensor or ComplexTensor from numpy.ndarray.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – Inputs. It should be one of numpy.ndarray, Tensor, ComplexTensor, and dict.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type converted inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor or ComplexTensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="go">tensor([1., 1., 1.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="ow">is</span> <span class="n">xs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;real&#39;</span><span class="p">:</span> <span class="n">xs</span><span class="p">,</span> <span class="s1">&#39;imag&#39;</span><span class="p">:</span> <span class="n">xs</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="go">ComplexTensor(</span>
<span class="go">Real:</span>
<span class="go">tensor([1., 1., 1.])</span>
<span class="go">Imag;</span>
<span class="go">tensor([1., 1., 1.])</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-vc-tacotron2">
<span id="id69"></span><h2>espnet.nets.pytorch_backend.e2e_vc_tacotron2<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-vc-tacotron2" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_vc_tacotron2"></span><p>Tacotron2-VC related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_vc_tacotron2.</code><code class="sig-name descname">Tacotron2</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_tacotron2.html#Tacotron2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.tts_interface.TTSInterface" title="espnet.nets.tts_interface.TTSInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.tts_interface.TTSInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>VC Tacotron2 module for VC.</p>
<p>This is a module of Tacotron2-based VC model,
which convert the sequence of acoustic features
into the sequence of acoustic features.</p>
<p>Initialize Tacotron2 module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>args</strong> (<em>Namespace</em><em>, </em><em>optional</em>) – <ul>
<li><p>spk_embed_dim (int): Dimension of the speaker embedding.</p></li>
<li><p>elayers (int): The number of encoder blstm layers.</p></li>
<li><p>eunits (int): The number of encoder blstm units.</p></li>
<li><p>econv_layers (int): The number of encoder conv layers.</p></li>
<li><p>econv_filts (int): The number of encoder conv filter size.</p></li>
<li><p>econv_chans (int): The number of encoder conv filter channels.</p></li>
<li><p>dlayers (int): The number of decoder lstm layers.</p></li>
<li><p>dunits (int): The number of decoder lstm units.</p></li>
<li><p>prenet_layers (int): The number of prenet layers.</p></li>
<li><p>prenet_units (int): The number of prenet units.</p></li>
<li><p>postnet_layers (int): The number of postnet layers.</p></li>
<li><p>postnet_filts (int): The number of postnet filter size.</p></li>
<li><p>postnet_chans (int): The number of postnet filter channels.</p></li>
<li><p>output_activation (int): The name of activation function for outputs.</p></li>
<li><p>adim (int): The number of dimension of mlp in attention.</p></li>
<li><p>aconv_chans (int): The number of attention conv filter channels.</p></li>
<li><p>aconv_filts (int): The number of attention conv filter size.</p></li>
<li><p>cumulate_att_w (bool): Whether to cumulate previous attention weight.</p></li>
<li><p>use_batch_norm (bool): Whether to use batch normalization.</p></li>
<li><dl class="simple">
<dt>use_concate (int):</dt><dd><p>Whether to concatenate encoder embedding with decoder lstm outputs.</p>
</dd>
</dl>
</li>
<li><p>dropout_rate (float): Dropout rate.</p></li>
<li><p>zoneout_rate (float): Zoneout rate.</p></li>
<li><p>reduction_factor (int): Reduction factor.</p></li>
<li><p>spk_embed_dim (int): Number of speaker embedding dimenstions.</p></li>
<li><dl class="simple">
<dt>spc_dim (int): Number of spectrogram embedding dimenstions</dt><dd><p>(only for use_cbhg=True).</p>
</dd>
</dl>
</li>
<li><p>use_cbhg (bool): Whether to use CBHG module.</p></li>
<li><dl class="simple">
<dt>cbhg_conv_bank_layers (int):</dt><dd><p>The number of convoluional banks in CBHG.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>cbhg_conv_bank_chans (int):</dt><dd><p>The number of channels of convolutional bank in CBHG.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>cbhg_proj_filts (int):</dt><dd><p>The number of filter size of projection layeri in CBHG.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>cbhg_proj_chans (int):</dt><dd><p>The number of channels of projection layer in CBHG.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>cbhg_highway_layers (int):</dt><dd><p>The number of layers of highway network in CBHG.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>cbhg_highway_units (int):</dt><dd><p>The number of units of highway network in CBHG.</p>
</dd>
</dl>
</li>
<li><p>cbhg_gru_units (int): The number of units of GRU in CBHG.</p></li>
<li><p>use_masking (bool): Whether to mask padded part in loss calculation.</p></li>
<li><dl class="simple">
<dt>bce_pos_weight (float): Weight of positive sample of stop token</dt><dd><p>(only for use_masking=True).</p>
</dd>
</dl>
</li>
<li><p>use-guided-attn-loss (bool): Whether to use guided attention loss.</p></li>
<li><p>guided-attn-loss-sigma (float) Sigma in guided attention loss.</p></li>
<li><p>guided-attn-loss-lamdba (float): Lambda in guided attention loss.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_tacotron2.html#Tacotron2.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add model-specific arguments to the parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.base_plot_keys">
<em class="property">property </em><code class="sig-name descname">base_plot_keys</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.base_plot_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>Return base key names to plot during training.</p>
<p>keys should match what <cite>chainer.reporter</cite> reports.
If you add the key <cite>loss</cite>, the reporter will report <cite>main/loss</cite></p>
<blockquote>
<div><p>and <cite>validation/main/loss</cite> values.</p>
</div></blockquote>
<dl class="simple">
<dt>also <cite>loss.png</cite> will be created as a figure visulizing <cite>main/loss</cite></dt><dd><p>and <cite>validation/main/loss</cite> values.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of strings which are base keys to plot during training.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_tacotron2.html#Tacotron2.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all of the attention weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded acoustic features (B, Tmax, idim).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors (B, spk_embed_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of attention weights (B, Lmax, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">labels</em>, <em class="sig-param">olens</em>, <em class="sig-param">spembs=None</em>, <em class="sig-param">spcs=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_tacotron2.html#Tacotron2.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of padded acoustic features (B, Tmax, idim).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of padded target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each target (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors (B, spk_embed_dim).</p></li>
<li><p><strong>spcs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of groundtruth spectrograms (B, Lmax, spc_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">inference_args</em>, <em class="sig-param">spemb=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_vc_tacotron2.html#Tacotron2.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_vc_tacotron2.Tacotron2.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate the sequence of features given the sequences of characters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Input sequence of acoustic features (T, idim).</p></li>
<li><p><strong>inference_args</strong> (<em>Namespace</em>) – <ul>
<li><p>threshold (float): Threshold in inference.</p></li>
<li><p>minlenratio (float): Minimum length ratio in inference.</p></li>
<li><p>maxlenratio (float): Maximum length ratio in inference.</p></li>
</ul>
</p></li>
<li><p><strong>spemb</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Speaker embedding vector (spk_embed_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequence of features (L, odim).
Tensor: Output sequence of stop probabilities (L,).
Tensor: Attention weights (L, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-e2e-asr-maskctc">
<span id="id70"></span><h2>espnet.nets.pytorch_backend.e2e_asr_maskctc<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr-maskctc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr_maskctc"></span><p>Mask CTC based non-autoregressive speech recognition model (pytorch).</p>
<p>See <a class="reference external" href="https://arxiv.org/abs/2005.08700">https://arxiv.org/abs/2005.08700</a> for the detail.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.e2e_asr_maskctc.</code><code class="sig-name descname">E2E</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">args</em>, <em class="sig-param">ignore_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_maskctc.html#E2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E" title="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.e2e_asr_transformer.E2E</span></code></a></p>
<p>E2E module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<p>Construct an E2E object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_maskctc.html#E2E.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E.add_maskctc_arguments">
<em class="property">static </em><code class="sig-name descname">add_maskctc_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_maskctc.html#E2E.add_maskctc_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E.add_maskctc_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for maskctc model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_maskctc.html#E2E.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of source sequences (B)</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ctc loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy in attention decoder</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E.recognize">
<code class="sig-name descname">recognize</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/e2e_asr_maskctc.html#E2E.recognize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_maskctc.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>Recognize input speech.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndnarray</em>) – input acoustic feature (B, T, D) or (T, D)</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argment Namespace contraining options</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of characters</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>decoding result</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-conformer-encoder">
<span id="id71"></span><h2>espnet.nets.pytorch_backend.conformer.encoder<a class="headerlink" href="#espnet-nets-pytorch-backend-conformer-encoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.conformer.encoder"></span><p>Encoder definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.conformer.encoder.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.conformer.encoder.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">attention_dim=256</em>, <em class="sig-param">attention_heads=4</em>, <em class="sig-param">linear_units=2048</em>, <em class="sig-param">num_blocks=6</em>, <em class="sig-param">dropout_rate=0.1</em>, <em class="sig-param">positional_dropout_rate=0.1</em>, <em class="sig-param">attention_dropout_rate=0.0</em>, <em class="sig-param">input_layer='conv2d'</em>, <em class="sig-param">normalize_before=True</em>, <em class="sig-param">concat_after=False</em>, <em class="sig-param">positionwise_layer_type='linear'</em>, <em class="sig-param">positionwise_conv_kernel_size=1</em>, <em class="sig-param">macaron_style=False</em>, <em class="sig-param">pos_enc_layer_type='abs_pos'</em>, <em class="sig-param">selfattention_layer_type='selfattn'</em>, <em class="sig-param">activation_type='swish'</em>, <em class="sig-param">use_cnn_module=False</em>, <em class="sig-param">zero_triu=False</em>, <em class="sig-param">cnn_module_kernel=31</em>, <em class="sig-param">padding_idx=-1</em>, <em class="sig-param">stochastic_depth_rate=0.0</em>, <em class="sig-param">intermediate_layers=None</em>, <em class="sig-param">ctc_softmax=None</em>, <em class="sig-param">conditioning_layer_dim=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/encoder.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.encoder.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Conformer encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>attention_dim</strong> (<em>int</em>) – Dimension of attention.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – The number of heads of multi head attention.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – The number of units of position-wise feed forward.</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em>) – The number of decoder blocks.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – Dropout rate after adding positional encoding.</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – Dropout rate in attention.</p></li>
<li><p><strong>input_layer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.nn.Module</em><em>]</em>) – Input layer type.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>positionwise_layer_type</strong> (<em>str</em>) – “linear”, “conv1d”, or “conv1d-linear”.</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – Kernel size of positionwise conv1d layer.</p></li>
<li><p><strong>macaron_style</strong> (<em>bool</em>) – Whether to use macaron style for positionwise layer.</p></li>
<li><p><strong>pos_enc_layer_type</strong> (<em>str</em>) – Encoder positional encoding layer type.</p></li>
<li><p><strong>selfattention_layer_type</strong> (<em>str</em>) – Encoder attention layer type.</p></li>
<li><p><strong>activation_type</strong> (<em>str</em>) – Encoder activation function type.</p></li>
<li><p><strong>use_cnn_module</strong> (<em>bool</em>) – Whether to use convolution module.</p></li>
<li><p><strong>zero_triu</strong> (<em>bool</em>) – Whether to zero the upper triangular part of attention matrix.</p></li>
<li><p><strong>cnn_module_kernel</strong> (<em>int</em>) – Kernerl size of convolution module.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em>) – Padding idx for input_layer=embed.</p></li>
<li><p><strong>stochastic_depth_rate</strong> (<em>float</em>) – Maximum probability to skip the encoder layer.</p></li>
<li><p><strong>intermediate_layers</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>None</em><em>]</em>) – indices of intermediate CTC layer.
indices start from 1.
if not None, intermediate outputs are returned (which changes return type
signature.)</p></li>
</ul>
</dd>
</dl>
<p>Construct an Encoder object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.conformer.encoder.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">masks</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/encoder.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.encoder.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, idim).</p></li>
<li><p><strong>masks</strong> (<em>torch.Tensor</em>) – Mask tensor (#batch, time).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time, attention_dim).
torch.Tensor: Mask tensor (#batch, time).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-conformer-contextual-block-encoder-layer">
<span id="id72"></span><h2>espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer<a class="headerlink" href="#espnet-nets-pytorch-backend-conformer-contextual-block-encoder-layer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer"></span><p>Created on Sat Aug 21 16:57:31 2021.</p>
<p>&#64;author: Keqi Deng (UCAS)</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.</code><code class="sig-name descname">ContextualBlockEncoderLayer</code><span class="sig-paren">(</span><em class="sig-param">size</em>, <em class="sig-param">self_attn</em>, <em class="sig-param">feed_forward</em>, <em class="sig-param">feed_forward_macaron</em>, <em class="sig-param">conv_module</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">total_layer_num</em>, <em class="sig-param">normalize_before=True</em>, <em class="sig-param">concat_after=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/contextual_block_encoder_layer.html#ContextualBlockEncoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Contexutal Block Encoder layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>self_attn</strong> (<em>torch.nn.Module</em>) – Self-attention module instance.
<cite>MultiHeadedAttention</cite> or <cite>RelPositionMultiHeadedAttention</cite> instance
can be used as the argument.</p></li>
<li><p><strong>feed_forward</strong> (<em>torch.nn.Module</em>) – Feed-forward module instance.
<cite>PositionwiseFeedForward</cite>, <cite>MultiLayeredConv1d</cite>, or <cite>Conv1dLinear</cite> instance
can be used as the argument.</p></li>
<li><p><strong>feed_forward_macaron</strong> (<em>torch.nn.Module</em>) – Additional feed-forward module instance.
<cite>PositionwiseFeedForward</cite>, <cite>MultiLayeredConv1d</cite>, or <cite>Conv1dLinear</cite> instance
can be used as the argument.</p></li>
<li><p><strong>conv_module</strong> (<em>torch.nn.Module</em>) – Convolution module instance.
<cite>ConvlutionModule</cite> instance can be used as the argument.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>total_layer_num</strong> (<em>int</em>) – Total number of layers</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
</ul>
</dd>
</dl>
<p>Construct an EncoderLayer object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em>, <em class="sig-param">infer_mode=False</em>, <em class="sig-param">past_ctx=None</em>, <em class="sig-param">next_ctx=None</em>, <em class="sig-param">is_short_segment=False</em>, <em class="sig-param">layer_idx=0</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/contextual_block_encoder_layer.html#ContextualBlockEncoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward_infer">
<code class="sig-name descname">forward_infer</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em>, <em class="sig-param">past_ctx=None</em>, <em class="sig-param">next_ctx=None</em>, <em class="sig-param">is_short_segment=False</em>, <em class="sig-param">layer_idx=0</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/contextual_block_encoder_layer.html#ContextualBlockEncoderLayer.forward_infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward_infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute encoded features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_input</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, time).</p></li>
<li><p><strong>past_ctx</strong> (<em>torch.Tensor</em>) – Previous contexutal vector</p></li>
<li><p><strong>next_ctx</strong> (<em>torch.Tensor</em>) – Next contexutal vector</p></li>
<li><p><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time, size).
torch.Tensor: Mask tensor (#batch, time).
cur_ctx (torch.Tensor): Current contexutal vector
next_ctx (torch.Tensor): Next contexutal vector
layer_idx (int): layer index number</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward_train">
<code class="sig-name descname">forward_train</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em>, <em class="sig-param">past_ctx=None</em>, <em class="sig-param">next_ctx=None</em>, <em class="sig-param">layer_idx=0</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/contextual_block_encoder_layer.html#ContextualBlockEncoderLayer.forward_train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute encoded features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_input</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, time).</p></li>
<li><p><strong>past_ctx</strong> (<em>torch.Tensor</em>) – Previous contexutal vector</p></li>
<li><p><strong>next_ctx</strong> (<em>torch.Tensor</em>) – Next contexutal vector</p></li>
<li><p><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time, size).
torch.Tensor: Mask tensor (#batch, time).
cur_ctx (torch.Tensor): Current contexutal vector
next_ctx (torch.Tensor): Next contexutal vector
layer_idx (int): layer index number</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-conformer-encoder-layer">
<span id="id73"></span><h2>espnet.nets.pytorch_backend.conformer.encoder_layer<a class="headerlink" href="#espnet-nets-pytorch-backend-conformer-encoder-layer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.conformer.encoder_layer"></span><p>Encoder self-attention layer definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.conformer.encoder_layer.EncoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.conformer.encoder_layer.</code><code class="sig-name descname">EncoderLayer</code><span class="sig-paren">(</span><em class="sig-param">size</em>, <em class="sig-param">self_attn</em>, <em class="sig-param">feed_forward</em>, <em class="sig-param">feed_forward_macaron</em>, <em class="sig-param">conv_module</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">normalize_before=True</em>, <em class="sig-param">concat_after=False</em>, <em class="sig-param">stochastic_depth_rate=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/encoder_layer.html#EncoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.encoder_layer.EncoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encoder layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>self_attn</strong> (<em>torch.nn.Module</em>) – Self-attention module instance.
<cite>MultiHeadedAttention</cite> or <cite>RelPositionMultiHeadedAttention</cite> instance
can be used as the argument.</p></li>
<li><p><strong>feed_forward</strong> (<em>torch.nn.Module</em>) – Feed-forward module instance.
<cite>PositionwiseFeedForward</cite>, <cite>MultiLayeredConv1d</cite>, or <cite>Conv1dLinear</cite> instance
can be used as the argument.</p></li>
<li><p><strong>feed_forward_macaron</strong> (<em>torch.nn.Module</em>) – Additional feed-forward module instance.
<cite>PositionwiseFeedForward</cite>, <cite>MultiLayeredConv1d</cite>, or <cite>Conv1dLinear</cite> instance
can be used as the argument.</p></li>
<li><p><strong>conv_module</strong> (<em>torch.nn.Module</em>) – Convolution module instance.
<cite>ConvlutionModule</cite> instance can be used as the argument.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>stochastic_depth_rate</strong> (<em>float</em>) – Proability to skip this layer.
During training, the layer may skip residual computation and return input
as-is with given probability.</p></li>
</ul>
</dd>
</dl>
<p>Construct an EncoderLayer object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.conformer.encoder_layer.EncoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x_input</em>, <em class="sig-param">mask</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/encoder_layer.html#EncoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.encoder_layer.EncoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute encoded features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_input</strong> (<em>Union</em><em>[</em><em>Tuple</em><em>, </em><em>torch.Tensor</em><em>]</em>) – Input tensor w/ or w/o pos emb.
- w/ pos emb: Tuple of tensors [(#batch, time, size), (1, time, size)].
- w/o pos emb: Tensor (#batch, time, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, time).</p></li>
<li><p><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time, size).
torch.Tensor: Mask tensor (#batch, time).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-conformer-init">
<span id="id74"></span><h2>espnet.nets.pytorch_backend.conformer.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-conformer-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.conformer.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-conformer-convolution">
<span id="id75"></span><h2>espnet.nets.pytorch_backend.conformer.convolution<a class="headerlink" href="#espnet-nets-pytorch-backend-conformer-convolution" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.conformer.convolution"></span><p>ConvolutionModule definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.conformer.convolution.ConvolutionModule">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.conformer.convolution.</code><code class="sig-name descname">ConvolutionModule</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">activation=ReLU()</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/convolution.html#ConvolutionModule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.convolution.ConvolutionModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ConvolutionModule in Conformer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<em>int</em>) – The number of channels of conv layers.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernerl size of conv layers.</p></li>
</ul>
</dd>
</dl>
<p>Construct an ConvolutionModule object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.conformer.convolution.ConvolutionModule.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/convolution.html#ConvolutionModule.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.convolution.ConvolutionModule.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute convolution module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, channels).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time, channels).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-conformer-argument">
<span id="id76"></span><h2>espnet.nets.pytorch_backend.conformer.argument<a class="headerlink" href="#espnet-nets-pytorch-backend-conformer-argument" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.conformer.argument"></span><p>Conformer common arguments.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.conformer.argument.add_arguments_conformer_common">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.conformer.argument.</code><code class="sig-name descname">add_arguments_conformer_common</code><span class="sig-paren">(</span><em class="sig-param">group</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/argument.html#add_arguments_conformer_common"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.argument.add_arguments_conformer_common" title="Permalink to this definition">¶</a></dt>
<dd><p>Add Transformer common arguments.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.conformer.argument.verify_rel_pos_type">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.conformer.argument.</code><code class="sig-name descname">verify_rel_pos_type</code><span class="sig-paren">(</span><em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/argument.html#verify_rel_pos_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.argument.verify_rel_pos_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Verify the relative positional encoding type for compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> (<em>Namespace</em>) – original arguments</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>modified arguments</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>args (Namespace)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-conformer-swish">
<span id="id77"></span><h2>espnet.nets.pytorch_backend.conformer.swish<a class="headerlink" href="#espnet-nets-pytorch-backend-conformer-swish" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.conformer.swish"></span><p>Swish() activation function for Conformer.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.conformer.swish.Swish">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.conformer.swish.</code><code class="sig-name descname">Swish</code><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/swish.html#Swish"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.swish.Swish" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Construct an Swish object.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.conformer.swish.Swish.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/conformer/swish.html#Swish.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.conformer.swish.Swish.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Return Swich activation function.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-lm-transformer">
<span id="id78"></span><h2>espnet.nets.pytorch_backend.lm.transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-lm-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.lm.transformer"></span><p>Transformer language model.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.lm.transformer.TransformerLM">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.lm.transformer.</code><code class="sig-name descname">TransformerLM</code><span class="sig-paren">(</span><em class="sig-param">n_vocab</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/transformer.html#TransformerLM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.transformer.TransformerLM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <a class="reference internal" href="#espnet.nets.lm_interface.LMInterface" title="espnet.nets.lm_interface.LMInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.lm_interface.LMInterface</span></code></a>, <a class="reference internal" href="#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a></p>
<p>Transformer language model.</p>
<p>Initialize class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_vocab</strong> (<em>int</em>) – The size of the vocabulary</p></li>
<li><p><strong>args</strong> (<em>argparse.Namespace</em>) – configurations. see py:method:<cite>add_arguments</cite></p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.transformer.TransformerLM.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/transformer.html#TransformerLM.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.transformer.TransformerLM.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments to command line argument parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.transformer.TransformerLM.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/transformer.html#TransformerLM.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.transformer.TransformerLM.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.transformer.TransformerLM.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">t: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/transformer.html#TransformerLM.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.transformer.TransformerLM.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute LM loss value from buffer sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input ids. (batch, len)</p></li>
<li><p><strong>t</strong> (<em>torch.Tensor</em>) – Target ids. (batch, len)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>loss to backward (scalar),
negative log-likelihood of t: -log p(t) (scalar) and
the number of elements in x (scalar)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The last two return values are used
in perplexity: p(t)^{-n} = exp(-log p(t) / n)</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.transformer.TransformerLM.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">y: torch.Tensor</em>, <em class="sig-param">state: Any</em>, <em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Any]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/transformer.html#TransformerLM.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.transformer.TransformerLM.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</p></li>
<li><p><strong>state</strong> – Scorer state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – encoder feature that generates ys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>torch.float32 scores for next token (n_vocab)
and next state for ys</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-lm-init">
<span id="id79"></span><h2>espnet.nets.pytorch_backend.lm.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-lm-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.lm.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-lm-seq-rnn">
<span id="id80"></span><h2>espnet.nets.pytorch_backend.lm.seq_rnn<a class="headerlink" href="#espnet-nets-pytorch-backend-lm-seq-rnn" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.lm.seq_rnn"></span><p>Sequential implementation of Recurrent Neural Network Language Model.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.lm.seq_rnn.</code><code class="sig-name descname">SequentialRNNLM</code><span class="sig-paren">(</span><em class="sig-param">n_vocab</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/seq_rnn.html#SequentialRNNLM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.lm_interface.LMInterface" title="espnet.nets.lm_interface.LMInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.lm_interface.LMInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Sequential RNNLM.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference external" href="https://github.com/pytorch/examples/blob/4581968193699de14b56527296262dd76ab43557/word_language_model/model.py">https://github.com/pytorch/examples/blob/4581968193699de14b56527296262dd76ab43557/word_language_model/model.py</a></p>
</div>
<p>Initialize class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_vocab</strong> (<em>int</em>) – The size of the vocabulary</p></li>
<li><p><strong>args</strong> (<em>argparse.Namespace</em>) – configurations. see py:method:<cite>add_arguments</cite></p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/seq_rnn.html#SequentialRNNLM.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments to command line argument parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">t</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/seq_rnn.html#SequentialRNNLM.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute LM loss value from buffer sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input ids. (batch, len)</p></li>
<li><p><strong>t</strong> (<em>torch.Tensor</em>) – Target ids. (batch, len)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>loss to backward (scalar),
negative log-likelihood of t: -log p(t) (scalar) and
the number of elements in x (scalar)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The last two return values are used
in perplexity: p(t)^{-n} = exp(-log p(t) / n)</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/seq_rnn.html#SequentialRNNLM.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an initial state for decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoded feature tensor</p>
</dd>
</dl>
<p>Returns: initial state</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/seq_rnn.html#SequentialRNNLM.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.seq_rnn.SequentialRNNLM.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</p></li>
<li><p><strong>state</strong> – Scorer state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – 2D encoder feature that generates ys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>torch.float32 scores for next token (n_vocab)
and next state for ys</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-lm-default">
<span id="id81"></span><h2>espnet.nets.pytorch_backend.lm.default<a class="headerlink" href="#espnet-nets-pytorch-backend-lm-default" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.lm.default"></span><p>Default Recurrent Neural Network Languge Model in <cite>lm_train.py</cite>.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.lm.default.ClassifierWithState">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.lm.default.</code><code class="sig-name descname">ClassifierWithState</code><span class="sig-paren">(</span><em class="sig-param">predictor</em>, <em class="sig-param">lossfun=CrossEntropyLoss()</em>, <em class="sig-param">label_key=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#ClassifierWithState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.ClassifierWithState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A wrapper for pytorch RNNLM.</p>
<p>Initialize class.</p>
<p>:param torch.nn.Module predictor : The RNNLM
:param function lossfun : The loss function to use
:param int/str label_key :</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.ClassifierWithState.buff_predict">
<code class="sig-name descname">buff_predict</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">x</em>, <em class="sig-param">n</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#ClassifierWithState.buff_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.ClassifierWithState.buff_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict new tokens from buffered inputs.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.ClassifierWithState.final">
<code class="sig-name descname">final</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">index=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#ClassifierWithState.final"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.ClassifierWithState.final" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict final log probabilities for given state using the predictor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> – The state</p>
</dd>
</dl>
<p>:return The final log probabilities
:rtype torch.Tensor</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.ClassifierWithState.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#ClassifierWithState.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.ClassifierWithState.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the loss value for an input and label pair.</p>
<p class="rubric">Notes</p>
<p>It also computes accuracy and stores it to the attribute.
When <code class="docutils literal notranslate"><span class="pre">label_key</span></code> is <code class="docutils literal notranslate"><span class="pre">int</span></code>, the corresponding element in <code class="docutils literal notranslate"><span class="pre">args</span></code>
is treated as ground truth labels. And when it is <code class="docutils literal notranslate"><span class="pre">str</span></code>, the
element in <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> is used.
The all elements of <code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> except the groundtruth
labels are features.
It feeds features to the predictor and compare the result
with ground truth labels.</p>
<p>:param torch.Tensor state : the LM state
:param list[torch.Tensor] args : Input minibatch
:param dict[torch.Tensor] kwargs : Input minibatch
:return loss value
:rtype torch.Tensor</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.ClassifierWithState.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#ClassifierWithState.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.ClassifierWithState.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict log probabilities for given state and input x using the predictor.</p>
<p>:param torch.Tensor state : The current state
:param torch.Tensor x : The input
:return a tuple (new state, log prob vector)
:rtype (torch.Tensor, torch.Tensor)</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.lm.default.DefaultRNNLM">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.lm.default.</code><code class="sig-name descname">DefaultRNNLM</code><span class="sig-paren">(</span><em class="sig-param">n_vocab</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#DefaultRNNLM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.DefaultRNNLM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a>, <a class="reference internal" href="#espnet.nets.lm_interface.LMInterface" title="espnet.nets.lm_interface.LMInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.lm_interface.LMInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Default RNNLM for <cite>LMInterface</cite> Implementation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PyTorch seems to have memory leak when one GPU compute this after data parallel.
If parallel GPUs compute this, it seems to be fine.
See also <a class="reference external" href="https://github.com/espnet/espnet/issues/1075">https://github.com/espnet/espnet/issues/1075</a></p>
</div>
<p>Initialize class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_vocab</strong> (<em>int</em>) – The size of the vocabulary</p></li>
<li><p><strong>args</strong> (<em>argparse.Namespace</em>) – configurations. see py:method:<cite>add_arguments</cite></p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.add_arguments">
<em class="property">static </em><code class="sig-name descname">add_arguments</code><span class="sig-paren">(</span><em class="sig-param">parser</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#DefaultRNNLM.add_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments to command line argument parser.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#DefaultRNNLM.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.final_score">
<code class="sig-name descname">final_score</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#DefaultRNNLM.final_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.final_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score eos.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> – Scorer state for prefix tokens</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>final score</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">t</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#DefaultRNNLM.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute LM loss value from buffer sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input ids. (batch, len)</p></li>
<li><p><strong>t</strong> (<em>torch.Tensor</em>) – Target ids. (batch, len)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>loss to backward (scalar),
negative log-likelihood of t: -log p(t) (scalar) and
the number of elements in x (scalar)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The last two return values are used
in perplexity: p(t)^{-n} = exp(-log p(t) / n)</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param">d</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#DefaultRNNLM.load_state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Load state dict.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">y</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#DefaultRNNLM.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</p></li>
<li><p><strong>state</strong> – Scorer state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – 2D encoder feature that generates ys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>torch.float32 scores for next token (n_vocab)
and next state for ys</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#DefaultRNNLM.state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.DefaultRNNLM.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Dump state dict.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.lm.default.RNNLM">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.lm.default.</code><code class="sig-name descname">RNNLM</code><span class="sig-paren">(</span><em class="sig-param">n_vocab</em>, <em class="sig-param">n_layers</em>, <em class="sig-param">n_units</em>, <em class="sig-param">n_embed=None</em>, <em class="sig-param">typ='lstm'</em>, <em class="sig-param">dropout_rate=0.5</em>, <em class="sig-param">emb_dropout_rate=0.0</em>, <em class="sig-param">tie_weights=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#RNNLM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.RNNLM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A pytorch RNNLM.</p>
<p>Initialize class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_vocab</strong> (<em>int</em>) – The size of the vocabulary</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) – The number of layers to create</p></li>
<li><p><strong>n_units</strong> (<em>int</em>) – The number of units per layer</p></li>
<li><p><strong>typ</strong> (<em>str</em>) – The RNN type</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.RNNLM.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#RNNLM.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.RNNLM.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward neural networks.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.lm.default.RNNLM.zero_state">
<code class="sig-name descname">zero_state</code><span class="sig-paren">(</span><em class="sig-param">batchsize</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/lm/default.html#RNNLM.zero_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.lm.default.RNNLM.zero_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize state.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-maskctc-mask">
<span id="id82"></span><h2>espnet.nets.pytorch_backend.maskctc.mask<a class="headerlink" href="#espnet-nets-pytorch-backend-maskctc-mask" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.maskctc.mask"></span><p>Attention masking module for Masked LM.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.maskctc.mask.square_mask">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.maskctc.mask.</code><code class="sig-name descname">square_mask</code><span class="sig-paren">(</span><em class="sig-param">ys_in_pad</em>, <em class="sig-param">ignore_id</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/maskctc/mask.html#square_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.maskctc.mask.square_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create attention mask to avoid attending on padding tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
<li><p><strong>ignore_id</strong> (<em>int</em>) – index of padding</p></li>
<li><p><strong>dtype</strong> (<em>torch.dtype</em>) – result dtype</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor (B, Lmax, Lmax)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-maskctc-init">
<span id="id83"></span><h2>espnet.nets.pytorch_backend.maskctc.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-maskctc-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.maskctc.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-maskctc-add-mask-token">
<span id="id84"></span><h2>espnet.nets.pytorch_backend.maskctc.add_mask_token<a class="headerlink" href="#espnet-nets-pytorch-backend-maskctc-add-mask-token" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.maskctc.add_mask_token"></span><p>Token masking module for Masked LM.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.maskctc.add_mask_token.mask_uniform">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.maskctc.add_mask_token.</code><code class="sig-name descname">mask_uniform</code><span class="sig-paren">(</span><em class="sig-param">ys_pad</em>, <em class="sig-param">mask_token</em>, <em class="sig-param">eos</em>, <em class="sig-param">ignore_id</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/maskctc/add_mask_token.html#mask_uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.maskctc.add_mask_token.mask_uniform" title="Permalink to this definition">¶</a></dt>
<dd><p>Replace random tokens with &lt;mask&gt; label and add &lt;eos&gt; label.</p>
<p>The number of &lt;mask&gt; is chosen from a uniform distribution
between one and the target sequence’s length.
:param torch.Tensor ys_pad: batch of padded target sequences (B, Lmax)
:param int mask_token: index of &lt;mask&gt;
:param int eos: index of &lt;eos&gt;
:param int ignore_id: index of padding
:return: padded tensor (B, Lmax)
:rtype: torch.Tensor
:return: padded tensor (B, Lmax)
:rtype: torch.Tensor</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-attention">
<span id="id85"></span><h2>espnet.nets.pytorch_backend.transformer.attention<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-attention" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.attention"></span><p>Multi-Head Attention layer definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.attention.LegacyRelPositionMultiHeadedAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.attention.</code><code class="sig-name descname">LegacyRelPositionMultiHeadedAttention</code><span class="sig-paren">(</span><em class="sig-param">n_head</em>, <em class="sig-param">n_feat</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">zero_triu=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#LegacyRelPositionMultiHeadedAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.LegacyRelPositionMultiHeadedAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention" title="espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention</span></code></a></p>
<p>Multi-Head Attention layer with relative position encoding (old version).</p>
<p>Details can be found in <a class="reference external" href="https://github.com/espnet/espnet/pull/2816">https://github.com/espnet/espnet/pull/2816</a>.</p>
<p>Paper: <a class="reference external" href="https://arxiv.org/abs/1901.02860">https://arxiv.org/abs/1901.02860</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_head</strong> (<em>int</em>) – The number of heads.</p></li>
<li><p><strong>n_feat</strong> (<em>int</em>) – The number of features.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>zero_triu</strong> (<em>bool</em>) – Whether to zero the upper triangular part of attention matrix.</p></li>
</ul>
</dd>
</dl>
<p>Construct an RelPositionMultiHeadedAttention object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.attention.LegacyRelPositionMultiHeadedAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em>, <em class="sig-param">pos_emb</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#LegacyRelPositionMultiHeadedAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.LegacyRelPositionMultiHeadedAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute ‘Scaled Dot Product Attention’ with rel. positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – Query tensor (#batch, time1, size).</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – Key tensor (#batch, time2, size).</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – Value tensor (#batch, time2, size).</p></li>
<li><p><strong>pos_emb</strong> (<em>torch.Tensor</em>) – Positional embedding tensor (#batch, time1, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor (#batch, 1, time2) or
(#batch, time1, time2).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time1, d_model).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.attention.LegacyRelPositionMultiHeadedAttention.rel_shift">
<code class="sig-name descname">rel_shift</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#LegacyRelPositionMultiHeadedAttention.rel_shift"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.LegacyRelPositionMultiHeadedAttention.rel_shift" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute relative positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (batch, head, time1, time2).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.attention.</code><code class="sig-name descname">MultiHeadedAttention</code><span class="sig-paren">(</span><em class="sig-param">n_head</em>, <em class="sig-param">n_feat</em>, <em class="sig-param">dropout_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#MultiHeadedAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi-Head Attention layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_head</strong> (<em>int</em>) – The number of heads.</p></li>
<li><p><strong>n_feat</strong> (<em>int</em>) – The number of features.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct an MultiHeadedAttention object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#MultiHeadedAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute scaled dot product attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – Query tensor (#batch, time1, size).</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – Key tensor (#batch, time2, size).</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – Value tensor (#batch, time2, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor (#batch, 1, time2) or
(#batch, time1, time2).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time1, d_model).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention.forward_attention">
<code class="sig-name descname">forward_attention</code><span class="sig-paren">(</span><em class="sig-param">value</em>, <em class="sig-param">scores</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#MultiHeadedAttention.forward_attention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention.forward_attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute attention context vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – Transformed value (#batch, n_head, time2, d_k).</p></li>
<li><p><strong>scores</strong> (<em>torch.Tensor</em>) – Attention score (#batch, n_head, time1, time2).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask (#batch, 1, time2) or (#batch, time1, time2).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed value (#batch, time1, d_model)</dt><dd><p>weighted by the attention score (#batch, time1, time2).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention.forward_qkv">
<code class="sig-name descname">forward_qkv</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#MultiHeadedAttention.forward_qkv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention.forward_qkv" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform query, key and value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – Query tensor (#batch, time1, size).</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – Key tensor (#batch, time2, size).</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – Value tensor (#batch, time2, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Transformed query tensor (#batch, n_head, time1, d_k).
torch.Tensor: Transformed key tensor (#batch, n_head, time2, d_k).
torch.Tensor: Transformed value tensor (#batch, n_head, time2, d_k).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.attention.RelPositionMultiHeadedAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.attention.</code><code class="sig-name descname">RelPositionMultiHeadedAttention</code><span class="sig-paren">(</span><em class="sig-param">n_head</em>, <em class="sig-param">n_feat</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">zero_triu=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#RelPositionMultiHeadedAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.RelPositionMultiHeadedAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention" title="espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention</span></code></a></p>
<p>Multi-Head Attention layer with relative position encoding (new implementation).</p>
<p>Details can be found in <a class="reference external" href="https://github.com/espnet/espnet/pull/2816">https://github.com/espnet/espnet/pull/2816</a>.</p>
<p>Paper: <a class="reference external" href="https://arxiv.org/abs/1901.02860">https://arxiv.org/abs/1901.02860</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_head</strong> (<em>int</em>) – The number of heads.</p></li>
<li><p><strong>n_feat</strong> (<em>int</em>) – The number of features.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>zero_triu</strong> (<em>bool</em>) – Whether to zero the upper triangular part of attention matrix.</p></li>
</ul>
</dd>
</dl>
<p>Construct an RelPositionMultiHeadedAttention object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.attention.RelPositionMultiHeadedAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em>, <em class="sig-param">pos_emb</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#RelPositionMultiHeadedAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.RelPositionMultiHeadedAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute ‘Scaled Dot Product Attention’ with rel. positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – Query tensor (#batch, time1, size).</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – Key tensor (#batch, time2, size).</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – Value tensor (#batch, time2, size).</p></li>
<li><p><strong>pos_emb</strong> (<em>torch.Tensor</em>) – Positional embedding tensor
(#batch, 2*time1-1, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor (#batch, 1, time2) or
(#batch, time1, time2).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time1, d_model).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.attention.RelPositionMultiHeadedAttention.rel_shift">
<code class="sig-name descname">rel_shift</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/attention.html#RelPositionMultiHeadedAttention.rel_shift"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.attention.RelPositionMultiHeadedAttention.rel_shift" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute relative positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (batch, head, time1, 2*time1-1).</p></li>
<li><p><strong>means the length of query vector.</strong> (<em>time1</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-embedding">
<span id="id86"></span><h2>espnet.nets.pytorch_backend.transformer.embedding<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-embedding" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.embedding"></span><p>Positional Encoding Module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.LearnableFourierPosEnc">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.embedding.</code><code class="sig-name descname">LearnableFourierPosEnc</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">dropout_rate=0.0</em>, <em class="sig-param">max_len=5000</em>, <em class="sig-param">gamma=1.0</em>, <em class="sig-param">apply_scaling=False</em>, <em class="sig-param">hidden_dim=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#LearnableFourierPosEnc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.LearnableFourierPosEnc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Learnable Fourier Features for Positional Encoding.</p>
<p>See <a class="reference external" href="https://arxiv.org/pdf/2106.02795.pdf">https://arxiv.org/pdf/2106.02795.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – Embedding dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>max_len</strong> (<em>int</em>) – Maximum input length.</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – init parameter for the positional kernel variance
see <a class="reference external" href="https://arxiv.org/pdf/2106.02795.pdf">https://arxiv.org/pdf/2106.02795.pdf</a>.</p></li>
<li><p><strong>apply_scaling</strong> (<em>bool</em>) – Whether to scale the input before adding the pos encoding.</p></li>
<li><p><strong>hidden_dim</strong> (<em>int</em>) – if not None, we modulate the pos encodings with
an MLP whose hidden layer has hidden_dim neurons.</p></li>
</ul>
</dd>
</dl>
<p>Initialize class.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.LearnableFourierPosEnc.extend_pe">
<code class="sig-name descname">extend_pe</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#LearnableFourierPosEnc.extend_pe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.LearnableFourierPosEnc.extend_pe" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the positional encodings.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.LearnableFourierPosEnc.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#LearnableFourierPosEnc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.LearnableFourierPosEnc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Add positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.LegacyRelPositionalEncoding">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.embedding.</code><code class="sig-name descname">LegacyRelPositionalEncoding</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">max_len=5000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#LegacyRelPositionalEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.LegacyRelPositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding" title="espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding</span></code></a></p>
<p>Relative positional encoding module (old version).</p>
<p>Details can be found in <a class="reference external" href="https://github.com/espnet/espnet/pull/2816">https://github.com/espnet/espnet/pull/2816</a>.</p>
<p>See : Appendix B in <a class="reference external" href="https://arxiv.org/abs/1901.02860">https://arxiv.org/abs/1901.02860</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – Embedding dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>max_len</strong> (<em>int</em>) – Maximum input length.</p></li>
</ul>
</dd>
</dl>
<p>Initialize class.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.LegacyRelPositionalEncoding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#LegacyRelPositionalEncoding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.LegacyRelPositionalEncoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded tensor (batch, time, <cite>*</cite>).
torch.Tensor: Positional embedding tensor (1, time, <cite>*</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.embedding.</code><code class="sig-name descname">PositionalEncoding</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">max_len=5000</em>, <em class="sig-param">reverse=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#PositionalEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – Embedding dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>max_len</strong> (<em>int</em>) – Maximum input length.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) – Whether to reverse the input position. Only for</p></li>
<li><p><strong>class LegacyRelPositionalEncoding. We remove it in the current</strong> (<em>the</em>) – </p></li>
<li><p><strong>RelPositionalEncoding.</strong> (<em>class</em>) – </p></li>
</ul>
</dd>
</dl>
<p>Construct an PositionalEncoding object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding.extend_pe">
<code class="sig-name descname">extend_pe</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#PositionalEncoding.extend_pe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding.extend_pe" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the positional encodings.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#PositionalEncoding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Add positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.RelPositionalEncoding">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.embedding.</code><code class="sig-name descname">RelPositionalEncoding</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">max_len=5000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#RelPositionalEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.RelPositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Relative positional encoding module (new implementation).</p>
<p>Details can be found in <a class="reference external" href="https://github.com/espnet/espnet/pull/2816">https://github.com/espnet/espnet/pull/2816</a>.</p>
<p>See : Appendix B in <a class="reference external" href="https://arxiv.org/abs/1901.02860">https://arxiv.org/abs/1901.02860</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – Embedding dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>max_len</strong> (<em>int</em>) – Maximum input length.</p></li>
</ul>
</dd>
</dl>
<p>Construct an PositionalEncoding object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.RelPositionalEncoding.extend_pe">
<code class="sig-name descname">extend_pe</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#RelPositionalEncoding.extend_pe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.RelPositionalEncoding.extend_pe" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the positional encodings.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.RelPositionalEncoding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#RelPositionalEncoding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.RelPositionalEncoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Add positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.embedding.</code><code class="sig-name descname">ScaledPositionalEncoding</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">max_len=5000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#ScaledPositionalEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding" title="espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding</span></code></a></p>
<p>Scaled positional encoding module.</p>
<p>See Sec. 3.2  <a class="reference external" href="https://arxiv.org/abs/1809.08895">https://arxiv.org/abs/1809.08895</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – Embedding dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>max_len</strong> (<em>int</em>) – Maximum input length.</p></li>
</ul>
</dd>
</dl>
<p>Initialize class.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#ScaledPositionalEncoding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Add positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#ScaledPositionalEncoding.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.StreamPositionalEncoding">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.embedding.</code><code class="sig-name descname">StreamPositionalEncoding</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">max_len=5000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#StreamPositionalEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.StreamPositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Streaming Positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – Embedding dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>max_len</strong> (<em>int</em>) – Maximum input length.</p></li>
</ul>
</dd>
</dl>
<p>Construct an PositionalEncoding object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.StreamPositionalEncoding.extend_pe">
<code class="sig-name descname">extend_pe</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#StreamPositionalEncoding.extend_pe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.StreamPositionalEncoding.extend_pe" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset the positional encodings.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.embedding.StreamPositionalEncoding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">start_idx: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/embedding.html#StreamPositionalEncoding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.embedding.StreamPositionalEncoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Add positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoded tensor (batch, time, <cite>*</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-mask">
<span id="id87"></span><h2>espnet.nets.pytorch_backend.transformer.mask<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-mask" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.mask"></span><p>Mask module.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.mask.subsequent_mask">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.mask.</code><code class="sig-name descname">subsequent_mask</code><span class="sig-paren">(</span><em class="sig-param">size</em>, <em class="sig-param">device='cpu'</em>, <em class="sig-param">dtype=torch.bool</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/mask.html#subsequent_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.mask.subsequent_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create mask for subsequent steps (size, size).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – size of mask</p></li>
<li><p><strong>device</strong> (<em>str</em>) – “cpu” or “cuda” or torch.Tensor.device</p></li>
<li><p><strong>dtype</strong> (<em>torch.dtype</em>) – result dtype</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">subsequent_mask</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="go">[[1, 0, 0],</span>
<span class="go"> [1, 1, 0],</span>
<span class="go"> [1, 1, 1]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.mask.target_mask">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.mask.</code><code class="sig-name descname">target_mask</code><span class="sig-paren">(</span><em class="sig-param">ys_in_pad</em>, <em class="sig-param">ignore_id</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/mask.html#target_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.mask.target_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create mask for decoder self-attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
<li><p><strong>ignore_id</strong> (<em>int</em>) – index of padding</p></li>
<li><p><strong>dtype</strong> (<em>torch.dtype</em>) – result dtype</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor (B, Lmax, Lmax)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-plot">
<span id="id88"></span><h2>espnet.nets.pytorch_backend.transformer.plot<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-plot" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.plot"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.plot.</code><code class="sig-name descname">PlotAttentionReport</code><span class="sig-paren">(</span><em class="sig-param">att_vis_fn</em>, <em class="sig-param">data</em>, <em class="sig-param">outdir</em>, <em class="sig-param">converter</em>, <em class="sig-param">transform</em>, <em class="sig-param">device</em>, <em class="sig-param">reverse=False</em>, <em class="sig-param">ikey='input'</em>, <em class="sig-param">iaxis=0</em>, <em class="sig-param">okey='output'</em>, <em class="sig-param">oaxis=0</em>, <em class="sig-param">subsampling_factor=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/plot.html#PlotAttentionReport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet.asr.html#espnet.asr.asr_utils.PlotAttentionReport" title="espnet.asr.asr_utils.PlotAttentionReport"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.asr.asr_utils.PlotAttentionReport</span></code></a></p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport.get_attention_weights">
<code class="sig-name descname">get_attention_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/plot.html#PlotAttentionReport.get_attention_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport.get_attention_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Return attention weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl>
<dt>attention weights. float. Its shape would be</dt><dd><p>differ from backend.
* pytorch-&gt; 1) multi-head case =&gt; (B, H, Lmax, Tmax), 2)</p>
<blockquote>
<div><p>other case =&gt; (B, Lmax, Tmax).</p>
</div></blockquote>
<ul class="simple">
<li><p>chainer-&gt; (B, Lmax, Tmax)</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport.log_attentions">
<code class="sig-name descname">log_attentions</code><span class="sig-paren">(</span><em class="sig-param">logger</em>, <em class="sig-param">step</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/plot.html#PlotAttentionReport.log_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport.log_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Add image files of att_ws matrix to the tensorboard.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport.plotfn">
<code class="sig-name descname">plotfn</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/plot.html#PlotAttentionReport.plotfn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport.plotfn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.plot.plot_multi_head_attention">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.plot.</code><code class="sig-name descname">plot_multi_head_attention</code><span class="sig-paren">(</span><em class="sig-param">data</em>, <em class="sig-param">uttid_list</em>, <em class="sig-param">attn_dict</em>, <em class="sig-param">outdir</em>, <em class="sig-param">suffix='png'</em>, <em class="sig-param">savefn=&lt;function savefig&gt;</em>, <em class="sig-param">ikey='input'</em>, <em class="sig-param">iaxis=0</em>, <em class="sig-param">okey='output'</em>, <em class="sig-param">oaxis=0</em>, <em class="sig-param">subsampling_factor=4</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/plot.html#plot_multi_head_attention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.plot.plot_multi_head_attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot multi head attentions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>dict</em>) – utts info from json file</p></li>
<li><p><strong>uttid_list</strong> (<em>List</em>) – utterance IDs</p></li>
<li><p><strong>torch.Tensor</strong><strong>] </strong><strong>attn_dict</strong> (<em>dict</em><em>[</em><em>str</em><em>,</em>) – multi head attention dict.
values should be torch.Tensor (head, input_length, output_length)</p></li>
<li><p><strong>outdir</strong> (<em>str</em>) – dir to save fig</p></li>
<li><p><strong>suffix</strong> (<em>str</em>) – filename suffix including image type (e.g., png)</p></li>
<li><p><strong>savefn</strong> – function to save</p></li>
<li><p><strong>ikey</strong> (<em>str</em>) – key to access input</p></li>
<li><p><strong>iaxis</strong> (<em>int</em>) – dimension to access input</p></li>
<li><p><strong>okey</strong> (<em>str</em>) – key to access output</p></li>
<li><p><strong>oaxis</strong> (<em>int</em>) – dimension to access output</p></li>
<li><p><strong>subsampling_factor</strong> – subsampling factor in encoder</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.plot.savefig">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.plot.</code><code class="sig-name descname">savefig</code><span class="sig-paren">(</span><em class="sig-param">plot</em>, <em class="sig-param">filename</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/plot.html#savefig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.plot.savefig" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-optimizer">
<span id="id89"></span><h2>espnet.nets.pytorch_backend.transformer.optimizer<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-optimizer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.optimizer"></span><p>Optimizer module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.optimizer.</code><code class="sig-name descname">NoamOpt</code><span class="sig-paren">(</span><em class="sig-param">model_size</em>, <em class="sig-param">factor</em>, <em class="sig-param">warmup</em>, <em class="sig-param">optimizer</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/optimizer.html#NoamOpt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Optim wrapper that implements rate.</p>
<p>Construct an NoamOpt object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param">state_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/optimizer.html#NoamOpt.load_state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Load state_dict.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.param_groups">
<em class="property">property </em><code class="sig-name descname">param_groups</code><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.param_groups" title="Permalink to this definition">¶</a></dt>
<dd><p>Return param_groups.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.rate">
<code class="sig-name descname">rate</code><span class="sig-paren">(</span><em class="sig-param">step=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/optimizer.html#NoamOpt.rate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.rate" title="Permalink to this definition">¶</a></dt>
<dd><p>Implement <cite>lrate</cite> above.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/optimizer.html#NoamOpt.state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Return state_dict.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/optimizer.html#NoamOpt.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Update parameters and rate.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/optimizer.html#NoamOpt.zero_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.optimizer.NoamOpt.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset gradient.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.optimizer.get_std_opt">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.optimizer.</code><code class="sig-name descname">get_std_opt</code><span class="sig-paren">(</span><em class="sig-param">model_params</em>, <em class="sig-param">d_model</em>, <em class="sig-param">warmup</em>, <em class="sig-param">factor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/optimizer.html#get_std_opt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.optimizer.get_std_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Get standard NoamOpt.</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-decoder">
<span id="id90"></span><h2>espnet.nets.pytorch_backend.transformer.decoder<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-decoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.decoder"></span><p>Decoder definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.decoder.Decoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.decoder.</code><code class="sig-name descname">Decoder</code><span class="sig-paren">(</span><em class="sig-param">odim</em>, <em class="sig-param">selfattention_layer_type='selfattn'</em>, <em class="sig-param">attention_dim=256</em>, <em class="sig-param">attention_heads=4</em>, <em class="sig-param">conv_wshare=4</em>, <em class="sig-param">conv_kernel_length=11</em>, <em class="sig-param">conv_usebias=False</em>, <em class="sig-param">linear_units=2048</em>, <em class="sig-param">num_blocks=6</em>, <em class="sig-param">dropout_rate=0.1</em>, <em class="sig-param">positional_dropout_rate=0.1</em>, <em class="sig-param">self_attention_dropout_rate=0.0</em>, <em class="sig-param">src_attention_dropout_rate=0.0</em>, <em class="sig-param">input_layer='embed'</em>, <em class="sig-param">use_output_layer=True</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before=True</em>, <em class="sig-param">concat_after=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/decoder.html#Decoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.decoder.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transfomer decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> (<em>int</em>) – Output diminsion.</p></li>
<li><p><strong>self_attention_layer_type</strong> (<em>str</em>) – Self-attention layer type.</p></li>
<li><p><strong>attention_dim</strong> (<em>int</em>) – Dimension of attention.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – The number of heads of multi head attention.</p></li>
<li><p><strong>conv_wshare</strong> (<em>int</em>) – The number of kernel of convolution. Only used in
self_attention_layer_type == “lightconv*” or “dynamiconv*”.</p></li>
<li><p><strong>conv_kernel_length</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>str</em><em>]</em>) – Kernel size str of convolution
(e.g. 71_71_71_71_71_71). Only used in self_attention_layer_type
== “lightconv*” or “dynamiconv*”.</p></li>
<li><p><strong>conv_usebias</strong> (<em>bool</em>) – Whether to use bias in convolution. Only used in
self_attention_layer_type == “lightconv*” or “dynamiconv*”.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – The number of units of position-wise feed forward.</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em>) – The number of decoder blocks.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – Dropout rate after adding positional encoding.</p></li>
<li><p><strong>self_attention_dropout_rate</strong> (<em>float</em>) – Dropout rate in self-attention.</p></li>
<li><p><strong>src_attention_dropout_rate</strong> (<em>float</em>) – Dropout rate in source-attention.</p></li>
<li><p><strong>input_layer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.nn.Module</em><em>]</em>) – Input layer type.</p></li>
<li><p><strong>use_output_layer</strong> (<em>bool</em>) – Whether to use output layer.</p></li>
<li><p><strong>pos_enc_class</strong> (<em>torch.nn.Module</em>) – Positional encoding module class.
<cite>PositionalEncoding `or `ScaledPositionalEncoding</cite></p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
</ul>
</dd>
</dl>
<p>Construct an Decoder object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.decoder.Decoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/decoder.html#Decoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.decoder.Decoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.decoder.Decoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">tgt</em>, <em class="sig-param">tgt_mask</em>, <em class="sig-param">memory</em>, <em class="sig-param">memory_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/decoder.html#Decoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.decoder.Decoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tgt</strong> (<em>torch.Tensor</em>) – Input token ids, int64 (#batch, maxlen_out) if
input_layer == “embed”. In the other case, input tensor
(#batch, maxlen_out, odim).</p></li>
<li><p><strong>tgt_mask</strong> (<em>torch.Tensor</em>) – Input token mask (#batch, maxlen_out).
dtype=torch.uint8 in PyTorch 1.2- and dtype=torch.bool in PyTorch 1.2+
(include 1.2).</p></li>
<li><p><strong>memory</strong> (<em>torch.Tensor</em>) – Encoded memory, float32 (#batch, maxlen_in, feat).</p></li>
<li><p><strong>memory_mask</strong> (<em>torch.Tensor</em>) – Encoded memory mask (#batch, maxlen_in).
dtype=torch.uint8 in PyTorch 1.2- and dtype=torch.bool in PyTorch 1.2+
(include 1.2).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Decoded token score before softmax (#batch, maxlen_out, odim)</dt><dd><p>if use_output_layer is True. In the other case,final block outputs
(#batch, maxlen_out, attention_dim).</p>
</dd>
</dl>
<p>torch.Tensor: Score mask before softmax (#batch, maxlen_out).</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.decoder.Decoder.forward_one_step">
<code class="sig-name descname">forward_one_step</code><span class="sig-paren">(</span><em class="sig-param">tgt</em>, <em class="sig-param">tgt_mask</em>, <em class="sig-param">memory</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/decoder.html#Decoder.forward_one_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.decoder.Decoder.forward_one_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward one step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tgt</strong> (<em>torch.Tensor</em>) – Input token ids, int64 (#batch, maxlen_out).</p></li>
<li><p><strong>tgt_mask</strong> (<em>torch.Tensor</em>) – Input token mask (#batch, maxlen_out).
dtype=torch.uint8 in PyTorch 1.2- and dtype=torch.bool in PyTorch 1.2+
(include 1.2).</p></li>
<li><p><strong>memory</strong> (<em>torch.Tensor</em>) – Encoded memory, float32 (#batch, maxlen_in, feat).</p></li>
<li><p><strong>cache</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – List of cached tensors.
Each tensor shape should be (#batch, maxlen_out - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (batch, maxlen_out, odim).
List[torch.Tensor]: List of cache tensors of each decoder layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.decoder.Decoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">ys</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/decoder.html#Decoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.decoder.Decoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-multi-layer-conv">
<span id="id91"></span><h2>espnet.nets.pytorch_backend.transformer.multi_layer_conv<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-multi-layer-conv" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.multi_layer_conv"></span><p>Layer modules for FFT block in FastSpeech (Feed-forward Transformer).</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.multi_layer_conv.Conv1dLinear">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.multi_layer_conv.</code><code class="sig-name descname">Conv1dLinear</code><span class="sig-paren">(</span><em class="sig-param">in_chans</em>, <em class="sig-param">hidden_chans</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dropout_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/multi_layer_conv.html#Conv1dLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.multi_layer_conv.Conv1dLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Conv1D + Linear for Transformer block.</p>
<p>A variant of MultiLayeredConv1d, which replaces second conv-layer to linear.</p>
<p>Initialize Conv1dLinear module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>hidden_chans</strong> (<em>int</em>) – Number of hidden channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of conv1d.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.multi_layer_conv.Conv1dLinear.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/multi_layer_conv.html#Conv1dLinear.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.multi_layer_conv.Conv1dLinear.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Batch of input tensors (B, T, in_chans).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of output tensors (B, T, hidden_chans).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.multi_layer_conv.MultiLayeredConv1d">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.multi_layer_conv.</code><code class="sig-name descname">MultiLayeredConv1d</code><span class="sig-paren">(</span><em class="sig-param">in_chans</em>, <em class="sig-param">hidden_chans</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dropout_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/multi_layer_conv.html#MultiLayeredConv1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.multi_layer_conv.MultiLayeredConv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi-layered conv1d for Transformer block.</p>
<p>This is a module of multi-leyered conv1d designed
to replace positionwise feed-forward network
in Transforner block, which is introduced in
<a class="reference external" href="https://arxiv.org/pdf/1905.09263.pdf">FastSpeech: Fast, Robust and Controllable Text to Speech</a>.</p>
<p>Initialize MultiLayeredConv1d module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_chans</strong> (<em>int</em>) – Number of input channels.</p></li>
<li><p><strong>hidden_chans</strong> (<em>int</em>) – Number of hidden channels.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – Kernel size of conv1d.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.multi_layer_conv.MultiLayeredConv1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/multi_layer_conv.html#MultiLayeredConv1d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.multi_layer_conv.MultiLayeredConv1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Batch of input tensors (B, T, in_chans).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of output tensors (B, T, hidden_chans).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-encoder">
<span id="id93"></span><h2>espnet.nets.pytorch_backend.transformer.encoder<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-encoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.encoder"></span><p>Encoder definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.encoder.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.encoder.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">attention_dim=256</em>, <em class="sig-param">attention_heads=4</em>, <em class="sig-param">conv_wshare=4</em>, <em class="sig-param">conv_kernel_length='11'</em>, <em class="sig-param">conv_usebias=False</em>, <em class="sig-param">linear_units=2048</em>, <em class="sig-param">num_blocks=6</em>, <em class="sig-param">dropout_rate=0.1</em>, <em class="sig-param">positional_dropout_rate=0.1</em>, <em class="sig-param">attention_dropout_rate=0.0</em>, <em class="sig-param">input_layer='conv2d'</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before=True</em>, <em class="sig-param">concat_after=False</em>, <em class="sig-param">positionwise_layer_type='linear'</em>, <em class="sig-param">positionwise_conv_kernel_size=1</em>, <em class="sig-param">selfattention_layer_type='selfattn'</em>, <em class="sig-param">padding_idx=-1</em>, <em class="sig-param">stochastic_depth_rate=0.0</em>, <em class="sig-param">intermediate_layers=None</em>, <em class="sig-param">ctc_softmax=None</em>, <em class="sig-param">conditioning_layer_dim=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/encoder.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.encoder.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transformer encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>attention_dim</strong> (<em>int</em>) – Dimension of attention.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – The number of heads of multi head attention.</p></li>
<li><p><strong>conv_wshare</strong> (<em>int</em>) – The number of kernel of convolution. Only used in
selfattention_layer_type == “lightconv*” or “dynamiconv*”.</p></li>
<li><p><strong>conv_kernel_length</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>str</em><em>]</em>) – Kernel size str of convolution
(e.g. 71_71_71_71_71_71). Only used in selfattention_layer_type
== “lightconv*” or “dynamiconv*”.</p></li>
<li><p><strong>conv_usebias</strong> (<em>bool</em>) – Whether to use bias in convolution. Only used in
selfattention_layer_type == “lightconv*” or “dynamiconv*”.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – The number of units of position-wise feed forward.</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em>) – The number of decoder blocks.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – Dropout rate after adding positional encoding.</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – Dropout rate in attention.</p></li>
<li><p><strong>input_layer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.nn.Module</em><em>]</em>) – Input layer type.</p></li>
<li><p><strong>pos_enc_class</strong> (<em>torch.nn.Module</em>) – Positional encoding module class.
<cite>PositionalEncoding `or `ScaledPositionalEncoding</cite></p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>positionwise_layer_type</strong> (<em>str</em>) – “linear”, “conv1d”, or “conv1d-linear”.</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – Kernel size of positionwise conv1d layer.</p></li>
<li><p><strong>selfattention_layer_type</strong> (<em>str</em>) – Encoder attention layer type.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em>) – Padding idx for input_layer=embed.</p></li>
<li><p><strong>stochastic_depth_rate</strong> (<em>float</em>) – Maximum probability to skip the encoder layer.</p></li>
<li><p><strong>intermediate_layers</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>None</em><em>]</em>) – indices of intermediate CTC layer.
indices start from 1.
if not None, intermediate outputs are returned (which changes return type
signature.)</p></li>
</ul>
</dd>
</dl>
<p>Construct an Encoder object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.encoder.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">masks</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/encoder.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.encoder.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, idim).</p></li>
<li><p><strong>masks</strong> (<em>torch.Tensor</em>) – Mask tensor (#batch, time).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time, attention_dim).
torch.Tensor: Mask tensor (#batch, time).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.encoder.Encoder.forward_one_step">
<code class="sig-name descname">forward_one_step</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">masks</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/encoder.html#Encoder.forward_one_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.encoder.Encoder.forward_one_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input frame.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – Input tensor.</p></li>
<li><p><strong>masks</strong> (<em>torch.Tensor</em>) – Mask tensor.</p></li>
<li><p><strong>cache</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – List of cache tensors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor.
torch.Tensor: Mask tensor.
List[torch.Tensor]: List of new cache tensors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.encoder.Encoder.get_positionwise_layer">
<code class="sig-name descname">get_positionwise_layer</code><span class="sig-paren">(</span><em class="sig-param">positionwise_layer_type='linear'</em>, <em class="sig-param">attention_dim=256</em>, <em class="sig-param">linear_units=2048</em>, <em class="sig-param">dropout_rate=0.1</em>, <em class="sig-param">positionwise_conv_kernel_size=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/encoder.html#Encoder.get_positionwise_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.encoder.Encoder.get_positionwise_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Define positionwise layer.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-contextual-block-encoder-layer">
<span id="id94"></span><h2>espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-contextual-block-encoder-layer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer"></span><p>Encoder self-attention layer definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer.</code><code class="sig-name descname">ContextualBlockEncoderLayer</code><span class="sig-paren">(</span><em class="sig-param">size</em>, <em class="sig-param">self_attn</em>, <em class="sig-param">feed_forward</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">total_layer_num</em>, <em class="sig-param">normalize_before=True</em>, <em class="sig-param">concat_after=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/contextual_block_encoder_layer.html#ContextualBlockEncoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Contexutal Block Encoder layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>self_attn</strong> (<em>torch.nn.Module</em>) – Self-attention module instance.
<cite>MultiHeadedAttention</cite> or <cite>RelPositionMultiHeadedAttention</cite> instance
can be used as the argument.</p></li>
<li><p><strong>feed_forward</strong> (<em>torch.nn.Module</em>) – Feed-forward module instance.
<cite>PositionwiseFeedForward</cite>, <cite>MultiLayeredConv1d</cite>, or <cite>Conv1dLinear</cite> instance
can be used as the argument.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>total_layer_num</strong> (<em>int</em>) – Total number of layers</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
</ul>
</dd>
</dl>
<p>Construct an EncoderLayer object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em>, <em class="sig-param">infer_mode=False</em>, <em class="sig-param">past_ctx=None</em>, <em class="sig-param">next_ctx=None</em>, <em class="sig-param">is_short_segment=False</em>, <em class="sig-param">layer_idx=0</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/contextual_block_encoder_layer.html#ContextualBlockEncoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward_infer">
<code class="sig-name descname">forward_infer</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em>, <em class="sig-param">past_ctx=None</em>, <em class="sig-param">next_ctx=None</em>, <em class="sig-param">is_short_segment=False</em>, <em class="sig-param">layer_idx=0</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/contextual_block_encoder_layer.html#ContextualBlockEncoderLayer.forward_infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward_infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute encoded features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_input</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, time).</p></li>
<li><p><strong>past_ctx</strong> (<em>torch.Tensor</em>) – Previous contexutal vector</p></li>
<li><p><strong>next_ctx</strong> (<em>torch.Tensor</em>) – Next contexutal vector</p></li>
<li><p><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time, size).
torch.Tensor: Mask tensor (#batch, time).
cur_ctx (torch.Tensor): Current contexutal vector
next_ctx (torch.Tensor): Next contexutal vector
layer_idx (int): layer index number</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward_train">
<code class="sig-name descname">forward_train</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em>, <em class="sig-param">past_ctx=None</em>, <em class="sig-param">next_ctx=None</em>, <em class="sig-param">layer_idx=0</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/contextual_block_encoder_layer.html#ContextualBlockEncoderLayer.forward_train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.contextual_block_encoder_layer.ContextualBlockEncoderLayer.forward_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute encoded features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_input</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, time).</p></li>
<li><p><strong>past_ctx</strong> (<em>torch.Tensor</em>) – Previous contexutal vector</p></li>
<li><p><strong>next_ctx</strong> (<em>torch.Tensor</em>) – Next contexutal vector</p></li>
<li><p><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time, size).
torch.Tensor: Mask tensor (#batch, time).
cur_ctx (torch.Tensor): Current contexutal vector
next_ctx (torch.Tensor): Next contexutal vector
layer_idx (int): layer index number</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-lightconv2d">
<span id="id95"></span><h2>espnet.nets.pytorch_backend.transformer.lightconv2d<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-lightconv2d" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.lightconv2d"></span><p>Lightweight 2-Dimensional Convolution module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.lightconv2d.LightweightConvolution2D">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.lightconv2d.</code><code class="sig-name descname">LightweightConvolution2D</code><span class="sig-paren">(</span><em class="sig-param">wshare</em>, <em class="sig-param">n_feat</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">use_kernel_mask=False</em>, <em class="sig-param">use_bias=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/lightconv2d.html#LightweightConvolution2D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.lightconv2d.LightweightConvolution2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Lightweight 2-Dimensional Convolution layer.</p>
<p>This implementation is based on
<a class="reference external" href="https://github.com/pytorch/fairseq/tree/master/fairseq">https://github.com/pytorch/fairseq/tree/master/fairseq</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>wshare</strong> (<em>int</em>) – the number of kernel of convolution</p></li>
<li><p><strong>n_feat</strong> (<em>int</em>) – the number of features</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout_rate</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size (length)</p></li>
<li><p><strong>use_kernel_mask</strong> (<em>bool</em>) – Use causal mask or not for convolution kernel</p></li>
<li><p><strong>use_bias</strong> (<em>bool</em>) – Use bias term or not.</p></li>
</ul>
</dd>
</dl>
<p>Construct Lightweight 2-Dimensional Convolution layer.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.lightconv2d.LightweightConvolution2D.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/lightconv2d.html#LightweightConvolution2D.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.lightconv2d.LightweightConvolution2D.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward of ‘Lightweight 2-Dimensional Convolution’.</p>
<p>This function takes query, key and value but uses only query.
This is just for compatibility with self-attention layer (attention.py)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – (batch, time1, d_model) input tensor</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – (batch, time2, d_model) NOT USED</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – (batch, time2, d_model) NOT USED</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – (batch, time1, time2) mask</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(batch, time1, d_model) output</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-subsampling">
<span id="id96"></span><h2>espnet.nets.pytorch_backend.transformer.subsampling<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-subsampling" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.subsampling"></span><p>Subsampling layer definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.subsampling.</code><code class="sig-name descname">Conv2dSubsampling</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">pos_enc=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#Conv2dSubsampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional 2D subsampling (to 1/4 length).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Output dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>pos_enc</strong> (<em>torch.nn.Module</em>) – Custom position encoding layer.</p></li>
</ul>
</dd>
</dl>
<p>Construct an Conv2dSubsampling object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#Conv2dSubsampling.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Subsample x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, idim).</p></li>
<li><p><strong>x_mask</strong> (<em>torch.Tensor</em>) – Input mask (#batch, 1, time).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Subsampled tensor (#batch, time’, odim),</dt><dd><p>where time’ = time // 4.</p>
</dd>
<dt>torch.Tensor: Subsampled mask (#batch, 1, time’),</dt><dd><p>where time’ = time // 4.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling2">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.subsampling.</code><code class="sig-name descname">Conv2dSubsampling2</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">pos_enc=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#Conv2dSubsampling2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional 2D subsampling (to 1/2 length).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Output dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>pos_enc</strong> (<em>torch.nn.Module</em>) – Custom position encoding layer.</p></li>
</ul>
</dd>
</dl>
<p>Construct an Conv2dSubsampling2 object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling2.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#Conv2dSubsampling2.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling2.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Subsample x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, idim).</p></li>
<li><p><strong>x_mask</strong> (<em>torch.Tensor</em>) – Input mask (#batch, 1, time).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Subsampled tensor (#batch, time’, odim),</dt><dd><p>where time’ = time // 2.</p>
</dd>
<dt>torch.Tensor: Subsampled mask (#batch, 1, time’),</dt><dd><p>where time’ = time // 2.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling6">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.subsampling.</code><code class="sig-name descname">Conv2dSubsampling6</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">pos_enc=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#Conv2dSubsampling6"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling6" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional 2D subsampling (to 1/6 length).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Output dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>pos_enc</strong> (<em>torch.nn.Module</em>) – Custom position encoding layer.</p></li>
</ul>
</dd>
</dl>
<p>Construct an Conv2dSubsampling6 object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling6.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#Conv2dSubsampling6.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling6.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Subsample x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, idim).</p></li>
<li><p><strong>x_mask</strong> (<em>torch.Tensor</em>) – Input mask (#batch, 1, time).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Subsampled tensor (#batch, time’, odim),</dt><dd><p>where time’ = time // 6.</p>
</dd>
<dt>torch.Tensor: Subsampled mask (#batch, 1, time’),</dt><dd><p>where time’ = time // 6.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling8">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.subsampling.</code><code class="sig-name descname">Conv2dSubsampling8</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">pos_enc=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#Conv2dSubsampling8"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling8" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional 2D subsampling (to 1/8 length).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Output dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>pos_enc</strong> (<em>torch.nn.Module</em>) – Custom position encoding layer.</p></li>
</ul>
</dd>
</dl>
<p>Construct an Conv2dSubsampling8 object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling8.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#Conv2dSubsampling8.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling8.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Subsample x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, idim).</p></li>
<li><p><strong>x_mask</strong> (<em>torch.Tensor</em>) – Input mask (#batch, 1, time).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Subsampled tensor (#batch, time’, odim),</dt><dd><p>where time’ = time // 8.</p>
</dd>
<dt>torch.Tensor: Subsampled mask (#batch, 1, time’),</dt><dd><p>where time’ = time // 8.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="exception">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.TooShortUttError">
<em class="property">exception </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.subsampling.</code><code class="sig-name descname">TooShortUttError</code><span class="sig-paren">(</span><em class="sig-param">message</em>, <em class="sig-param">actual_size</em>, <em class="sig-param">limit</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#TooShortUttError"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.TooShortUttError" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></p>
<p>Raised when the utt is too short for subsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>message</strong> (<em>str</em>) – Message for error catch</p></li>
<li><p><strong>actual_size</strong> (<em>int</em>) – the short size that cannot pass the subsampling</p></li>
<li><p><strong>limit</strong> (<em>int</em>) – the limit size for subsampling</p></li>
</ul>
</dd>
</dl>
<p>Construct a TooShortUttError for error handler.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling.check_short_utt">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.subsampling.</code><code class="sig-name descname">check_short_utt</code><span class="sig-paren">(</span><em class="sig-param">ins</em>, <em class="sig-param">size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling.html#check_short_utt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling.check_short_utt" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the utterance is too short for subsampling.</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-layer-norm">
<span id="id97"></span><h2>espnet.nets.pytorch_backend.transformer.layer_norm<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-layer-norm" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.layer_norm"></span><p>Layer normalization module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.layer_norm.LayerNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.layer_norm.</code><code class="sig-name descname">LayerNorm</code><span class="sig-paren">(</span><em class="sig-param">nout</em>, <em class="sig-param">dim=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/layer_norm.html#LayerNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.layer_norm.LayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.normalization.LayerNorm</span></code></p>
<p>Layer normalization module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nout</strong> (<em>int</em>) – Output dim size.</p></li>
<li><p><strong>dim</strong> (<em>int</em>) – Dimension to be normalized.</p></li>
</ul>
</dd>
</dl>
<p>Construct an LayerNorm object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.layer_norm.LayerNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/layer_norm.html#LayerNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.layer_norm.LayerNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply layer normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Normalized tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-dynamic-conv">
<span id="id98"></span><h2>espnet.nets.pytorch_backend.transformer.dynamic_conv<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-dynamic-conv" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.dynamic_conv"></span><p>Dynamic Convolution module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.dynamic_conv.DynamicConvolution">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.dynamic_conv.</code><code class="sig-name descname">DynamicConvolution</code><span class="sig-paren">(</span><em class="sig-param">wshare</em>, <em class="sig-param">n_feat</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">use_kernel_mask=False</em>, <em class="sig-param">use_bias=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/dynamic_conv.html#DynamicConvolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.dynamic_conv.DynamicConvolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Dynamic Convolution layer.</p>
<p>This implementation is based on
<a class="reference external" href="https://github.com/pytorch/fairseq/tree/master/fairseq">https://github.com/pytorch/fairseq/tree/master/fairseq</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>wshare</strong> (<em>int</em>) – the number of kernel of convolution</p></li>
<li><p><strong>n_feat</strong> (<em>int</em>) – the number of features</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout_rate</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size (length)</p></li>
<li><p><strong>use_kernel_mask</strong> (<em>bool</em>) – Use causal mask or not for convolution kernel</p></li>
<li><p><strong>use_bias</strong> (<em>bool</em>) – Use bias term or not.</p></li>
</ul>
</dd>
</dl>
<p>Construct Dynamic Convolution layer.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.dynamic_conv.DynamicConvolution.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/dynamic_conv.html#DynamicConvolution.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.dynamic_conv.DynamicConvolution.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward of ‘Dynamic Convolution’.</p>
<p>This function takes query, key and value but uses only quert.
This is just for compatibility with self-attention layer (attention.py)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – (batch, time1, d_model) input tensor</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – (batch, time2, d_model) NOT USED</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – (batch, time2, d_model) NOT USED</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – (batch, time1, time2) mask</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(batch, time1, d_model) output</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-encoder-layer">
<span id="id99"></span><h2>espnet.nets.pytorch_backend.transformer.encoder_layer<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-encoder-layer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.encoder_layer"></span><p>Encoder self-attention layer definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.encoder_layer.EncoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.encoder_layer.</code><code class="sig-name descname">EncoderLayer</code><span class="sig-paren">(</span><em class="sig-param">size</em>, <em class="sig-param">self_attn</em>, <em class="sig-param">feed_forward</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">normalize_before=True</em>, <em class="sig-param">concat_after=False</em>, <em class="sig-param">stochastic_depth_rate=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/encoder_layer.html#EncoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.encoder_layer.EncoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encoder layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>self_attn</strong> (<em>torch.nn.Module</em>) – Self-attention module instance.
<cite>MultiHeadedAttention</cite> or <cite>RelPositionMultiHeadedAttention</cite> instance
can be used as the argument.</p></li>
<li><p><strong>feed_forward</strong> (<em>torch.nn.Module</em>) – Feed-forward module instance.
<cite>PositionwiseFeedForward</cite>, <cite>MultiLayeredConv1d</cite>, or <cite>Conv1dLinear</cite> instance
can be used as the argument.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>stochastic_depth_rate</strong> (<em>float</em>) – Proability to skip this layer.
During training, the layer may skip residual computation and return input
as-is with given probability.</p></li>
</ul>
</dd>
</dl>
<p>Construct an EncoderLayer object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.encoder_layer.EncoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/encoder_layer.html#EncoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.encoder_layer.EncoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute encoded features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_input</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, time).</p></li>
<li><p><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time, size).
torch.Tensor: Mask tensor (#batch, time).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-repeat">
<span id="id100"></span><h2>espnet.nets.pytorch_backend.transformer.repeat<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-repeat" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.repeat"></span><p>Repeat the same layer definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.repeat.MultiSequential">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.repeat.</code><code class="sig-name descname">MultiSequential</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/repeat.html#MultiSequential"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.repeat.MultiSequential" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.Sequential</span></code></p>
<p>Multi-input multi-output torch.nn.Sequential.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.repeat.MultiSequential.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/repeat.html#MultiSequential.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.repeat.MultiSequential.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Repeat.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.repeat.repeat">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.repeat.</code><code class="sig-name descname">repeat</code><span class="sig-paren">(</span><em class="sig-param">N</em>, <em class="sig-param">fn</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/repeat.html#repeat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.repeat.repeat" title="Permalink to this definition">¶</a></dt>
<dd><p>Repeat module N times.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<em>int</em>) – Number of repeat time.</p></li>
<li><p><strong>fn</strong> (<em>Callable</em>) – Function to generate module.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Repeated model instance.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#espnet.nets.pytorch_backend.transformer.repeat.MultiSequential" title="espnet.nets.pytorch_backend.transformer.repeat.MultiSequential">MultiSequential</a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-init">
<span id="id101"></span><h2>espnet.nets.pytorch_backend.transformer.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-transformer-label-smoothing-loss">
<span id="id102"></span><h2>espnet.nets.pytorch_backend.transformer.label_smoothing_loss<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-label-smoothing-loss" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.label_smoothing_loss"></span><p>Label smoothing module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.label_smoothing_loss.LabelSmoothingLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.label_smoothing_loss.</code><code class="sig-name descname">LabelSmoothingLoss</code><span class="sig-paren">(</span><em class="sig-param">size</em>, <em class="sig-param">padding_idx</em>, <em class="sig-param">smoothing</em>, <em class="sig-param">normalize_length=False</em>, <em class="sig-param">criterion=KLDivLoss()</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/label_smoothing_loss.html#LabelSmoothingLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.label_smoothing_loss.LabelSmoothingLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Label-smoothing loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – the number of class</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em>) – ignored class id</p></li>
<li><p><strong>smoothing</strong> (<em>float</em>) – smoothing rate (0.0 means the conventional CE)</p></li>
<li><p><strong>normalize_length</strong> (<em>bool</em>) – normalize loss by sequence length if True</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.Module</em>) – loss function to be smoothed</p></li>
</ul>
</dd>
</dl>
<p>Construct an LabelSmoothingLoss object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.label_smoothing_loss.LabelSmoothingLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">target</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/label_smoothing_loss.html#LabelSmoothingLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.label_smoothing_loss.LabelSmoothingLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute loss between x and target.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – prediction (batch, seqlen, class)</p></li>
<li><p><strong>target</strong> (<em>torch.Tensor</em>) – target signal masked with self.padding_id (batch, seqlen)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>scalar float value</p>
</dd>
</dl>
<p>:rtype torch.Tensor</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-dynamic-conv2d">
<span id="id103"></span><h2>espnet.nets.pytorch_backend.transformer.dynamic_conv2d<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-dynamic-conv2d" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.dynamic_conv2d"></span><p>Dynamic 2-Dimensional Convolution module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.dynamic_conv2d.DynamicConvolution2D">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.dynamic_conv2d.</code><code class="sig-name descname">DynamicConvolution2D</code><span class="sig-paren">(</span><em class="sig-param">wshare</em>, <em class="sig-param">n_feat</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">use_kernel_mask=False</em>, <em class="sig-param">use_bias=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/dynamic_conv2d.html#DynamicConvolution2D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.dynamic_conv2d.DynamicConvolution2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Dynamic 2-Dimensional Convolution layer.</p>
<p>This implementation is based on
<a class="reference external" href="https://github.com/pytorch/fairseq/tree/master/fairseq">https://github.com/pytorch/fairseq/tree/master/fairseq</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>wshare</strong> (<em>int</em>) – the number of kernel of convolution</p></li>
<li><p><strong>n_feat</strong> (<em>int</em>) – the number of features</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout_rate</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size (length)</p></li>
<li><p><strong>use_kernel_mask</strong> (<em>bool</em>) – Use causal mask or not for convolution kernel</p></li>
<li><p><strong>use_bias</strong> (<em>bool</em>) – Use bias term or not.</p></li>
</ul>
</dd>
</dl>
<p>Construct Dynamic 2-Dimensional Convolution layer.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.dynamic_conv2d.DynamicConvolution2D.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/dynamic_conv2d.html#DynamicConvolution2D.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.dynamic_conv2d.DynamicConvolution2D.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward of ‘Dynamic 2-Dimensional Convolution’.</p>
<p>This function takes query, key and value but uses only query.
This is just for compatibility with self-attention layer (attention.py)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – (batch, time1, d_model) input tensor</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – (batch, time2, d_model) NOT USED</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – (batch, time2, d_model) NOT USED</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – (batch, time1, time2) mask</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(batch, time1, d_model) output</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-subsampling-without-posenc">
<span id="id104"></span><h2>espnet.nets.pytorch_backend.transformer.subsampling_without_posenc<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-subsampling-without-posenc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.subsampling_without_posenc"></span><p>Subsampling layer definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling_without_posenc.Conv2dSubsamplingWOPosEnc">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.subsampling_without_posenc.</code><code class="sig-name descname">Conv2dSubsamplingWOPosEnc</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">kernels</em>, <em class="sig-param">strides</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling_without_posenc.html#Conv2dSubsamplingWOPosEnc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling_without_posenc.Conv2dSubsamplingWOPosEnc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional 2D subsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Output dimension.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>kernels</strong> (<em>list</em>) – kernel sizes</p></li>
<li><p><strong>strides</strong> (<em>list</em>) – stride sizes</p></li>
</ul>
</dd>
</dl>
<p>Construct an Conv2dSubsamplingWOPosEnc object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.subsampling_without_posenc.Conv2dSubsamplingWOPosEnc.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/subsampling_without_posenc.html#Conv2dSubsamplingWOPosEnc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.subsampling_without_posenc.Conv2dSubsamplingWOPosEnc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Subsample x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, time, idim).</p></li>
<li><p><strong>x_mask</strong> (<em>torch.Tensor</em>) – Input mask (#batch, 1, time).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Subsampled tensor (#batch, time’, odim),</dt><dd><p>where time’ = time // 4.</p>
</dd>
<dt>torch.Tensor: Subsampled mask (#batch, 1, time’),</dt><dd><p>where time’ = time // 4.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-encoder-mix">
<span id="id105"></span><h2>espnet.nets.pytorch_backend.transformer.encoder_mix<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-encoder-mix" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.encoder_mix"></span><p>Encoder Mix definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.encoder_mix.</code><code class="sig-name descname">EncoderMix</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">attention_dim=256</em>, <em class="sig-param">attention_heads=4</em>, <em class="sig-param">linear_units=2048</em>, <em class="sig-param">num_blocks_sd=4</em>, <em class="sig-param">num_blocks_rec=8</em>, <em class="sig-param">dropout_rate=0.1</em>, <em class="sig-param">positional_dropout_rate=0.1</em>, <em class="sig-param">attention_dropout_rate=0.0</em>, <em class="sig-param">input_layer='conv2d'</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before=True</em>, <em class="sig-param">concat_after=False</em>, <em class="sig-param">positionwise_layer_type='linear'</em>, <em class="sig-param">positionwise_conv_kernel_size=1</em>, <em class="sig-param">padding_idx=-1</em>, <em class="sig-param">num_spkrs=2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/encoder_mix.html#EncoderMix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.transformer.encoder.Encoder" title="espnet.nets.pytorch_backend.transformer.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.transformer.encoder.Encoder</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transformer encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – input dim</p></li>
<li><p><strong>attention_dim</strong> (<em>int</em>) – dimension of attention</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – the number of heads of multi head attention</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – the number of units of position-wise feed forward</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em>) – the number of decoder blocks</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout rate</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – dropout rate in attention</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – dropout rate after adding positional encoding</p></li>
<li><p><strong>or torch.nn.Module input_layer</strong> (<em>str</em>) – input layer type</p></li>
<li><p><strong>pos_enc_class</strong> (<em>class</em>) – PositionalEncoding or ScaledPositionalEncoding</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – whether to use layer_norm before the first block</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – whether to concat attention layer’s input and output
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>positionwise_layer_type</strong> (<em>str</em>) – linear of conv1d</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – kernel size of positionwise conv1d layer</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em>) – padding_idx for input_layer=embed</p></li>
</ul>
</dd>
</dl>
<p>Construct an Encoder object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">masks</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/encoder_mix.html#EncoderMix.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – input tensor</p></li>
<li><p><strong>masks</strong> (<em>torch.Tensor</em>) – input mask</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
<dt class="field-odd">Rtype Tuple[torch.Tensor, torch.Tensor]</dt>
<dd class="field-odd"><p></p></dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix.forward_one_step">
<code class="sig-name descname">forward_one_step</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">masks</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/encoder_mix.html#EncoderMix.forward_one_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.encoder_mix.EncoderMix.forward_one_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input frame.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – input tensor</p></li>
<li><p><strong>masks</strong> (<em>torch.Tensor</em>) – input mask</p></li>
<li><p><strong>cache</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – cache tensors</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>position embedded tensor, mask and new cache</p>
</dd>
<dt class="field-odd">Rtype Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]</dt>
<dd class="field-odd"><p></p></dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-argument">
<span id="id106"></span><h2>espnet.nets.pytorch_backend.transformer.argument<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-argument" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.argument"></span><p>Transformer common arguments.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.argument.add_arguments_transformer_common">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.argument.</code><code class="sig-name descname">add_arguments_transformer_common</code><span class="sig-paren">(</span><em class="sig-param">group</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/argument.html#add_arguments_transformer_common"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.argument.add_arguments_transformer_common" title="Permalink to this definition">¶</a></dt>
<dd><p>Add Transformer common arguments.</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-lightconv">
<span id="id107"></span><h2>espnet.nets.pytorch_backend.transformer.lightconv<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-lightconv" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.lightconv"></span><p>Lightweight Convolution Module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.lightconv.LightweightConvolution">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.lightconv.</code><code class="sig-name descname">LightweightConvolution</code><span class="sig-paren">(</span><em class="sig-param">wshare</em>, <em class="sig-param">n_feat</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">use_kernel_mask=False</em>, <em class="sig-param">use_bias=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/lightconv.html#LightweightConvolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.lightconv.LightweightConvolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Lightweight Convolution layer.</p>
<p>This implementation is based on
<a class="reference external" href="https://github.com/pytorch/fairseq/tree/master/fairseq">https://github.com/pytorch/fairseq/tree/master/fairseq</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>wshare</strong> (<em>int</em>) – the number of kernel of convolution</p></li>
<li><p><strong>n_feat</strong> (<em>int</em>) – the number of features</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout_rate</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size (length)</p></li>
<li><p><strong>use_kernel_mask</strong> (<em>bool</em>) – Use causal mask or not for convolution kernel</p></li>
<li><p><strong>use_bias</strong> (<em>bool</em>) – Use bias term or not.</p></li>
</ul>
</dd>
</dl>
<p>Construct Lightweight Convolution layer.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.lightconv.LightweightConvolution.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/lightconv.html#LightweightConvolution.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.lightconv.LightweightConvolution.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward of ‘Lightweight Convolution’.</p>
<p>This function takes query, key and value but uses only query.
This is just for compatibility with self-attention layer (attention.py)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – (batch, time1, d_model) input tensor</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – (batch, time2, d_model) NOT USED</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – (batch, time2, d_model) NOT USED</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – (batch, time1, time2) mask</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(batch, time1, d_model) output</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-positionwise-feed-forward">
<span id="id108"></span><h2>espnet.nets.pytorch_backend.transformer.positionwise_feed_forward<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-positionwise-feed-forward" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.positionwise_feed_forward"></span><p>Positionwise feed forward layer definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.positionwise_feed_forward.</code><code class="sig-name descname">PositionwiseFeedForward</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">hidden_units</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">activation=ReLU()</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/positionwise_feed_forward.html#PositionwiseFeedForward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Positionwise feed forward layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimenstion.</p></li>
<li><p><strong>hidden_units</strong> (<em>int</em>) – The number of hidden units.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct an PositionwiseFeedForward object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/positionwise_feed_forward.html#PositionwiseFeedForward.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward function.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-initializer">
<span id="id109"></span><h2>espnet.nets.pytorch_backend.transformer.initializer<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-initializer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.initializer"></span><p>Parameter initialization.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.initializer.initialize">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.initializer.</code><code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">init_type='pytorch'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/initializer.html#initialize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.initializer.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize Transformer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – transformer instance</p></li>
<li><p><strong>init_type</strong> (<em>str</em>) – initialization type</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-add-sos-eos">
<span id="id110"></span><h2>espnet.nets.pytorch_backend.transformer.add_sos_eos<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-add-sos-eos" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.add_sos_eos"></span><p>Unility functions for Transformer.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.transformer.add_sos_eos.add_sos_eos">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.add_sos_eos.</code><code class="sig-name descname">add_sos_eos</code><span class="sig-paren">(</span><em class="sig-param">ys_pad</em>, <em class="sig-param">sos</em>, <em class="sig-param">eos</em>, <em class="sig-param">ignore_id</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/add_sos_eos.html#add_sos_eos"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.add_sos_eos.add_sos_eos" title="Permalink to this definition">¶</a></dt>
<dd><p>Add &lt;sos&gt; and &lt;eos&gt; labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</p></li>
<li><p><strong>sos</strong> (<em>int</em>) – index of &lt;sos&gt;</p></li>
<li><p><strong>eos</strong> (<em>int</em>) – index of &lt;eos&gt;</p></li>
<li><p><strong>ignore_id</strong> (<em>int</em>) – index of padding</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>padded tensor (B, Lmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>padded tensor (B, Lmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-longformer-attention">
<span id="id111"></span><h2>espnet.nets.pytorch_backend.transformer.longformer_attention<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-longformer-attention" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.longformer_attention"></span><p>Longformer based Local Attention Definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.longformer_attention.LongformerAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.longformer_attention.</code><code class="sig-name descname">LongformerAttention</code><span class="sig-paren">(</span><em class="sig-param">config: longformer.longformer.LongformerConfig</em>, <em class="sig-param">layer_id: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/longformer_attention.html#LongformerAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.longformer_attention.LongformerAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Longformer based Local Attention Definition.</p>
<p>Compute Longformer based Self-Attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> – Longformer attention configuration</p></li>
<li><p><strong>layer_id</strong> – Integer representing the layer index</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.longformer_attention.LongformerAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/longformer_attention.html#LongformerAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.longformer_attention.LongformerAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Longformer Self-Attention with masking.</p>
<p>Expects <cite>len(hidden_states)</cite> to be multiple of <cite>attention_window</cite>.
Padding to <cite>attention_window</cite> happens in <code class="xref py py-meth docutils literal notranslate"><span class="pre">encoder.forward()</span></code>
to avoid redoing the padding on each layer.
:param query: Query tensor (#batch, time1, size).
:type query: torch.Tensor
:param key: Key tensor (#batch, time2, size).
:type key: torch.Tensor
:param value: Value tensor (#batch, time2, size).
:type value: torch.Tensor
:param pos_emb: Positional embedding tensor</p>
<blockquote>
<div><p>(#batch, 2*time1-1, size).</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor (#batch, 1, time2) or
(#batch, time1, time2).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor (#batch, time1, d_model).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transformer-decoder-layer">
<span id="id112"></span><h2>espnet.nets.pytorch_backend.transformer.decoder_layer<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer-decoder-layer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer.decoder_layer"></span><p>Decoder self-attention layer definition.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transformer.decoder_layer.DecoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transformer.decoder_layer.</code><code class="sig-name descname">DecoderLayer</code><span class="sig-paren">(</span><em class="sig-param">size</em>, <em class="sig-param">self_attn</em>, <em class="sig-param">src_attn</em>, <em class="sig-param">feed_forward</em>, <em class="sig-param">dropout_rate</em>, <em class="sig-param">normalize_before=True</em>, <em class="sig-param">concat_after=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/decoder_layer.html#DecoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.decoder_layer.DecoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Single decoder layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>self_attn</strong> (<em>torch.nn.Module</em>) – Self-attention module instance.
<cite>MultiHeadedAttention</cite> instance can be used as the argument.</p></li>
<li><p><strong>src_attn</strong> (<em>torch.nn.Module</em>) – Self-attention module instance.
<cite>MultiHeadedAttention</cite> instance can be used as the argument.</p></li>
<li><p><strong>feed_forward</strong> (<em>torch.nn.Module</em>) – Feed-forward module instance.
<cite>PositionwiseFeedForward</cite>, <cite>MultiLayeredConv1d</cite>, or <cite>Conv1dLinear</cite> instance
can be used as the argument.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
</ul>
</dd>
</dl>
<p>Construct an DecoderLayer object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transformer.decoder_layer.DecoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">tgt</em>, <em class="sig-param">tgt_mask</em>, <em class="sig-param">memory</em>, <em class="sig-param">memory_mask</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transformer/decoder_layer.html#DecoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transformer.decoder_layer.DecoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute decoded features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tgt</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, maxlen_out, size).</p></li>
<li><p><strong>tgt_mask</strong> (<em>torch.Tensor</em>) – Mask for input tensor (#batch, maxlen_out).</p></li>
<li><p><strong>memory</strong> (<em>torch.Tensor</em>) – Encoded memory, float32 (#batch, maxlen_in, size).</p></li>
<li><p><strong>memory_mask</strong> (<em>torch.Tensor</em>) – Encoded memory mask (#batch, maxlen_in).</p></li>
<li><p><strong>cache</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – List of cached tensors.
Each tensor shape should be (#batch, maxlen_out - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor(#batch, maxlen_out, size).
torch.Tensor: Mask for output tensor (#batch, maxlen_out).
torch.Tensor: Encoded memory (#batch, maxlen_in, size).
torch.Tensor: Encoded memory mask (#batch, maxlen_in).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-rnn-init">
<span id="id113"></span><h2>espnet.nets.pytorch_backend.rnn.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-rnn-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.rnn.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-rnn-attentions">
<span id="id114"></span><h2>espnet.nets.pytorch_backend.rnn.attentions<a class="headerlink" href="#espnet-nets-pytorch-backend-rnn-attentions" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.rnn.attentions"></span><p>Attention modules for RNN.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttAdd">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttAdd</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttAdd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttAdd" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Additive attention</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention
and not store pre_compute_enc_h</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttAdd.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em>, <em class="sig-param">scaling=2.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttAdd.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttAdd.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttAdd forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – dummy (does not use)</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>previous attention weights (B x T_max)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttAdd.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttAdd.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttAdd.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttCov">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttCov</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttCov"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttCov" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Coverage mechanism attention</p>
<dl class="simple">
<dt>Reference: Get To The Point: Summarization with Pointer-Generator Network</dt><dd><p>(<a class="reference external" href="https://arxiv.org/abs/1704.04368">https://arxiv.org/abs/1704.04368</a>)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention
and not store pre_compute_enc_h</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttCov.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev_list</em>, <em class="sig-param">scaling=2.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttCov.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttCov.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttCov forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev_list</strong> (<em>list</em>) – list of previous attention weight</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of previous attention weights</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttCov.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttCov.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttCov.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttCovLoc">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttCovLoc</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttCovLoc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttCovLoc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Coverage mechanism location aware attention</p>
<p>This attention is a combination of coverage and location-aware attentions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention and not store pre_compute_enc_h</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttCovLoc.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev_list</em>, <em class="sig-param">scaling=2.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttCovLoc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttCovLoc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttCovLoc forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev_list</strong> (<em>list</em>) – list of previous attention weight</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of previous attention weights</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttCovLoc.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttCovLoc.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttCovLoc.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttDot">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttDot</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttDot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttDot" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Dot product attention</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention
and not store pre_compute_enc_h</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttDot.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em>, <em class="sig-param">scaling=2.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttDot.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttDot.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttDot forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – dummy (does not use)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – dummy (does not use)</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>previous attention weight (B x T_max)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttDot.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttDot.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttDot.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttForward">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttForward</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttForward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Forward attention module.</p>
<p>Reference:
Forward attention in sequence-to-sequence acoustic modeling for speech synthesis</p>
<blockquote>
<div><p>(<a class="reference external" href="https://arxiv.org/pdf/1807.06736.pdf">https://arxiv.org/pdf/1807.06736.pdf</a>)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttForward.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em>, <em class="sig-param">scaling=1.0</em>, <em class="sig-param">last_attended_idx=None</em>, <em class="sig-param">backward_window=1</em>, <em class="sig-param">forward_window=3</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttForward.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttForward.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate AttForward forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – attention weights of previous step</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
<li><p><strong>last_attended_idx</strong> (<em>int</em>) – index of the inputs of the last attended</p></li>
<li><p><strong>backward_window</strong> (<em>int</em>) – backward window size in attention constraint</p></li>
<li><p><strong>forward_window</strong> (<em>int</em>) – forward window size in attetion constraint</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>previous attention weights (B x T_max)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttForward.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttForward.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttForward.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttForwardTA</code><span class="sig-paren">(</span><em class="sig-param">eunits</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em>, <em class="sig-param">odim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttForwardTA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Forward attention with transition agent module.</p>
<p>Reference:
Forward attention in sequence-to-sequence acoustic modeling for speech synthesis</p>
<blockquote>
<div><p>(<a class="reference external" href="https://arxiv.org/pdf/1807.06736.pdf">https://arxiv.org/pdf/1807.06736.pdf</a>)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eunits</strong> (<em>int</em>) – # units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – output dimension</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em>, <em class="sig-param">out_prev</em>, <em class="sig-param">scaling=1.0</em>, <em class="sig-param">last_attended_idx=None</em>, <em class="sig-param">backward_window=1</em>, <em class="sig-param">forward_window=3</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttForwardTA.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate AttForwardTA forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B, Tmax, eunits)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B, dunits)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – attention weights of previous step</p></li>
<li><p><strong>out_prev</strong> (<em>torch.Tensor</em>) – decoder outputs of previous step (B, odim)</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
<li><p><strong>last_attended_idx</strong> (<em>int</em>) – index of the inputs of the last attended</p></li>
<li><p><strong>backward_window</strong> (<em>int</em>) – backward window size in attention constraint</p></li>
<li><p><strong>forward_window</strong> (<em>int</em>) – forward window size in attetion constraint</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, dunits)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>previous attention weights (B, Tmax)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttForwardTA.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttForwardTA.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttLoc">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttLoc</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttLoc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttLoc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>location-aware attention module.</p>
<dl class="simple">
<dt>Reference: Attention-Based Models for Speech Recognition</dt><dd><p>(<a class="reference external" href="https://arxiv.org/pdf/1506.07503.pdf">https://arxiv.org/pdf/1506.07503.pdf</a>)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention
and not store pre_compute_enc_h</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttLoc.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em>, <em class="sig-param">scaling=2.0</em>, <em class="sig-param">last_attended_idx=None</em>, <em class="sig-param">backward_window=1</em>, <em class="sig-param">forward_window=3</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttLoc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttLoc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate AttLoc forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – previous attention weight (B x T_max)</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
<li><p><strong>forward_window</strong> (<em>int</em>) – forward window size when constraining attention</p></li>
<li><p><strong>last_attended_idx</strong> (<em>int</em>) – index of the inputs of the last attended</p></li>
<li><p><strong>backward_window</strong> (<em>int</em>) – backward window size in attention constraint</p></li>
<li><p><strong>forward_window</strong> – forward window size in attetion constraint</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>previous attention weights (B x T_max)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttLoc.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttLoc.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttLoc.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttLoc2D">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttLoc2D</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">att_win</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttLoc2D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttLoc2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>2D location-aware attention</p>
<p>This attention is an extended version of location aware attention.
It take not only one frame before attention weights,
but also earlier frames into account.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</p></li>
<li><p><strong>att_win</strong> (<em>int</em>) – attention window size (default=5)</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention and not store pre_compute_enc_h</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttLoc2D.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em>, <em class="sig-param">scaling=2.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttLoc2D.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttLoc2D.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttLoc2D forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – previous attention weight (B x att_win x T_max)</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>previous attention weights (B x att_win x T_max)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttLoc2D.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttLoc2D.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttLoc2D.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttLocRec">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttLocRec</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">att_dim</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttLocRec"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttLocRec" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>location-aware recurrent attention</p>
<p>This attention is an extended version of location aware attention.
With the use of RNN,
it take the effect of the history of attention weights into account.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>att_dim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention and not store pre_compute_enc_h</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttLocRec.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev_states</em>, <em class="sig-param">scaling=2.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttLocRec.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttLocRec.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttLocRec forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev_states</strong> (<em>tuple</em>) – previous attention weight and lstm states
((B, T_max), ((B, att_dim), (B, att_dim)))</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>previous attention weights and lstm states (w, (hx, cx))
((B, T_max), ((B, att_dim), (B, att_dim)))</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttLocRec.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttLocRec.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttLocRec.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttMultiHeadAdd</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">aheads</em>, <em class="sig-param">att_dim_k</em>, <em class="sig-param">att_dim_v</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadAdd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi head additive attention</p>
<dl class="simple">
<dt>Reference: Attention is all you need</dt><dd><p>(<a class="reference external" href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>)</p>
</dd>
</dl>
<p>This attention is multi head attention using additive attention for each head.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>aheads</strong> (<em>int</em>) – # heads of multi head attention</p></li>
<li><p><strong>att_dim_k</strong> (<em>int</em>) – dimension k in multi head attention</p></li>
<li><p><strong>att_dim_v</strong> (<em>int</em>) – dimension v in multi head attention</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention
and not store pre_compute_k and pre_compute_v</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadAdd.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttMultiHeadAdd forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – dummy (does not use)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of previous attention weight (B x T_max) * aheads</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadAdd.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadAdd.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttMultiHeadDot</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">aheads</em>, <em class="sig-param">att_dim_k</em>, <em class="sig-param">att_dim_v</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadDot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi head dot product attention</p>
<dl class="simple">
<dt>Reference: Attention is all you need</dt><dd><p>(<a class="reference external" href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>aheads</strong> (<em>int</em>) – # heads of multi head attention</p></li>
<li><p><strong>att_dim_k</strong> (<em>int</em>) – dimension k in multi head attention</p></li>
<li><p><strong>att_dim_v</strong> (<em>int</em>) – dimension v in multi head attention</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention
and not store pre_compute_k and pre_compute_v</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadDot.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttMultiHeadDot forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – dummy (does not use)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B x D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of previous attention weight (B x T_max) * aheads</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadDot.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadDot.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttMultiHeadLoc</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">aheads</em>, <em class="sig-param">att_dim_k</em>, <em class="sig-param">att_dim_v</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadLoc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi head location based attention</p>
<dl class="simple">
<dt>Reference: Attention is all you need</dt><dd><p>(<a class="reference external" href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>)</p>
</dd>
</dl>
<p>This attention is multi head attention using location-aware attention for each head.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>aheads</strong> (<em>int</em>) – # heads of multi head attention</p></li>
<li><p><strong>att_dim_k</strong> (<em>int</em>) – dimension k in multi head attention</p></li>
<li><p><strong>att_dim_v</strong> (<em>int</em>) – dimension v in multi head attention</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention
and not store pre_compute_k and pre_compute_v</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em>, <em class="sig-param">scaling=2.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadLoc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttMultiHeadLoc forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – list of previous attention weight (B x T_max) * aheads</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – scaling parameter before applying softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B x D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of previous attention weight (B x T_max) * aheads</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadLoc.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadLoc.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">AttMultiHeadMultiResLoc</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">aheads</em>, <em class="sig-param">att_dim_k</em>, <em class="sig-param">att_dim_v</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadMultiResLoc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi head multi resolution location based attention</p>
<dl class="simple">
<dt>Reference: Attention is all you need</dt><dd><p>(<a class="reference external" href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>)</p>
</dd>
</dl>
<p>This attention is multi head attention using location-aware attention for each head.
Furthermore, it uses different filter size for each head.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>aheads</strong> (<em>int</em>) – # heads of multi head attention</p></li>
<li><p><strong>att_dim_k</strong> (<em>int</em>) – dimension k in multi head attention</p></li>
<li><p><strong>att_dim_v</strong> (<em>int</em>) – dimension v in multi head attention</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – maximum # channels of attention convolution
each head use #ch = aconv_chans * (head + 1) / aheads
e.g. aheads=4, aconv_chans=100 =&gt; filter size = 25, 50, 75, 100</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention
and not store pre_compute_k and pre_compute_v</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadMultiResLoc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>AttMultiHeadMultiResLoc forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B x T_max x D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – decoder hidden state (B x D_dec)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – list of previous attention weight
(B x T_max) * aheads</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B x D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of previous attention weight (B x T_max) * aheads</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#AttMultiHeadMultiResLoc.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.AttMultiHeadMultiResLoc.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.NoAtt">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">NoAtt</code><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#NoAtt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.NoAtt" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>No attention</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.NoAtt.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_hs_pad</em>, <em class="sig-param">enc_hs_len</em>, <em class="sig-param">dec_z</em>, <em class="sig-param">att_prev</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#NoAtt.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.NoAtt.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>NoAtt forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_hs_pad</strong> (<em>torch.Tensor</em>) – padded encoder hidden state (B, T_max, D_enc)</p></li>
<li><p><strong>enc_hs_len</strong> (<em>list</em>) – padded encoder hidden state length (B)</p></li>
<li><p><strong>dec_z</strong> (<em>torch.Tensor</em>) – dummy (does not use)</p></li>
<li><p><strong>att_prev</strong> (<em>torch.Tensor</em>) – dummy (does not use)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention weighted encoder state (B, D_enc)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>previous attention weights</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.NoAtt.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#NoAtt.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.NoAtt.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.att_for">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">att_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">num_att=1</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#att_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.att_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an attention module given the program arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>Namespace</em>) – The arguments</p></li>
<li><p><strong>num_att</strong> (<em>int</em>) – number of attention modules
(in multi-speaker case, it can be 2 or more)</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – switch on/off mode of hierarchical attention network (HAN)</p></li>
</ul>
</dd>
</dl>
<p>:rtype torch.nn.Module
:return: The attention module</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.att_to_numpy">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">att_to_numpy</code><span class="sig-paren">(</span><em class="sig-param">att_ws</em>, <em class="sig-param">att</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#att_to_numpy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.att_to_numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts attention weights to a numpy array given the attention</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>att_ws</strong> (<em>list</em>) – The attention weights</p></li>
<li><p><strong>att</strong> (<em>torch.nn.Module</em>) – The attention</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>np.ndarray</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The numpy array of the attention weights</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.rnn.attentions.initial_att">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.attentions.</code><code class="sig-name descname">initial_att</code><span class="sig-paren">(</span><em class="sig-param">atype</em>, <em class="sig-param">eprojs</em>, <em class="sig-param">dunits</em>, <em class="sig-param">aheads</em>, <em class="sig-param">adim</em>, <em class="sig-param">awin</em>, <em class="sig-param">aconv_chans</em>, <em class="sig-param">aconv_filts</em>, <em class="sig-param">han_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/attentions.html#initial_att"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.attentions.initial_att" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a single attention module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>atype</strong> (<em>str</em>) – attention type</p></li>
<li><p><strong>eprojs</strong> (<em>int</em>) – # projection-units of encoder</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – # units of decoder</p></li>
<li><p><strong>aheads</strong> (<em>int</em>) – # heads of multi head attention</p></li>
<li><p><strong>adim</strong> (<em>int</em>) – attention dimension</p></li>
<li><p><strong>awin</strong> (<em>int</em>) – attention window size</p></li>
<li><p><strong>aconv_chans</strong> (<em>int</em>) – # channels of attention convolution</p></li>
<li><p><strong>aconv_filts</strong> (<em>int</em>) – filter size of attention convolution</p></li>
<li><p><strong>han_mode</strong> (<em>bool</em>) – flag to swith on mode of hierarchical attention</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The attention module</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-rnn-argument">
<span id="id115"></span><h2>espnet.nets.pytorch_backend.rnn.argument<a class="headerlink" href="#espnet-nets-pytorch-backend-rnn-argument" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.rnn.argument"></span><p>Conformer common arguments.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.rnn.argument.add_arguments_rnn_attention_common">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.argument.</code><code class="sig-name descname">add_arguments_rnn_attention_common</code><span class="sig-paren">(</span><em class="sig-param">group</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/argument.html#add_arguments_rnn_attention_common"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.argument.add_arguments_rnn_attention_common" title="Permalink to this definition">¶</a></dt>
<dd><p>Define common arguments for RNN attention.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.rnn.argument.add_arguments_rnn_decoder_common">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.argument.</code><code class="sig-name descname">add_arguments_rnn_decoder_common</code><span class="sig-paren">(</span><em class="sig-param">group</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/argument.html#add_arguments_rnn_decoder_common"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.argument.add_arguments_rnn_decoder_common" title="Permalink to this definition">¶</a></dt>
<dd><p>Define common arguments for RNN decoder.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.rnn.argument.add_arguments_rnn_encoder_common">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.argument.</code><code class="sig-name descname">add_arguments_rnn_encoder_common</code><span class="sig-paren">(</span><em class="sig-param">group</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/argument.html#add_arguments_rnn_encoder_common"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.argument.add_arguments_rnn_encoder_common" title="Permalink to this definition">¶</a></dt>
<dd><p>Define common arguments for RNN encoder.</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-rnn-decoders">
<span id="id116"></span><h2>espnet.nets.pytorch_backend.rnn.decoders<a class="headerlink" href="#espnet-nets-pytorch-backend-rnn-decoders" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.rnn.decoders"></span><p>RNN decoder module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.Decoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.decoders.</code><code class="sig-name descname">Decoder</code><span class="sig-paren">(</span><em class="sig-param">eprojs</em>, <em class="sig-param">odim</em>, <em class="sig-param">dtype</em>, <em class="sig-param">dlayers</em>, <em class="sig-param">dunits</em>, <em class="sig-param">sos</em>, <em class="sig-param">eos</em>, <em class="sig-param">att</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">char_list=None</em>, <em class="sig-param">labeldist=None</em>, <em class="sig-param">lsm_weight=0.0</em>, <em class="sig-param">sampling_probability=0.0</em>, <em class="sig-param">dropout=0.0</em>, <em class="sig-param">context_residual=False</em>, <em class="sig-param">replace_sos=False</em>, <em class="sig-param">num_encs=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#Decoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <a class="reference internal" href="#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.ScorerInterface</span></code></a></p>
<p>Decoder module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eprojs</strong> (<em>int</em>) – encoder projection units</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – dimension of outputs</p></li>
<li><p><strong>dtype</strong> (<em>str</em>) – gru or lstm</p></li>
<li><p><strong>dlayers</strong> (<em>int</em>) – decoder layers</p></li>
<li><p><strong>dunits</strong> (<em>int</em>) – decoder units</p></li>
<li><p><strong>sos</strong> (<em>int</em>) – start of sequence symbol id</p></li>
<li><p><strong>eos</strong> (<em>int</em>) – end of sequence symbol id</p></li>
<li><p><strong>att</strong> (<em>torch.nn.Module</em>) – attention module</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – verbose level</p></li>
<li><p><strong>char_list</strong> (<em>list</em>) – list of character strings</p></li>
<li><p><strong>labeldist</strong> (<em>ndarray</em>) – distribution of label smoothing</p></li>
<li><p><strong>lsm_weight</strong> (<em>float</em>) – label smoothing weight</p></li>
<li><p><strong>sampling_probability</strong> (<em>float</em>) – scheduled sampling probability</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout rate</p></li>
<li><p><strong>context_residual</strong> (<em>float</em>) – if True, use context vector for token generation</p></li>
<li><p><strong>replace_sos</strong> (<em>float</em>) – use for multilingual (speech/text) translation</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.Decoder.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em>, <em class="sig-param">hlen</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">strm_idx=0</em>, <em class="sig-param">lang_ids=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#Decoder.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.Decoder.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all of attentions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> (<em>torch.Tensor</em>) – batch of padded hidden state sequences
(B, Tmax, D)
in multi-encoder case, list of torch.Tensor,
[(B, Tmax_1, D), (B, Tmax_2, D), …, ] ]</p></li>
<li><p><strong>hlen</strong> (<em>torch.Tensor</em>) – batch of lengths of hidden state sequences (B)
[in multi-encoder case, list of torch.Tensor,
[(B), (B), …, ]</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, Lmax)</p></li>
<li><p><strong>strm_idx</strong> (<em>int</em>) – stream index for parallel speaker attention in multi-speaker case</p></li>
<li><p><strong>lang_ids</strong> (<em>torch.Tensor</em>) – batch of target language id tensor (B, 1)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>attention weights with the following shape,
1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
2) multi-encoder case =&gt;</p>
<blockquote>
<div><p>[(B, Lmax, Tmax1), (B, Lmax, Tmax2), …, (B, Lmax, NumEncs)]</p>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>other case =&gt; attention weights (B, Lmax, Tmax).</p></li>
</ol>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.Decoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em>, <em class="sig-param">hlens</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">strm_idx=0</em>, <em class="sig-param">lang_ids=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#Decoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.Decoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Decoder forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> (<em>torch.Tensor</em>) – batch of padded hidden state sequences (B, Tmax, D)
[in multi-encoder case,
list of torch.Tensor,
[(B, Tmax_1, D), (B, Tmax_2, D), …, ] ]</p></li>
<li><p><strong>hlens</strong> (<em>torch.Tensor</em>) – batch of lengths of hidden state sequences (B)
[in multi-encoder case, list of torch.Tensor,
[(B), (B), …, ]</p></li>
<li><p><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor
(B, Lmax)</p></li>
<li><p><strong>strm_idx</strong> (<em>int</em>) – stream index indicates the index of decoding stream.</p></li>
<li><p><strong>lang_ids</strong> (<em>torch.Tensor</em>) – batch of target language id tensor (B, 1)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>attention loss value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>accuracy</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.Decoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#Decoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.Decoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an initial state for decoding (optional).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoded feature tensor</p>
</dd>
</dl>
<p>Returns: initial state</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.Decoder.recognize_beam">
<code class="sig-name descname">recognize_beam</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">lpz</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em>, <em class="sig-param">strm_idx=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#Decoder.recognize_beam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.Decoder.recognize_beam" title="Permalink to this definition">¶</a></dt>
<dd><p>beam search implementation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h</strong> (<em>torch.Tensor</em>) – encoder hidden state (T, eprojs)
[in multi-encoder case, list of torch.Tensor,
[(T1, eprojs), (T2, eprojs), …] ]</p></li>
<li><p><strong>lpz</strong> (<em>torch.Tensor</em>) – ctc log softmax output (T, odim)
[in multi-encoder case, list of torch.Tensor,
[(T1, odim), (T2, odim), …] ]</p></li>
<li><p><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</p></li>
<li><p><strong>char_list</strong> – list of character strings</p></li>
<li><p><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language module</p></li>
<li><p><strong>strm_idx</strong> (<em>int</em>) – stream index for speaker parallel attention in multi-speaker case</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>N-best decoding results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of dicts</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.Decoder.recognize_beam_batch">
<code class="sig-name descname">recognize_beam_batch</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">hlens</em>, <em class="sig-param">lpz</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">char_list</em>, <em class="sig-param">rnnlm=None</em>, <em class="sig-param">normalize_score=True</em>, <em class="sig-param">strm_idx=0</em>, <em class="sig-param">lang_ids=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#Decoder.recognize_beam_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.Decoder.recognize_beam_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.Decoder.rnn_forward">
<code class="sig-name descname">rnn_forward</code><span class="sig-paren">(</span><em class="sig-param">ey</em>, <em class="sig-param">z_list</em>, <em class="sig-param">c_list</em>, <em class="sig-param">z_prev</em>, <em class="sig-param">c_prev</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#Decoder.rnn_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.Decoder.rnn_forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.Decoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">yseq</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#Decoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.Decoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</p></li>
<li><p><strong>state</strong> – Scorer state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>scores for next token that has a shape of <cite>(n_vocab)</cite>
and next state for ys</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.Decoder.zero_state">
<code class="sig-name descname">zero_state</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#Decoder.zero_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.Decoder.zero_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.rnn.decoders.decoder_for">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.decoders.</code><code class="sig-name descname">decoder_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">odim</em>, <em class="sig-param">sos</em>, <em class="sig-param">eos</em>, <em class="sig-param">att</em>, <em class="sig-param">labeldist</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/decoders.html#decoder_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.decoders.decoder_for" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-rnn-encoders">
<span id="id117"></span><h2>espnet.nets.pytorch_backend.rnn.encoders<a class="headerlink" href="#espnet-nets-pytorch-backend-rnn-encoders" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.rnn.encoders"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.encoders.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">etype</em>, <em class="sig-param">idim</em>, <em class="sig-param">elayers</em>, <em class="sig-param">eunits</em>, <em class="sig-param">eprojs</em>, <em class="sig-param">subsample</em>, <em class="sig-param">dropout</em>, <em class="sig-param">in_channel=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encoder module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>etype</strong> (<em>str</em>) – type of encoder network</p></li>
<li><p><strong>idim</strong> (<em>int</em>) – number of dimensions of encoder network</p></li>
<li><p><strong>elayers</strong> (<em>int</em>) – number of layers of encoder network</p></li>
<li><p><strong>eunits</strong> (<em>int</em>) – number of lstm units of encoder network</p></li>
<li><p><strong>eprojs</strong> (<em>int</em>) – number of projection units of encoder network</p></li>
<li><p><strong>subsample</strong> (<em>np.ndarray</em>) – list of subsampling numbers</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout rate</p></li>
<li><p><strong>in_channel</strong> (<em>int</em>) – number of input channels</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">prev_states=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encoder forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, D)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>prev_state</strong> (<em>torch.Tensor</em>) – batch of previous encoder hidden states (?, …)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of hidden state sequences (B, Tmax, eprojs)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.RNN">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.encoders.</code><code class="sig-name descname">RNN</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">elayers</em>, <em class="sig-param">cdim</em>, <em class="sig-param">hdim</em>, <em class="sig-param">dropout</em>, <em class="sig-param">typ='blstm'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#RNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RNN module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>elayers</strong> (<em>int</em>) – number of encoder layers</p></li>
<li><p><strong>cdim</strong> (<em>int</em>) – number of rnn units (resulted in cdim * 2 if bidirectional)</p></li>
<li><p><strong>hdim</strong> (<em>int</em>) – number of final projection units</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout rate</p></li>
<li><p><strong>typ</strong> (<em>str</em>) – The RNN type</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.RNN.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">prev_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#RNN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.RNN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>RNN forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, D)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>prev_state</strong> (<em>torch.Tensor</em>) – batch of previous RNN states</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of hidden state sequences (B, Tmax, eprojs)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.RNNP">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.encoders.</code><code class="sig-name descname">RNNP</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">elayers</em>, <em class="sig-param">cdim</em>, <em class="sig-param">hdim</em>, <em class="sig-param">subsample</em>, <em class="sig-param">dropout</em>, <em class="sig-param">typ='blstm'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#RNNP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.RNNP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RNN with projection layer module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – dimension of inputs</p></li>
<li><p><strong>elayers</strong> (<em>int</em>) – number of encoder layers</p></li>
<li><p><strong>cdim</strong> (<em>int</em>) – number of rnn units (resulted in cdim * 2 if bidirectional)</p></li>
<li><p><strong>hdim</strong> (<em>int</em>) – number of projection units</p></li>
<li><p><strong>subsample</strong> (<em>np.ndarray</em>) – list of subsampling numbers</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout rate</p></li>
<li><p><strong>typ</strong> (<em>str</em>) – The RNN type</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.RNNP.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">prev_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#RNNP.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.RNNP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>RNNP forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
<li><p><strong>prev_state</strong> (<em>torch.Tensor</em>) – batch of previous RNN states</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of hidden state sequences (B, Tmax, hdim)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.VGG2L">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.encoders.</code><code class="sig-name descname">VGG2L</code><span class="sig-paren">(</span><em class="sig-param">in_channel=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#VGG2L"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.VGG2L" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>VGG-like module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>in_channel</strong> (<em>int</em>) – number of input channels</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.VGG2L.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">ilens</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#VGG2L.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.VGG2L.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG2L forward</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, D)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>batch of padded hidden state sequences (B, Tmax // 4, 128 * D // 4)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.encoder_for">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.encoders.</code><code class="sig-name descname">encoder_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">idim</em>, <em class="sig-param">subsample</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#encoder_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.encoder_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an encoder module given the program arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>Namespace</em>) – The arguments</p></li>
<li><p><strong>or List of integer idim</strong> (<em>int</em>) – dimension of input, e.g. 83, or
List of dimensions of inputs, e.g. [83,83]</p></li>
<li><p><strong>or List of List subsample</strong> (<em>List</em>) – <p>subsample factors, e.g. [1,2,2,1,1], or
List of subsample factors of each encoder.</p>
<blockquote>
<div><p>e.g. [[1,2,2,1,1], [1,2,2,1,1]]</p>
</div></blockquote>
</p></li>
</ul>
</dd>
</dl>
<p>:rtype torch.nn.Module
:return: The encoder module</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.rnn.encoders.reset_backward_rnn_state">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.rnn.encoders.</code><code class="sig-name descname">reset_backward_rnn_state</code><span class="sig-paren">(</span><em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/rnn/encoders.html#reset_backward_rnn_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.rnn.encoders.reset_backward_rnn_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets backward BRNN states to zeroes</p>
<p>Useful in processing of sliding windows over the inputs</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-streaming-segment">
<span id="id118"></span><h2>espnet.nets.pytorch_backend.streaming.segment<a class="headerlink" href="#espnet-nets-pytorch-backend-streaming-segment" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.streaming.segment"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.streaming.segment.SegmentStreamingE2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.streaming.segment.</code><code class="sig-name descname">SegmentStreamingE2E</code><span class="sig-paren">(</span><em class="sig-param">e2e</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/streaming/segment.html#SegmentStreamingE2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.streaming.segment.SegmentStreamingE2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>SegmentStreamingE2E constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>e2e</strong> (<a class="reference internal" href="#espnet.nets.chainer_backend.e2e_asr.E2E" title="espnet.nets.chainer_backend.e2e_asr.E2E"><em>E2E</em></a>) – E2E ASR object</p></li>
<li><p><strong>recog_args</strong> – arguments for “recognize” method of E2E</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.streaming.segment.SegmentStreamingE2E.accept_input">
<code class="sig-name descname">accept_input</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/streaming/segment.html#SegmentStreamingE2E.accept_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.streaming.segment.SegmentStreamingE2E.accept_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this method each time a new batch of input is available.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-streaming-window">
<span id="id119"></span><h2>espnet.nets.pytorch_backend.streaming.window<a class="headerlink" href="#espnet-nets-pytorch-backend-streaming-window" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.streaming.window"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.streaming.window.WindowStreamingE2E">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.streaming.window.</code><code class="sig-name descname">WindowStreamingE2E</code><span class="sig-paren">(</span><em class="sig-param">e2e</em>, <em class="sig-param">recog_args</em>, <em class="sig-param">rnnlm=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/streaming/window.html#WindowStreamingE2E"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.streaming.window.WindowStreamingE2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>WindowStreamingE2E constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>e2e</strong> (<a class="reference internal" href="#espnet.nets.chainer_backend.e2e_asr.E2E" title="espnet.nets.chainer_backend.e2e_asr.E2E"><em>E2E</em></a>) – E2E ASR object</p></li>
<li><p><strong>recog_args</strong> – arguments for “recognize” method of E2E</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.streaming.window.WindowStreamingE2E.accept_input">
<code class="sig-name descname">accept_input</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/streaming/window.html#WindowStreamingE2E.accept_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.streaming.window.WindowStreamingE2E.accept_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this method each time a new batch of input is available.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.streaming.window.WindowStreamingE2E.decode_with_attention_offline">
<code class="sig-name descname">decode_with_attention_offline</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/streaming/window.html#WindowStreamingE2E.decode_with_attention_offline"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.streaming.window.WindowStreamingE2E.decode_with_attention_offline" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the attention decoder offline.</p>
<p>Works even if the previous layers (encoder and CTC decoder) were
being run in the online mode.
This method should be run after all the audio has been consumed.
This is used mostly to compare the results between offline
and online implementation of the previous layers.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-streaming-init">
<span id="id120"></span><h2>espnet.nets.pytorch_backend.streaming.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-streaming-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.streaming.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-frontends-dnn-beamformer">
<span id="id121"></span><h2>espnet.nets.pytorch_backend.frontends.dnn_beamformer<a class="headerlink" href="#espnet-nets-pytorch-backend-frontends-dnn-beamformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.frontends.dnn_beamformer"></span><p>DNN beamformer module.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.frontends.dnn_beamformer.AttentionReference">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.dnn_beamformer.</code><code class="sig-name descname">AttentionReference</code><span class="sig-paren">(</span><em class="sig-param">bidim</em>, <em class="sig-param">att_dim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/dnn_beamformer.html#AttentionReference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.dnn_beamformer.AttentionReference" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.dnn_beamformer.AttentionReference.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">psd_in: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em>, <em class="sig-param">scaling: float = 2.0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.LongTensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/dnn_beamformer.html#AttentionReference.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.dnn_beamformer.AttentionReference.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The forward function</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>psd_in</strong> (<em>ComplexTensor</em>) – (B, F, C, C)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – (B,)</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, C)
ilens (torch.Tensor): (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>u (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.frontends.dnn_beamformer.DNN_Beamformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.dnn_beamformer.</code><code class="sig-name descname">DNN_Beamformer</code><span class="sig-paren">(</span><em class="sig-param">bidim</em>, <em class="sig-param">btype='blstmp'</em>, <em class="sig-param">blayers=3</em>, <em class="sig-param">bunits=300</em>, <em class="sig-param">bprojs=320</em>, <em class="sig-param">bnmask=2</em>, <em class="sig-param">dropout_rate=0.0</em>, <em class="sig-param">badim=320</em>, <em class="sig-param">ref_channel: int = -1</em>, <em class="sig-param">beamformer_type='mvdr'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/dnn_beamformer.html#DNN_Beamformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.dnn_beamformer.DNN_Beamformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>DNN mask based Beamformer</p>
<dl class="simple">
<dt>Citation:</dt><dd><p>Multichannel End-to-end Speech Recognition; T. Ochiai et al., 2017;
<a class="reference external" href="https://arxiv.org/abs/1703.04783">https://arxiv.org/abs/1703.04783</a></p>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.dnn_beamformer.DNN_Beamformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">data: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch_complex.tensor.ComplexTensor, torch.LongTensor, torch_complex.tensor.ComplexTensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/dnn_beamformer.html#DNN_Beamformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.dnn_beamformer.DNN_Beamformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The forward function</p>
<dl class="simple">
<dt>Notation:</dt><dd><p>B: Batch
C: Channel
T: Time or Sequence length
F: Freq</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>ComplexTensor</em>) – (B, T, C, F)</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, T, F)
ilens (torch.Tensor): (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>enhanced (ComplexTensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-frontends-dnn-wpe">
<span id="id122"></span><h2>espnet.nets.pytorch_backend.frontends.dnn_wpe<a class="headerlink" href="#espnet-nets-pytorch-backend-frontends-dnn-wpe" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.frontends.dnn_wpe"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.frontends.dnn_wpe.DNN_WPE">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.dnn_wpe.</code><code class="sig-name descname">DNN_WPE</code><span class="sig-paren">(</span><em class="sig-param">wtype: str = 'blstmp'</em>, <em class="sig-param">widim: int = 257</em>, <em class="sig-param">wlayers: int = 3</em>, <em class="sig-param">wunits: int = 300</em>, <em class="sig-param">wprojs: int = 320</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">taps: int = 5</em>, <em class="sig-param">delay: int = 3</em>, <em class="sig-param">use_dnn_mask: bool = True</em>, <em class="sig-param">iterations: int = 1</em>, <em class="sig-param">normalization: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/dnn_wpe.html#DNN_WPE"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.dnn_wpe.DNN_WPE" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.dnn_wpe.DNN_WPE.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">data: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch_complex.tensor.ComplexTensor, torch.LongTensor, torch_complex.tensor.ComplexTensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/dnn_wpe.html#DNN_WPE.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.dnn_wpe.DNN_WPE.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The forward function</p>
<dl class="simple">
<dt>Notation:</dt><dd><p>B: Batch
C: Channel
T: Time or Sequence length
F: Freq or Some dimension of the feature vector</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – (B, C, T, F)</p></li>
<li><p><strong>ilens</strong> – (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(B, C, T, F)
ilens: (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>data</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-frontends-feature-transform">
<span id="id123"></span><h2>espnet.nets.pytorch_backend.frontends.feature_transform<a class="headerlink" href="#espnet-nets-pytorch-backend-frontends-feature-transform" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.frontends.feature_transform"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.FeatureTransform">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.feature_transform.</code><code class="sig-name descname">FeatureTransform</code><span class="sig-paren">(</span><em class="sig-param">fs: int = 16000</em>, <em class="sig-param">n_fft: int = 512</em>, <em class="sig-param">n_mels: int = 80</em>, <em class="sig-param">fmin: float = 0.0</em>, <em class="sig-param">fmax: float = None</em>, <em class="sig-param">stats_file: str = None</em>, <em class="sig-param">apply_uttmvn: bool = True</em>, <em class="sig-param">uttmvn_norm_means: bool = True</em>, <em class="sig-param">uttmvn_norm_vars: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#FeatureTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.FeatureTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.FeatureTransform.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch_complex.tensor.ComplexTensor, ilens: Union[torch.LongTensor, numpy.ndarray, List[int]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.LongTensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#FeatureTransform.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.FeatureTransform.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.GlobalMVN">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.feature_transform.</code><code class="sig-name descname">GlobalMVN</code><span class="sig-paren">(</span><em class="sig-param">stats_file: str</em>, <em class="sig-param">norm_means: bool = True</em>, <em class="sig-param">norm_vars: bool = True</em>, <em class="sig-param">eps: float = 1e-20</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#GlobalMVN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.GlobalMVN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Apply global mean and variance normalization</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stats_file</strong> (<em>str</em>) – npy file of 1-dim array or text file.
From the _first element to
the {(len(array) - 1) / 2}th element are treated as
the sum of features,
and the rest excluding the last elements are
treated as the sum of the square value of features,
and the last elements eqauls to the number of samples.</p></li>
<li><p><strong>std_floor</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.GlobalMVN.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#GlobalMVN.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.GlobalMVN.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.GlobalMVN.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.LongTensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#GlobalMVN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.GlobalMVN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.LogMel">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.feature_transform.</code><code class="sig-name descname">LogMel</code><span class="sig-paren">(</span><em class="sig-param">fs: int = 16000</em>, <em class="sig-param">n_fft: int = 512</em>, <em class="sig-param">n_mels: int = 80</em>, <em class="sig-param">fmin: float = 0.0</em>, <em class="sig-param">fmax: float = None</em>, <em class="sig-param">htk: bool = False</em>, <em class="sig-param">norm=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#LogMel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.LogMel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convert STFT to fbank feats</p>
<p>The arguments is same as librosa.filters.mel</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fs</strong> – number &gt; 0 [scalar] sampling rate of the incoming signal</p></li>
<li><p><strong>n_fft</strong> – int &gt; 0 [scalar] number of FFT components</p></li>
<li><p><strong>n_mels</strong> – int &gt; 0 [scalar] number of Mel bands to generate</p></li>
<li><p><strong>fmin</strong> – float &gt;= 0 [scalar] lowest frequency (in Hz)</p></li>
<li><p><strong>fmax</strong> – float &gt;= 0 [scalar] highest frequency (in Hz).
If <cite>None</cite>, use <cite>fmax = fs / 2.0</cite></p></li>
<li><p><strong>htk</strong> – use HTK formula instead of Slaney</p></li>
<li><p><strong>norm</strong> – {None, 1, np.inf} [scalar]
if 1, divide the triangular mel weights by the width of the mel band
(area normalization).  Otherwise, leave all the triangles aiming for
a peak value of 1.0</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.LogMel.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#LogMel.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.LogMel.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.LogMel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">feat: torch.Tensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.LongTensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#LogMel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.LogMel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.UtteranceMVN">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.feature_transform.</code><code class="sig-name descname">UtteranceMVN</code><span class="sig-paren">(</span><em class="sig-param">norm_means: bool = True</em>, <em class="sig-param">norm_vars: bool = False</em>, <em class="sig-param">eps: float = 1e-20</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#UtteranceMVN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.UtteranceMVN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.UtteranceMVN.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#UtteranceMVN.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.UtteranceMVN.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.UtteranceMVN.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.LongTensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#UtteranceMVN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.UtteranceMVN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.feature_transform_for">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.feature_transform.</code><code class="sig-name descname">feature_transform_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">n_fft</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#feature_transform_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.feature_transform_for" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.frontends.feature_transform.utterance_mvn">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.feature_transform.</code><code class="sig-name descname">utterance_mvn</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">ilens: torch.LongTensor</em>, <em class="sig-param">norm_means: bool = True</em>, <em class="sig-param">norm_vars: bool = False</em>, <em class="sig-param">eps: float = 1e-20</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.LongTensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/feature_transform.html#utterance_mvn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.feature_transform.utterance_mvn" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply utterance mean and variance normalization</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – (B, T, D), assumed zero padded</p></li>
<li><p><strong>ilens</strong> – (B, T, D)</p></li>
<li><p><strong>norm_means</strong> – </p></li>
<li><p><strong>norm_vars</strong> – </p></li>
<li><p><strong>eps</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-frontends-init">
<span id="id124"></span><h2>espnet.nets.pytorch_backend.frontends.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-frontends-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.frontends.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-frontends-beamformer">
<span id="id125"></span><h2>espnet.nets.pytorch_backend.frontends.beamformer<a class="headerlink" href="#espnet-nets-pytorch-backend-frontends-beamformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.frontends.beamformer"></span><dl class="function">
<dt id="espnet.nets.pytorch_backend.frontends.beamformer.apply_beamforming_vector">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.beamformer.</code><code class="sig-name descname">apply_beamforming_vector</code><span class="sig-paren">(</span><em class="sig-param">beamform_vector: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">mix: torch_complex.tensor.ComplexTensor</em><span class="sig-paren">)</span> &#x2192; torch_complex.tensor.ComplexTensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/beamformer.html#apply_beamforming_vector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.beamformer.apply_beamforming_vector" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.frontends.beamformer.get_mvdr_vector">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.beamformer.</code><code class="sig-name descname">get_mvdr_vector</code><span class="sig-paren">(</span><em class="sig-param">psd_s: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">psd_n: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">reference_vector: torch.Tensor</em>, <em class="sig-param">eps: float = 1e-15</em><span class="sig-paren">)</span> &#x2192; torch_complex.tensor.ComplexTensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/beamformer.html#get_mvdr_vector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.beamformer.get_mvdr_vector" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the MVDR(Minimum Variance Distortionless Response) vector:</p>
<blockquote>
<div><p>h = (Npsd^-1 &#64; Spsd) / (Tr(Npsd^-1 &#64; Spsd)) &#64; u</p>
</div></blockquote>
<dl class="simple">
<dt>Reference:</dt><dd><p>On optimal frequency-domain multichannel linear filtering
for noise reduction; M. Souden et al., 2010;
<a class="reference external" href="https://ieeexplore.ieee.org/document/5089420">https://ieeexplore.ieee.org/document/5089420</a></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>psd_s</strong> (<em>ComplexTensor</em>) – (…, F, C, C)</p></li>
<li><p><strong>psd_n</strong> (<em>ComplexTensor</em>) – (…, F, C, C)</p></li>
<li><p><strong>reference_vector</strong> (<em>torch.Tensor</em>) – (…, C)</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(…, F, C)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>beamform_vector (ComplexTensor)r</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.frontends.beamformer.get_power_spectral_density_matrix">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.beamformer.</code><code class="sig-name descname">get_power_spectral_density_matrix</code><span class="sig-paren">(</span><em class="sig-param">xs: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">normalization=True</em>, <em class="sig-param">eps: float = 1e-15</em><span class="sig-paren">)</span> &#x2192; torch_complex.tensor.ComplexTensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/beamformer.html#get_power_spectral_density_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.beamformer.get_power_spectral_density_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Return cross-channel power spectral density (PSD) matrix</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>ComplexTensor</em>) – (…, F, C, T)</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – (…, F, C, T)</p></li>
<li><p><strong>normalization</strong> (<em>bool</em>) – </p></li>
<li><p><strong>eps</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Returns</dt><dd><p>psd (ComplexTensor): (…, F, C, C)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-frontends-frontend">
<span id="id126"></span><h2>espnet.nets.pytorch_backend.frontends.frontend<a class="headerlink" href="#espnet-nets-pytorch-backend-frontends-frontend" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.frontends.frontend"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.frontends.frontend.Frontend">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.frontend.</code><code class="sig-name descname">Frontend</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">use_wpe: bool = False</em>, <em class="sig-param">wtype: str = 'blstmp'</em>, <em class="sig-param">wlayers: int = 3</em>, <em class="sig-param">wunits: int = 300</em>, <em class="sig-param">wprojs: int = 320</em>, <em class="sig-param">wdropout_rate: float = 0.0</em>, <em class="sig-param">taps: int = 5</em>, <em class="sig-param">delay: int = 3</em>, <em class="sig-param">use_dnn_mask_for_wpe: bool = True</em>, <em class="sig-param">use_beamformer: bool = False</em>, <em class="sig-param">btype: str = 'blstmp'</em>, <em class="sig-param">blayers: int = 3</em>, <em class="sig-param">bunits: int = 300</em>, <em class="sig-param">bprojs: int = 320</em>, <em class="sig-param">bnmask: int = 2</em>, <em class="sig-param">badim: int = 320</em>, <em class="sig-param">ref_channel: int = -1</em>, <em class="sig-param">bdropout_rate=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/frontend.html#Frontend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.frontend.Frontend" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.frontend.Frontend.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch_complex.tensor.ComplexTensor, ilens: Union[torch.LongTensor, numpy.ndarray, List[int]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch_complex.tensor.ComplexTensor, torch.LongTensor, Optional[torch_complex.tensor.ComplexTensor]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/frontend.html#Frontend.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.frontend.Frontend.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.frontends.frontend.frontend_for">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.frontend.</code><code class="sig-name descname">frontend_for</code><span class="sig-paren">(</span><em class="sig-param">args</em>, <em class="sig-param">idim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/frontend.html#frontend_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.frontend.frontend_for" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-frontends-mask-estimator">
<span id="id127"></span><h2>espnet.nets.pytorch_backend.frontends.mask_estimator<a class="headerlink" href="#espnet-nets-pytorch-backend-frontends-mask-estimator" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.frontends.mask_estimator"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.frontends.mask_estimator.MaskEstimator">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.frontends.mask_estimator.</code><code class="sig-name descname">MaskEstimator</code><span class="sig-paren">(</span><em class="sig-param">type</em>, <em class="sig-param">idim</em>, <em class="sig-param">layers</em>, <em class="sig-param">units</em>, <em class="sig-param">projs</em>, <em class="sig-param">dropout</em>, <em class="sig-param">nmask=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/mask_estimator.html#MaskEstimator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.mask_estimator.MaskEstimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.frontends.mask_estimator.MaskEstimator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs: torch_complex.tensor.ComplexTensor</em>, <em class="sig-param">ilens: torch.LongTensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Tuple[torch.Tensor, ...], torch.LongTensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/frontends/mask_estimator.html#MaskEstimator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.frontends.mask_estimator.MaskEstimator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The forward function</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> – (B, F, C, T)</p></li>
<li><p><strong>ilens</strong> – (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The hidden vector (B, F, C, T)
masks: A tuple of the masks. (B, F, C, T)
ilens: (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>hs (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-tacotron2-decoder">
<span id="id128"></span><h2>espnet.nets.pytorch_backend.tacotron2.decoder<a class="headerlink" href="#espnet-nets-pytorch-backend-tacotron2-decoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.tacotron2.decoder"></span><p>Tacotron2 decoder related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.Decoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.decoder.</code><code class="sig-name descname">Decoder</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">att</em>, <em class="sig-param">dlayers=2</em>, <em class="sig-param">dunits=1024</em>, <em class="sig-param">prenet_layers=2</em>, <em class="sig-param">prenet_units=256</em>, <em class="sig-param">postnet_layers=5</em>, <em class="sig-param">postnet_chans=512</em>, <em class="sig-param">postnet_filts=5</em>, <em class="sig-param">output_activation_fn=None</em>, <em class="sig-param">cumulate_att_w=True</em>, <em class="sig-param">use_batch_norm=True</em>, <em class="sig-param">use_concate=True</em>, <em class="sig-param">dropout_rate=0.5</em>, <em class="sig-param">zoneout_rate=0.1</em>, <em class="sig-param">reduction_factor=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#Decoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Decoder module of Spectrogram prediction network.</p>
<p>This is a module of decoder of Spectrogram prediction network in Tacotron2,
which described in <a class="reference external" href="https://arxiv.org/abs/1712.05884">Natural TTS
Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a>.
The decoder generates the sequence of
features from the sequence of the hidden states.</p>
<p>Initialize Tacotron2 decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>att</strong> (<em>torch.nn.Module</em>) – Instance of attention class.</p></li>
<li><p><strong>dlayers</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of decoder lstm layers.</p></li>
<li><p><strong>dunits</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of decoder lstm units.</p></li>
<li><p><strong>prenet_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of prenet layers.</p></li>
<li><p><strong>prenet_units</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of prenet units.</p></li>
<li><p><strong>postnet_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of postnet layers.</p></li>
<li><p><strong>postnet_filts</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of postnet filter size.</p></li>
<li><p><strong>postnet_chans</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of postnet filter channels.</p></li>
<li><p><strong>output_activation_fn</strong> (<em>torch.nn.Module</em><em>, </em><em>optional</em>) – Activation function for outputs.</p></li>
<li><p><strong>cumulate_att_w</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to cumulate previous attention weight.</p></li>
<li><p><strong>use_batch_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use batch normalization.</p></li>
<li><p><strong>use_concate</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to concatenate encoder embedding
with decoder lstm outputs.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Dropout rate.</p></li>
<li><p><strong>zoneout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Zoneout rate.</p></li>
<li><p><strong>reduction_factor</strong> (<em>int</em><em>, </em><em>optional</em>) – Reduction factor.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.Decoder.calculate_all_attentions">
<code class="sig-name descname">calculate_all_attentions</code><span class="sig-paren">(</span><em class="sig-param">hs</em>, <em class="sig-param">hlens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#Decoder.calculate_all_attentions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.Decoder.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all of the attention weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs</strong> (<em>Tensor</em>) – Batch of the sequences of padded hidden states (B, Tmax, idim).</p></li>
<li><p><strong>hlens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of the sequences of padded target features (B, Lmax, odim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of attention weights (B, Lmax, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This computation is performed in teacher-forcing manner.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.Decoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs</em>, <em class="sig-param">hlens</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#Decoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.Decoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs</strong> (<em>Tensor</em>) – Batch of the sequences of padded hidden states (B, Tmax, idim).</p></li>
<li><p><strong>hlens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of the sequences of padded target features (B, Lmax, odim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of output tensors after postnet (B, Lmax, odim).
Tensor: Batch of output tensors before postnet (B, Lmax, odim).
Tensor: Batch of logits of stop prediction (B, Lmax).
Tensor: Batch of attention weights (B, Lmax, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This computation is performed in teacher-forcing manner.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.Decoder.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">h</em>, <em class="sig-param">threshold=0.5</em>, <em class="sig-param">minlenratio=0.0</em>, <em class="sig-param">maxlenratio=10.0</em>, <em class="sig-param">use_att_constraint=False</em>, <em class="sig-param">backward_window=None</em>, <em class="sig-param">forward_window=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#Decoder.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.Decoder.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate the sequence of features given the sequences of characters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h</strong> (<em>Tensor</em>) – Input sequence of encoder hidden states (T, C).</p></li>
<li><p><strong>threshold</strong> (<em>float</em><em>, </em><em>optional</em>) – Threshold to stop generation.</p></li>
<li><p><strong>minlenratio</strong> (<em>float</em><em>, </em><em>optional</em>) – Minimum length ratio.
If set to 1.0 and the length of input is 10,
the minimum length of outputs will be 10 * 1 = 10.</p></li>
<li><p><strong>minlenratio</strong> – Minimum length ratio.
If set to 10 and the length of input is 10,
the maximum length of outputs will be 10 * 10 = 100.</p></li>
<li><p><strong>use_att_constraint</strong> (<em>bool</em>) – Whether to apply attention constraint introduced in <a class="reference external" href="https://arxiv.org/abs/1710.07654">Deep Voice 3</a>.</p></li>
<li><p><strong>backward_window</strong> (<em>int</em>) – Backward window size in attention constraint.</p></li>
<li><p><strong>forward_window</strong> (<em>int</em>) – Forward window size in attention constraint.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output sequence of features (L, odim).
Tensor: Output sequence of stop probabilities (L,).
Tensor: Attention weights (L, T).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This computation is performed in auto-regressive manner.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.Postnet">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.decoder.</code><code class="sig-name descname">Postnet</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">n_layers=5</em>, <em class="sig-param">n_chans=512</em>, <em class="sig-param">n_filts=5</em>, <em class="sig-param">dropout_rate=0.5</em>, <em class="sig-param">use_batch_norm=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#Postnet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.Postnet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Postnet module for Spectrogram prediction network.</p>
<p>This is a module of Postnet in Spectrogram prediction network,
which described in <a class="reference external" href="https://arxiv.org/abs/1712.05884">Natural TTS Synthesis by
Conditioning WaveNet on Mel Spectrogram Predictions</a>.
The Postnet predicts refines the predicted
Mel-filterbank of the decoder,
which helps to compensate the detail structure of spectrogram.</p>
<p>Initialize postnet module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>n_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of layers.</p></li>
<li><p><strong>n_filts</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of filter size.</p></li>
<li><p><strong>n_units</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of filter channels.</p></li>
<li><p><strong>use_batch_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use batch normalization..</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Dropout rate..</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.Postnet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#Postnet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.Postnet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>xs</strong> (<em>Tensor</em>) – Batch of the sequences of padded input tensors (B, idim, Tmax).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of padded output tensor. (B, odim, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.Prenet">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.decoder.</code><code class="sig-name descname">Prenet</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">n_layers=2</em>, <em class="sig-param">n_units=256</em>, <em class="sig-param">dropout_rate=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#Prenet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.Prenet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Prenet module for decoder of Spectrogram prediction network.</p>
<p>This is a module of Prenet in the decoder of Spectrogram prediction network,
which described in <a class="reference external" href="https://arxiv.org/abs/1712.05884">Natural TTS
Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a>.
The Prenet preforms nonlinear conversion
of inputs before input to auto-regressive lstm,
which helps to learn diagonal attentions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This module alway applies dropout even in evaluation.
See the detail in <a class="reference external" href="https://arxiv.org/abs/1712.05884">Natural TTS Synthesis by
Conditioning WaveNet on Mel Spectrogram Predictions</a>.</p>
</div>
<p>Initialize prenet module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>n_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of prenet layers.</p></li>
<li><p><strong>n_units</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of prenet units.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.Prenet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#Prenet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.Prenet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Batch of input tensors (B, …, idim).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of output tensors (B, …, odim).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.ZoneOutCell">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.decoder.</code><code class="sig-name descname">ZoneOutCell</code><span class="sig-paren">(</span><em class="sig-param">cell</em>, <em class="sig-param">zoneout_rate=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#ZoneOutCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.ZoneOutCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ZoneOut Cell module.</p>
<p>This is a module of zoneout described in
<a class="reference external" href="https://arxiv.org/abs/1606.01305">Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations</a>.
This code is modified from <a class="reference external" href="https://github.com/eladhoffer/seq2seq.pytorch">eladhoffer/seq2seq.pytorch</a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lstm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lstm</span> <span class="o">=</span> <span class="n">ZoneOutCell</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize zone out cell module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cell</strong> (<em>torch.nn.Module</em>) – Pytorch recurrent cell module
e.g. <cite>torch.nn.Module.LSTMCell</cite>.</p></li>
<li><p><strong>zoneout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Probability of zoneout from 0.0 to 1.0.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.ZoneOutCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">hidden</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#ZoneOutCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.ZoneOutCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Tensor</em>) – Batch of input tensor (B, input_size).</p></li>
<li><p><strong>hidden</strong> (<em>tuple</em>) – <ul>
<li><p>Tensor: Batch of initial hidden states (B, hidden_size).</p></li>
<li><p>Tensor: Batch of initial cell states (B, hidden_size).</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>Tensor: Batch of next hidden states (B, hidden_size).</p></li>
<li><p>Tensor: Batch of next cell states (B, hidden_size).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.tacotron2.decoder.decoder_init">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.decoder.</code><code class="sig-name descname">decoder_init</code><span class="sig-paren">(</span><em class="sig-param">m</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/decoder.html#decoder_init"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.decoder.decoder_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder parameters.</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-tacotron2-encoder">
<span id="id132"></span><h2>espnet.nets.pytorch_backend.tacotron2.encoder<a class="headerlink" href="#espnet-nets-pytorch-backend-tacotron2-encoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.tacotron2.encoder"></span><p>Tacotron2 encoder related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.tacotron2.encoder.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.encoder.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">input_layer='embed'</em>, <em class="sig-param">embed_dim=512</em>, <em class="sig-param">elayers=1</em>, <em class="sig-param">eunits=512</em>, <em class="sig-param">econv_layers=3</em>, <em class="sig-param">econv_chans=512</em>, <em class="sig-param">econv_filts=5</em>, <em class="sig-param">use_batch_norm=True</em>, <em class="sig-param">use_residual=False</em>, <em class="sig-param">dropout_rate=0.5</em>, <em class="sig-param">padding_idx=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/encoder.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.encoder.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encoder module of Spectrogram prediction network.</p>
<p>This is a module of encoder of Spectrogram prediction network in Tacotron2,
which described in <a class="reference external" href="https://arxiv.org/abs/1712.05884">Natural TTS Synthesis by Conditioning WaveNet on Mel
Spectrogram Predictions</a>. This is the encoder which converts either a sequence
of characters or acoustic features into the sequence of hidden states.</p>
<p>Initialize Tacotron2 encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – </p></li>
<li><p><strong>input_layer</strong> (<em>str</em>) – Input layer type.</p></li>
<li><p><strong>embed_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – </p></li>
<li><p><strong>elayers</strong> (<em>int</em><em>, </em><em>optional</em>) – </p></li>
<li><p><strong>eunits</strong> (<em>int</em><em>, </em><em>optional</em>) – </p></li>
<li><p><strong>econv_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – </p></li>
<li><p><strong>econv_filts</strong> (<em>int</em><em>, </em><em>optional</em>) – </p></li>
<li><p><strong>econv_chans</strong> (<em>int</em><em>, </em><em>optional</em>) – </p></li>
<li><p><strong>use_batch_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – </p></li>
<li><p><strong>use_residual</strong> (<em>bool</em><em>, </em><em>optional</em>) – </p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.encoder.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/encoder.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.encoder.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of the padded sequence. Either character ids (B, Tmax)
or acoustic feature (B, Tmax, idim * encoder_reduction_factor). Padded
value should be 0.</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input batch (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of the sequences of encoder states(B, Tmax, eunits).
LongTensor: Batch of lengths of each sequence (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.encoder.Encoder.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/encoder.html#Encoder.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.encoder.Encoder.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – The sequeunce of character ids (T,)
or acoustic feature (T, idim * encoder_reduction_factor).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The sequences of encoder states(T, eunits).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.tacotron2.encoder.encoder_init">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.encoder.</code><code class="sig-name descname">encoder_init</code><span class="sig-paren">(</span><em class="sig-param">m</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/encoder.html#encoder_init"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.encoder.encoder_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize encoder parameters.</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-tacotron2-cbhg">
<span id="id134"></span><h2>espnet.nets.pytorch_backend.tacotron2.cbhg<a class="headerlink" href="#espnet-nets-pytorch-backend-tacotron2-cbhg" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.tacotron2.cbhg"></span><p>CBHG related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.tacotron2.cbhg.CBHG">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.cbhg.</code><code class="sig-name descname">CBHG</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">odim</em>, <em class="sig-param">conv_bank_layers=8</em>, <em class="sig-param">conv_bank_chans=128</em>, <em class="sig-param">conv_proj_filts=3</em>, <em class="sig-param">conv_proj_chans=256</em>, <em class="sig-param">highway_layers=4</em>, <em class="sig-param">highway_units=128</em>, <em class="sig-param">gru_units=256</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/cbhg.html#CBHG"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.cbhg.CBHG" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>CBHG module to convert log Mel-filterbanks to linear spectrogram.</p>
<p>This is a module of CBHG introduced
in <a class="reference external" href="https://arxiv.org/abs/1703.10135">Tacotron: Towards End-to-End Speech Synthesis</a>.
The CBHG converts the sequence of log Mel-filterbanks into linear spectrogram.</p>
<p>Initialize CBHG module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p></li>
<li><p><strong>odim</strong> (<em>int</em>) – Dimension of the outputs.</p></li>
<li><p><strong>conv_bank_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of convolution bank layers.</p></li>
<li><p><strong>conv_bank_chans</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of channels in convolution bank.</p></li>
<li><p><strong>conv_proj_filts</strong> (<em>int</em><em>, </em><em>optional</em>) – Kernel size of convolutional projection layer.</p></li>
<li><p><strong>conv_proj_chans</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of channels in convolutional projection layer.</p></li>
<li><p><strong>highway_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of highway network layers.</p></li>
<li><p><strong>highway_units</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of highway network units.</p></li>
<li><p><strong>gru_units</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of GRU units (for both directions).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.cbhg.CBHG.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/cbhg.html#CBHG.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.cbhg.CBHG.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of the padded sequences of inputs (B, Tmax, idim).</p></li>
<li><p><strong>ilens</strong> (<em>LongTensor</em>) – Batch of lengths of each input sequence (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of the padded sequence of outputs (B, Tmax, odim).
LongTensor: Batch of lengths of each output sequence (B,).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.cbhg.CBHG.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/cbhg.html#CBHG.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.cbhg.CBHG.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – The sequences of inputs (T, idim).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The sequence of outputs (T, odim).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.tacotron2.cbhg.CBHGLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.cbhg.</code><code class="sig-name descname">CBHGLoss</code><span class="sig-paren">(</span><em class="sig-param">use_masking=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/cbhg.html#CBHGLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.cbhg.CBHGLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Loss function module for CBHG.</p>
<p>Initialize CBHG loss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_masking</strong> (<em>bool</em>) – Whether to mask padded part in loss calculation.</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.cbhg.CBHGLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">cbhg_outs</em>, <em class="sig-param">spcs</em>, <em class="sig-param">olens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/cbhg.html#CBHGLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.cbhg.CBHGLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cbhg_outs</strong> (<em>Tensor</em>) – Batch of CBHG outputs (B, Lmax, spc_dim).</p></li>
<li><p><strong>spcs</strong> (<em>Tensor</em>) – Batch of groundtruth of spectrogram (B, Lmax, spc_dim).</p></li>
<li><p><strong>olens</strong> (<em>LongTensor</em>) – Batch of the lengths of each sequence (B,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>L1 loss value
Tensor: Mean square error loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.tacotron2.cbhg.HighwayNet">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.tacotron2.cbhg.</code><code class="sig-name descname">HighwayNet</code><span class="sig-paren">(</span><em class="sig-param">idim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/cbhg.html#HighwayNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.cbhg.HighwayNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Highway Network module.</p>
<p>This is a module of Highway Network introduced in <a class="reference external" href="https://arxiv.org/abs/1505.00387">Highway Networks</a>.</p>
<p>Initialize Highway Network module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idim</strong> (<em>int</em>) – Dimension of the inputs.</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.tacotron2.cbhg.HighwayNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/tacotron2/cbhg.html#HighwayNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.tacotron2.cbhg.HighwayNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Batch of inputs (B, …, idim).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of outputs, which are the same shape as inputs (B, …, idim).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-tacotron2-init">
<span id="id135"></span><h2>espnet.nets.pytorch_backend.tacotron2.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-tacotron2-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.tacotron2.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-fastspeech-duration-predictor">
<span id="id136"></span><h2>espnet.nets.pytorch_backend.fastspeech.duration_predictor<a class="headerlink" href="#espnet-nets-pytorch-backend-fastspeech-duration-predictor" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.fastspeech.duration_predictor"></span><p>Duration predictor related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.fastspeech.duration_predictor.</code><code class="sig-name descname">DurationPredictor</code><span class="sig-paren">(</span><em class="sig-param">idim</em>, <em class="sig-param">n_layers=2</em>, <em class="sig-param">n_chans=384</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">dropout_rate=0.1</em>, <em class="sig-param">offset=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/fastspeech/duration_predictor.html#DurationPredictor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Duration predictor module.</p>
<p>This is a module of duration predictor described
in <a class="reference external" href="https://arxiv.org/pdf/1905.09263.pdf">FastSpeech: Fast, Robust and Controllable Text to Speech</a>.
The duration predictor predicts a duration of each frame in log domain
from the hidden embeddings of encoder.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The calculation domain of outputs is different
between in <cite>forward</cite> and in <cite>inference</cite>. In <cite>forward</cite>,
the outputs are calculated in log domain but in <cite>inference</cite>,
those are calculated in linear domain.</p>
</div>
<p>Initilize duration predictor module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>n_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of convolutional layers.</p></li>
<li><p><strong>n_chans</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of channels of convolutional layers.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Kernel size of convolutional layers.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – Dropout rate.</p></li>
<li><p><strong>offset</strong> (<em>float</em><em>, </em><em>optional</em>) – Offset value to avoid nan in log domain.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">x_masks=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/fastspeech/duration_predictor.html#DurationPredictor.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of input sequences (B, Tmax, idim).</p></li>
<li><p><strong>x_masks</strong> (<em>ByteTensor</em><em>, </em><em>optional</em>) – Batch of masks indicating padded part (B, Tmax).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of predicted durations in log domain (B, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">x_masks=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/fastspeech/duration_predictor.html#DurationPredictor.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictor.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Inference duration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of input sequences (B, Tmax, idim).</p></li>
<li><p><strong>x_masks</strong> (<em>ByteTensor</em><em>, </em><em>optional</em>) – Batch of masks indicating padded part (B, Tmax).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of predicted durations in linear domain (B, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>LongTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictorLoss">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.fastspeech.duration_predictor.</code><code class="sig-name descname">DurationPredictorLoss</code><span class="sig-paren">(</span><em class="sig-param">offset=1.0</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/fastspeech/duration_predictor.html#DurationPredictorLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictorLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Loss function module for duration predictor.</p>
<p>The loss value is Calculated in log domain to make it Gaussian.</p>
<p>Initilize duration predictor loss module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>offset</strong> (<em>float</em><em>, </em><em>optional</em>) – Offset value to avoid nan in log domain.</p></li>
<li><p><strong>reduction</strong> (<em>str</em>) – Reduction type in loss calculation.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictorLoss.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">outputs</em>, <em class="sig-param">targets</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/fastspeech/duration_predictor.html#DurationPredictorLoss.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.fastspeech.duration_predictor.DurationPredictorLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<em>Tensor</em>) – Batch of prediction durations in log domain (B, T)</p></li>
<li><p><strong>targets</strong> (<em>LongTensor</em>) – Batch of groundtruth durations in linear domain (B, T)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mean squared error loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>outputs</cite> is in log domain but <cite>targets</cite> is in linear domain.</p>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-fastspeech-duration-calculator">
<span id="id138"></span><h2>espnet.nets.pytorch_backend.fastspeech.duration_calculator<a class="headerlink" href="#espnet-nets-pytorch-backend-fastspeech-duration-calculator" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.fastspeech.duration_calculator"></span><p>Duration calculator related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.fastspeech.duration_calculator.DurationCalculator">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.fastspeech.duration_calculator.</code><code class="sig-name descname">DurationCalculator</code><span class="sig-paren">(</span><em class="sig-param">teacher_model</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/fastspeech/duration_calculator.html#DurationCalculator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.fastspeech.duration_calculator.DurationCalculator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Duration calculator module for FastSpeech.</p>
<p>Initialize duration calculator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>teacher_model</strong> (<a class="reference internal" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer" title="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer"><em>e2e_tts_transformer.Transformer</em></a>) – Pretrained auto-regressive Transformer.</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.fastspeech.duration_calculator.DurationCalculator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ilens</em>, <em class="sig-param">ys</em>, <em class="sig-param">olens</em>, <em class="sig-param">spembs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/fastspeech/duration_calculator.html#DurationCalculator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.fastspeech.duration_calculator.DurationCalculator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of the padded sequences of character ids (B, Tmax).</p></li>
<li><p><strong>ilens</strong> (<em>Tensor</em>) – Batch of lengths of each input sequence (B,).</p></li>
<li><p><strong>ys</strong> (<em>Tensor</em>) – Batch of the padded sequence of target features (B, Lmax, odim).</p></li>
<li><p><strong>olens</strong> (<em>Tensor</em>) – Batch of lengths of each output sequence (B,).</p></li>
<li><p><strong>spembs</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Batch of speaker embedding vectors (B, spk_embed_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Batch of durations (B, Tmax).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-fastspeech-length-regulator">
<span id="id140"></span><h2>espnet.nets.pytorch_backend.fastspeech.length_regulator<a class="headerlink" href="#espnet-nets-pytorch-backend-fastspeech-length-regulator" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.fastspeech.length_regulator"></span><p>Length regulator related modules.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.fastspeech.length_regulator.LengthRegulator">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.fastspeech.length_regulator.</code><code class="sig-name descname">LengthRegulator</code><span class="sig-paren">(</span><em class="sig-param">pad_value=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/fastspeech/length_regulator.html#LengthRegulator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.fastspeech.length_regulator.LengthRegulator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Length regulator module for feed-forward Transformer.</p>
<p>This is a module of length regulator described in
<a class="reference external" href="https://arxiv.org/pdf/1905.09263.pdf">FastSpeech: Fast, Robust and Controllable Text to Speech</a>.
The length regulator expands char or
phoneme-level embedding features to frame-level by repeating each
feature based on the corresponding predicted durations.</p>
<p>Initilize length regulator module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>pad_value</strong> (<em>float</em><em>, </em><em>optional</em>) – Value used for padding.</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.fastspeech.length_regulator.LengthRegulator.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em>, <em class="sig-param">ds</em>, <em class="sig-param">alpha=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/fastspeech/length_regulator.html#LengthRegulator.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.fastspeech.length_regulator.LengthRegulator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>Tensor</em>) – Batch of sequences of char or phoneme embeddings (B, Tmax, D).</p></li>
<li><p><strong>ds</strong> (<em>LongTensor</em>) – Batch of durations of each frame (B, T).</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) – Alpha value to control speed of speech.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>replicated input tensor based on durations (B, T*, D).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-fastspeech-init">
<span id="id142"></span><h2>espnet.nets.pytorch_backend.fastspeech.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-fastspeech-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.fastspeech.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-transducer-joint-network">
<span id="id143"></span><h2>espnet.nets.pytorch_backend.transducer.joint_network<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-joint-network" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.joint_network"></span><p>Transducer joint network implementation.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.joint_network.JointNetwork">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.joint_network.</code><code class="sig-name descname">JointNetwork</code><span class="sig-paren">(</span><em class="sig-param">joint_output_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">decoder_output_size: int</em>, <em class="sig-param">joint_space_size: int</em>, <em class="sig-param">joint_activation_type: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/joint_network.html#JointNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.joint_network.JointNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transducer joint network module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>joint_output_size</strong> – Joint network output dimension</p></li>
<li><p><strong>encoder_output_size</strong> – Encoder output dimension.</p></li>
<li><p><strong>decoder_output_size</strong> – Decoder output dimension.</p></li>
<li><p><strong>joint_space_size</strong> – Dimension of joint space.</p></li>
<li><p><strong>joint_activation_type</strong> – Type of activation for joint network.</p></li>
</ul>
</dd>
</dl>
<p>Joint network initializer.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.joint_network.JointNetwork.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em>, <em class="sig-param">dec_out: torch.Tensor</em>, <em class="sig-param">is_aux: bool = False</em>, <em class="sig-param">quantization: bool = False</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/joint_network.html#JointNetwork.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.joint_network.JointNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Joint computation of encoder and decoder hidden state sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_out</strong> – Expanded encoder output state sequences (B, T, 1, D_enc)</p></li>
<li><p><strong>dec_out</strong> – Expanded decoder output state sequences (B, 1, U, D_dec)</p></li>
<li><p><strong>is_aux</strong> – Whether auxiliary tasks in used.</p></li>
<li><p><strong>quantization</strong> – Whether dynamic quantization is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Joint output state sequences. (B, T, U, D_out)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>joint_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-transformer-decoder-layer">
<span id="id144"></span><h2>espnet.nets.pytorch_backend.transducer.transformer_decoder_layer<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-transformer-decoder-layer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.transformer_decoder_layer"></span><p>Transformer decoder layer definition for custom Transducer model.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.</code><code class="sig-name descname">TransformerDecoderLayer</code><span class="sig-paren">(</span><em class="sig-param">hdim: int</em>, <em class="sig-param">self_attention: espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention</em>, <em class="sig-param">feed_forward: espnet.nets.pytorch_backend.transformer.positionwise_feed_forward.PositionwiseFeedForward</em>, <em class="sig-param">dropout_rate: float</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transformer_decoder_layer.html#TransformerDecoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transformer decoder layer module for custom Transducer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hdim</strong> – Hidden dimension.</p></li>
<li><p><strong>self_attention</strong> – Self-attention module.</p></li>
<li><p><strong>feed_forward</strong> – Feed forward module.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct an DecoderLayer object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">sequence: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">cache: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transformer_decoder_layer.html#TransformerDecoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute previous decoder output sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence</strong> – Transformer input sequences. (B, U, D_dec)</p></li>
<li><p><strong>mask</strong> – Transformer intput mask sequences. (B, U)</p></li>
<li><p><strong>cache</strong> – Cached decoder output sequences. (B, (U - 1), D_dec)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Transformer output sequences. (B, U, D_dec)
mask: Transformer output mask sequences. (B, U)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sequence</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-custom-encoder">
<span id="id145"></span><h2>espnet.nets.pytorch_backend.transducer.custom_encoder<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-custom-encoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.custom_encoder"></span><p>Cutom encoder definition for transducer models.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.custom_encoder.CustomEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.custom_encoder.</code><code class="sig-name descname">CustomEncoder</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">enc_arch: List</em>, <em class="sig-param">input_layer: str = 'linear'</em>, <em class="sig-param">repeat_block: int = 1</em>, <em class="sig-param">self_attn_type: str = 'selfattn'</em>, <em class="sig-param">positional_encoding_type: str = 'abs_pos'</em>, <em class="sig-param">positionwise_layer_type: str = 'linear'</em>, <em class="sig-param">positionwise_activation_type: str = 'relu'</em>, <em class="sig-param">conv_mod_activation_type: str = 'relu'</em>, <em class="sig-param">aux_enc_output_layers: List = []</em>, <em class="sig-param">input_layer_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer_pos_enc_dropout_rate: float = 0.0</em>, <em class="sig-param">padding_idx: int = -1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_encoder.html#CustomEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_encoder.CustomEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Custom encoder module for transducer models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> – Input dimension.</p></li>
<li><p><strong>enc_arch</strong> – Encoder block architecture (type and parameters).</p></li>
<li><p><strong>input_layer</strong> – Input layer type.</p></li>
<li><p><strong>repeat_block</strong> – Number of times blocks_arch is repeated.</p></li>
<li><p><strong>self_attn_type</strong> – Self-attention type.</p></li>
<li><p><strong>positional_encoding_type</strong> – Positional encoding type.</p></li>
<li><p><strong>positionwise_layer_type</strong> – Positionwise layer type.</p></li>
<li><p><strong>positionwise_activation_type</strong> – Positionwise activation type.</p></li>
<li><p><strong>conv_mod_activation_type</strong> – Convolutional module activation type.</p></li>
<li><p><strong>aux_enc_output_layers</strong> – Layer IDs for auxiliary encoder output sequences.</p></li>
<li><p><strong>input_layer_dropout_rate</strong> – Dropout rate for input layer.</p></li>
<li><p><strong>input_layer_pos_enc_dropout_rate</strong> – Dropout rate for input layer pos. enc.</p></li>
<li><p><strong>padding_idx</strong> – Padding symbol ID for embedding layer.</p></li>
</ul>
</dd>
</dl>
<p>Construct an CustomEncoder object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.custom_encoder.CustomEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_encoder.html#CustomEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_encoder.CustomEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode feature sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats</strong> – Feature sequences. (B, F, D_feats)</p></li>
<li><p><strong>feats_mask</strong> – Feature mask sequences. (B, 1, F)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Encoder output sequences. (B, T, D_enc) with/without</dt><dd><p>Auxiliary encoder output sequences. (B, T, D_enc_aux)</p>
</dd>
<dt>enc_out_mask: Mask for encoder output sequences. (B, 1, T) with/without</dt><dd><p>Mask for auxiliary encoder output sequences. (B, T, D_enc_aux)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>enc_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-error-calculator">
<span id="id146"></span><h2>espnet.nets.pytorch_backend.transducer.error_calculator<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-error-calculator" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.error_calculator"></span><p>CER/WER computation for Transducer model.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.error_calculator.ErrorCalculator">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.error_calculator.</code><code class="sig-name descname">ErrorCalculator</code><span class="sig-paren">(</span><em class="sig-param">decoder: Union[espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder, espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder], joint_network: espnet.nets.pytorch_backend.transducer.joint_network.JointNetwork, token_list: List[int], sym_space: str, sym_blank: str, report_cer: bool = False, report_wer: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/error_calculator.html#ErrorCalculator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.error_calculator.ErrorCalculator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>CER and WER computation for Transducer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint network module.</p></li>
<li><p><strong>token_list</strong> – Set of unique labels.</p></li>
<li><p><strong>sym_space</strong> – Space symbol.</p></li>
<li><p><strong>sym_blank</strong> – Blank symbol.</p></li>
<li><p><strong>report_cer</strong> – Whether to compute CER.</p></li>
<li><p><strong>report_wer</strong> – Whether to compute WER.</p></li>
</ul>
</dd>
</dl>
<p>Construct an ErrorCalculator object for Transducer model.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.error_calculator.ErrorCalculator.calculate_cer">
<code class="sig-name descname">calculate_cer</code><span class="sig-paren">(</span><em class="sig-param">hyps: torch.Tensor</em>, <em class="sig-param">refs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/error_calculator.html#ErrorCalculator.calculate_cer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.error_calculator.ErrorCalculator.calculate_cer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level CER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses sequences. (B, L)</p></li>
<li><p><strong>refs</strong> – References sequences. (B, L)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Average sentence-level CER score.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.error_calculator.ErrorCalculator.calculate_wer">
<code class="sig-name descname">calculate_wer</code><span class="sig-paren">(</span><em class="sig-param">hyps: torch.Tensor</em>, <em class="sig-param">refs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/error_calculator.html#ErrorCalculator.calculate_wer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.error_calculator.ErrorCalculator.calculate_wer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level WER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses sequences. (B, L)</p></li>
<li><p><strong>refs</strong> – References sequences. (B, L)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Average sentence-level WER score.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.error_calculator.ErrorCalculator.convert_to_char">
<code class="sig-name descname">convert_to_char</code><span class="sig-paren">(</span><em class="sig-param">hyps: torch.Tensor</em>, <em class="sig-param">refs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[List, List]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/error_calculator.html#ErrorCalculator.convert_to_char"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.error_calculator.ErrorCalculator.convert_to_char" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert label ID sequences to character.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses sequences. (B, L)</p></li>
<li><p><strong>refs</strong> – References sequences. (B, L)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Character list of hypotheses.
char_hyps: Character list of references.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>char_hyps</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-init">
<span id="id147"></span><h2>espnet.nets.pytorch_backend.transducer.__init__<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-init" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet-nets-pytorch-backend-transducer-transducer-tasks">
<span id="id148"></span><h2>espnet.nets.pytorch_backend.transducer.transducer_tasks<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-transducer-tasks" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.transducer_tasks"></span><p>Module implementing Transducer main and auxiliary tasks.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.transducer_tasks.</code><code class="sig-name descname">TransducerTasks</code><span class="sig-paren">(</span><em class="sig-param">encoder_dim: int</em>, <em class="sig-param">decoder_dim: int</em>, <em class="sig-param">joint_dim: int</em>, <em class="sig-param">output_dim: int</em>, <em class="sig-param">joint_activation_type: str = 'tanh'</em>, <em class="sig-param">transducer_loss_weight: float = 1.0</em>, <em class="sig-param">ctc_loss: bool = False</em>, <em class="sig-param">ctc_loss_weight: float = 0.5</em>, <em class="sig-param">ctc_loss_dropout_rate: float = 0.0</em>, <em class="sig-param">lm_loss: bool = False</em>, <em class="sig-param">lm_loss_weight: float = 0.5</em>, <em class="sig-param">lm_loss_smoothing_rate: float = 0.0</em>, <em class="sig-param">aux_transducer_loss: bool = False</em>, <em class="sig-param">aux_transducer_loss_weight: float = 0.2</em>, <em class="sig-param">aux_transducer_loss_mlp_dim: int = 320</em>, <em class="sig-param">aux_trans_loss_mlp_dropout_rate: float = 0.0</em>, <em class="sig-param">symm_kl_div_loss: bool = False</em>, <em class="sig-param">symm_kl_div_loss_weight: float = 0.2</em>, <em class="sig-param">fastemit_lambda: float = 0.0</em>, <em class="sig-param">blank_id: int = 0</em>, <em class="sig-param">ignore_id: int = -1</em>, <em class="sig-param">training: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transducer_tasks.html#TransducerTasks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transducer tasks module.</p>
<p>Initialize module for Transducer tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_dim</strong> – Encoder outputs dimension.</p></li>
<li><p><strong>decoder_dim</strong> – Decoder outputs dimension.</p></li>
<li><p><strong>joint_dim</strong> – Joint space dimension.</p></li>
<li><p><strong>output_dim</strong> – Output dimension.</p></li>
<li><p><strong>joint_activation_type</strong> – Type of activation for joint network.</p></li>
<li><p><strong>transducer_loss_weight</strong> – Weight for main transducer loss.</p></li>
<li><p><strong>ctc_loss</strong> – Compute CTC loss.</p></li>
<li><p><strong>ctc_loss_weight</strong> – Weight of CTC loss.</p></li>
<li><p><strong>ctc_loss_dropout_rate</strong> – Dropout rate for CTC loss inputs.</p></li>
<li><p><strong>lm_loss</strong> – Compute LM loss.</p></li>
<li><p><strong>lm_loss_weight</strong> – Weight of LM loss.</p></li>
<li><p><strong>lm_loss_smoothing_rate</strong> – Smoothing rate for LM loss’ label smoothing.</p></li>
<li><p><strong>aux_transducer_loss</strong> – Compute auxiliary transducer loss.</p></li>
<li><p><strong>aux_transducer_loss_weight</strong> – Weight of auxiliary transducer loss.</p></li>
<li><p><strong>aux_transducer_loss_mlp_dim</strong> – Hidden dimension for aux. transducer MLP.</p></li>
<li><p><strong>aux_trans_loss_mlp_dropout_rate</strong> – Dropout rate for aux. transducer MLP.</p></li>
<li><p><strong>symm_kl_div_loss</strong> – Compute KL divergence loss.</p></li>
<li><p><strong>symm_kl_div_loss_weight</strong> – Weight of KL divergence loss.</p></li>
<li><p><strong>fastemit_lambda</strong> – Regularization parameter for FastEmit.</p></li>
<li><p><strong>blank_id</strong> – Blank symbol ID.</p></li>
<li><p><strong>ignore_id</strong> – Padding symbol ID.</p></li>
<li><p><strong>training</strong> – Whether the model was initializated in training or inference mode.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.compute_aux_transducer_and_symm_kl_div_losses">
<code class="sig-name descname">compute_aux_transducer_and_symm_kl_div_losses</code><span class="sig-paren">(</span><em class="sig-param">aux_enc_out: torch.Tensor</em>, <em class="sig-param">dec_out: torch.Tensor</em>, <em class="sig-param">joint_out: torch.Tensor</em>, <em class="sig-param">target: torch.Tensor</em>, <em class="sig-param">aux_t_len: torch.Tensor</em>, <em class="sig-param">u_len: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transducer_tasks.html#TransducerTasks.compute_aux_transducer_and_symm_kl_div_losses"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.compute_aux_transducer_and_symm_kl_div_losses" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute auxiliary Transducer loss and Jensen-Shannon divergence loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>aux_enc_out</strong> – Encoder auxiliary output sequences. [N x (B, T_aux, D_enc_aux)]</p></li>
<li><p><strong>dec_out</strong> – Decoder output sequences. (B, U, D_dec)</p></li>
<li><p><strong>joint_out</strong> – Joint output sequences. (B, T, U, D_joint)</p></li>
<li><p><strong>target</strong> – Target character ID sequences. (B, L)</p></li>
<li><p><strong>aux_t_len</strong> – Auxiliary time lengths. [N x (B,)]</p></li>
<li><p><strong>u_len</strong> – True U lengths. (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Auxiliary Transducer loss and KL divergence loss values.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.compute_ctc_loss">
<code class="sig-name descname">compute_ctc_loss</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em>, <em class="sig-param">target: torch.Tensor</em>, <em class="sig-param">t_len: torch.Tensor</em>, <em class="sig-param">u_len: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transducer_tasks.html#TransducerTasks.compute_ctc_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.compute_ctc_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute CTC loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_out</strong> – Encoder output sequences. (B, T, D_enc)</p></li>
<li><p><strong>target</strong> – Target character ID sequences. (B, U)</p></li>
<li><p><strong>t_len</strong> – Time lengths. (B,)</p></li>
<li><p><strong>u_len</strong> – Label lengths. (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>CTC loss value.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.compute_lm_loss">
<code class="sig-name descname">compute_lm_loss</code><span class="sig-paren">(</span><em class="sig-param">dec_out: torch.Tensor</em>, <em class="sig-param">target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transducer_tasks.html#TransducerTasks.compute_lm_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.compute_lm_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward LM loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dec_out</strong> – Decoder output sequences. (B, U, D_dec)</p></li>
<li><p><strong>target</strong> – Target label ID sequences. (B, U)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>LM loss value.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.compute_transducer_loss">
<code class="sig-name descname">compute_transducer_loss</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em>, <em class="sig-param">dec_out: None._VariableFunctionsClass.tensor</em>, <em class="sig-param">target: torch.Tensor</em>, <em class="sig-param">t_len: torch.Tensor</em>, <em class="sig-param">u_len: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transducer_tasks.html#TransducerTasks.compute_transducer_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.compute_transducer_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Transducer loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_out</strong> – Encoder output sequences. (B, T, D_enc)</p></li>
<li><p><strong>dec_out</strong> – Decoder output sequences. (B, U, D_dec)</p></li>
<li><p><strong>target</strong> – Target label ID sequences. (B, L)</p></li>
<li><p><strong>t_len</strong> – Time lengths. (B,)</p></li>
<li><p><strong>u_len</strong> – Label lengths. (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Joint output sequences. (B, T, U, D_joint),
Transducer loss value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(joint_out, loss_trans)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor, aux_enc_out: List[torch.Tensor], dec_out: torch.Tensor, labels: torch.Tensor, enc_out_len: torch.Tensor, aux_enc_out_len: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Tuple[Any], float, float]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transducer_tasks.html#TransducerTasks.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward main and auxiliary task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_out</strong> – Encoder output sequences. (B, T, D_enc)</p></li>
<li><p><strong>aux_enc_out</strong> – Encoder intermediate output sequences. (B, T_aux, D_enc_aux)</p></li>
<li><p><strong>dec_out</strong> – Decoder output sequences. (B, U, D_dec)</p></li>
<li><p><strong>target</strong> – Target label ID sequences. (B, L)</p></li>
<li><p><strong>t_len</strong> – Time lengths. (B,)</p></li>
<li><p><strong>aux_t_len</strong> – Auxiliary time lengths. (B,)</p></li>
<li><p><strong>u_len</strong> – Label lengths. (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Weighted losses.</dt><dd><p>(transducer loss, ctc loss, aux Transducer loss, KL div loss, LM loss)</p>
</dd>
</dl>
<p>cer: Sentence-level CER score.
wer: Sentence-level WER score.</p>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.get_target">
<code class="sig-name descname">get_target</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transducer_tasks.html#TransducerTasks.get_target"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.get_target" title="Permalink to this definition">¶</a></dt>
<dd><p>Set target label ID sequences.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Target label ID sequences. (B, L)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>target</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.get_transducer_tasks_io">
<code class="sig-name descname">get_transducer_tasks_io</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor, enc_out_len: torch.Tensor, aux_enc_out_len: Optional[List]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transducer_tasks.html#TransducerTasks.get_transducer_tasks_io"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.get_transducer_tasks_io" title="Permalink to this definition">¶</a></dt>
<dd><p>Get Transducer tasks inputs and outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – Label ID sequences. (B, U)</p></li>
<li><p><strong>enc_out_len</strong> – Time lengths. (B,)</p></li>
<li><p><strong>aux_enc_out_len</strong> – Auxiliary time lengths. [N X (B,)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Target label ID sequences. (B, L)
lm_loss_target: LM loss target label ID sequences. (B, U)
t_len: Time lengths. (B,)
aux_t_len: Auxiliary time lengths. [N x (B,)]
u_len: Label lengths. (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>target</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.set_target">
<code class="sig-name descname">set_target</code><span class="sig-paren">(</span><em class="sig-param">target: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/transducer_tasks.html#TransducerTasks.set_target"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.transducer_tasks.TransducerTasks.set_target" title="Permalink to this definition">¶</a></dt>
<dd><p>Set target label ID sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> – Target label ID sequences. (B, L)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-rnn-decoder">
<span id="id149"></span><h2>espnet.nets.pytorch_backend.transducer.rnn_decoder<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-rnn-decoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.rnn_decoder"></span><p>RNN decoder definition for Transducer model.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.rnn_decoder.</code><code class="sig-name descname">RNNDecoder</code><span class="sig-paren">(</span><em class="sig-param">odim: int</em>, <em class="sig-param">dtype: str</em>, <em class="sig-param">dlayers: int</em>, <em class="sig-param">dunits: int</em>, <em class="sig-param">embed_dim: int</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">dropout_rate_embed: float = 0.0</em>, <em class="sig-param">blank_id: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_decoder.html#RNNDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.transducer_decoder_interface.TransducerDecoderInterface" title="espnet.nets.transducer_decoder_interface.TransducerDecoderInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.transducer_decoder_interface.TransducerDecoderInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RNN decoder module for Transducer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> – Output dimension.</p></li>
<li><p><strong>dtype</strong> – Decoder units type.</p></li>
<li><p><strong>dlayers</strong> – Number of decoder layers.</p></li>
<li><p><strong>dunits</strong> – Number of decoder units per layer..</p></li>
<li><p><strong>embed_dim</strong> – Embedding layer dimension.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate for decoder layers.</p></li>
<li><p><strong>dropout_rate_embed</strong> – Dropout rate for embedding layer.</p></li>
<li><p><strong>blank_id</strong> – Blank symbol ID.</p></li>
</ul>
</dd>
</dl>
<p>Transducer initializer.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: Union[List[espnet.nets.transducer_decoder_interface.Hypothesis], List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]], dec_states: Tuple[torch.Tensor, Optional[torch.Tensor]], cache: Dict[str, Any], use_lm: bool</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_decoder.html#RNNDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses.</p></li>
<li><p><strong>states</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p></li>
<li><p><strong>cache</strong> – Pairs of (dec_out, dec_states) for each label sequences. (keys)</p></li>
<li><p><strong>use_lm</strong> – Whether to compute label ID sequences for LM.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences. (B, D_dec)
dec_states: Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))
lm_labels: Label ID sequences for LM. (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.create_batch_states">
<code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">states: Tuple[torch.Tensor, Optional[torch.Tensor]], new_states: List[Tuple[torch.Tensor, Optional[torch.Tensor]]], check_list: Optional[List] = None</em><span class="sig-paren">)</span> &#x2192; List[Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_decoder.html#RNNDecoder.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p></li>
<li><p><strong>new_states</strong> – Decoder hidden states. [N x ((1, D_dec), (1, D_dec))]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>states</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_decoder.html#RNNDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>labels</strong> – Label ID sequences. (B, L)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences. (B, T, U, D_dec)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[None._VariableFunctionsClass.tensor]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_decoder.html#RNNDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Initial decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.rnn_forward">
<code class="sig-name descname">rnn_forward</code><span class="sig-paren">(</span><em class="sig-param">sequence: torch.Tensor, state: Tuple[torch.Tensor, Optional[torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_decoder.html#RNNDecoder.rnn_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.rnn_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence</strong> – RNN input sequences. (B, D_emb)</p></li>
<li><p><strong>state</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>RNN output sequences. (B, D_dec)
(h_next, c_next): Decoder hidden states. (N, B, D_dec), (N, B, D_dec))</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sequence</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">hyp: espnet.nets.transducer_decoder_interface.Hypothesis, cache: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]], torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_decoder.html#RNNDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyp</strong> – Hypothesis.</p></li>
<li><p><strong>cache</strong> – Pairs of (dec_out, state) for each label sequence. (key)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequence. (1, D_dec)
new_state: Decoder hidden states. ((N, 1, D_dec), (N, 1, D_dec))
label: Label ID for LM. (1,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: Tuple[torch.Tensor, Optional[torch.Tensor]], idx: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_decoder.html#RNNDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Decoder hidden state for given ID.</dt><dd><p>((N, 1, D_dec), (N, 1, D_dec))</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.set_device">
<code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.device</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_decoder.html#RNNDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_decoder.RNNDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-arguments">
<span id="id150"></span><h2>espnet.nets.pytorch_backend.transducer.arguments<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-arguments" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.arguments"></span><p>Transducer model arguments.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.arguments.add_auxiliary_task_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.arguments.</code><code class="sig-name descname">add_auxiliary_task_arguments</code><span class="sig-paren">(</span><em class="sig-param">group: argparse._ArgumentGroup</em><span class="sig-paren">)</span> &#x2192; argparse._ArgumentGroup<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/arguments.html#add_auxiliary_task_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.arguments.add_auxiliary_task_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Add arguments for auxiliary task.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.arguments.add_custom_decoder_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.arguments.</code><code class="sig-name descname">add_custom_decoder_arguments</code><span class="sig-paren">(</span><em class="sig-param">group: argparse._ArgumentGroup</em><span class="sig-paren">)</span> &#x2192; argparse._ArgumentGroup<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/arguments.html#add_custom_decoder_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.arguments.add_custom_decoder_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Define arguments for Custom decoder.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.arguments.add_custom_encoder_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.arguments.</code><code class="sig-name descname">add_custom_encoder_arguments</code><span class="sig-paren">(</span><em class="sig-param">group: argparse._ArgumentGroup</em><span class="sig-paren">)</span> &#x2192; argparse._ArgumentGroup<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/arguments.html#add_custom_encoder_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.arguments.add_custom_encoder_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Define arguments for Custom encoder.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.arguments.add_custom_training_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.arguments.</code><code class="sig-name descname">add_custom_training_arguments</code><span class="sig-paren">(</span><em class="sig-param">group: argparse._ArgumentGroup</em><span class="sig-paren">)</span> &#x2192; argparse._ArgumentGroup<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/arguments.html#add_custom_training_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.arguments.add_custom_training_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Define arguments for training with Custom architecture.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.arguments.add_decoder_general_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.arguments.</code><code class="sig-name descname">add_decoder_general_arguments</code><span class="sig-paren">(</span><em class="sig-param">group: argparse._ArgumentGroup</em><span class="sig-paren">)</span> &#x2192; argparse._ArgumentGroup<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/arguments.html#add_decoder_general_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.arguments.add_decoder_general_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Define general arguments for encoder.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.arguments.add_encoder_general_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.arguments.</code><code class="sig-name descname">add_encoder_general_arguments</code><span class="sig-paren">(</span><em class="sig-param">group: argparse._ArgumentGroup</em><span class="sig-paren">)</span> &#x2192; argparse._ArgumentGroup<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/arguments.html#add_encoder_general_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.arguments.add_encoder_general_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Define general arguments for encoder.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.arguments.add_rnn_decoder_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.arguments.</code><code class="sig-name descname">add_rnn_decoder_arguments</code><span class="sig-paren">(</span><em class="sig-param">group: argparse._ArgumentGroup</em><span class="sig-paren">)</span> &#x2192; argparse._ArgumentGroup<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/arguments.html#add_rnn_decoder_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.arguments.add_rnn_decoder_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Define arguments for RNN decoder.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.arguments.add_rnn_encoder_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.arguments.</code><code class="sig-name descname">add_rnn_encoder_arguments</code><span class="sig-paren">(</span><em class="sig-param">group: argparse._ArgumentGroup</em><span class="sig-paren">)</span> &#x2192; argparse._ArgumentGroup<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/arguments.html#add_rnn_encoder_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.arguments.add_rnn_encoder_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Define arguments for RNN encoder.</p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.arguments.add_transducer_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.arguments.</code><code class="sig-name descname">add_transducer_arguments</code><span class="sig-paren">(</span><em class="sig-param">group: argparse._ArgumentGroup</em><span class="sig-paren">)</span> &#x2192; argparse._ArgumentGroup<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/arguments.html#add_transducer_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.arguments.add_transducer_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Define general arguments for Transducer model.</p>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-initializer">
<span id="id151"></span><h2>espnet.nets.pytorch_backend.transducer.initializer<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-initializer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.initializer"></span><p>Parameter initialization for Transducer model.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.initializer.initializer">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.initializer.</code><code class="sig-name descname">initializer</code><span class="sig-paren">(</span><em class="sig-param">model: torch.nn.modules.module.Module</em>, <em class="sig-param">args: argparse.Namespace</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/initializer.html#initializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.initializer.initializer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize Transducer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Transducer model.</p></li>
<li><p><strong>args</strong> – Namespace containing model options.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-utils">
<span id="id152"></span><h2>espnet.nets.pytorch_backend.transducer.utils<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-utils" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.utils"></span><p>Utility functions for Transducer models.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.check_batch_states">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">check_batch_states</code><span class="sig-paren">(</span><em class="sig-param">states</em>, <em class="sig-param">max_len</em>, <em class="sig-param">pad_id</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#check_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.check_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Check decoder hidden states and left pad or trim if necessary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state</strong> – Decoder hidden states. [N x (B, ?, D_dec)]</p></li>
<li><p><strong>max_len</strong> – maximum sequence length.</p></li>
<li><p><strong>pad_id</strong> – Padding symbol ID.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder hidden states. [N x (B, max_len, dec_dim)]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>final</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.check_state">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">check_state</code><span class="sig-paren">(</span><em class="sig-param">state: List[Optional[torch.Tensor]], max_len: int, pad_id: int</em><span class="sig-paren">)</span> &#x2192; List[Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#check_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.check_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Check decoder hidden states and left pad or trim if necessary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state</strong> – Decoder hidden states. [N x (?, D_dec)]</p></li>
<li><p><strong>max_len</strong> – maximum sequence length.</p></li>
<li><p><strong>pad_id</strong> – Padding symbol ID.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder hidden states. [N x (1, max_len, D_dec)]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>final</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.create_lm_batch_states">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">create_lm_batch_states</code><span class="sig-paren">(</span><em class="sig-param">lm_states: Union[List[Any], Dict[str, Any]], lm_layers, is_wordlm: bool</em><span class="sig-paren">)</span> &#x2192; Union[List[Any], Dict[str, Any]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#create_lm_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.create_lm_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create LM hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lm_states</strong> – LM hidden states.</p></li>
<li><p><strong>lm_layers</strong> – Number of LM layers.</p></li>
<li><p><strong>is_wordlm</strong> – Whether provided LM is a word-level LM.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>LM hidden states.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>new_states</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.custom_torch_load">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">custom_torch_load</code><span class="sig-paren">(</span><em class="sig-param">model_path: str</em>, <em class="sig-param">model: torch.nn.modules.module.Module</em>, <em class="sig-param">training: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#custom_torch_load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.custom_torch_load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load Transducer model with training-only modules and parameters removed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong> – Model path.</p></li>
<li><p><strong>model</strong> – Transducer model.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.get_decoder_input">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">get_decoder_input</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">blank_id: int</em>, <em class="sig-param">ignore_id: int</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#get_decoder_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.get_decoder_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare decoder input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>labels</strong> – Label ID sequences. (B, L)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Label ID sequences with blank prefix. (B, U)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>decoder_input</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.init_lm_state">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">init_lm_state</code><span class="sig-paren">(</span><em class="sig-param">lm_model: torch.nn.modules.module.Module</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#init_lm_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.init_lm_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize LM hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>lm_model</strong> – LM module.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Initial LM hidden states.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>lm_state</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.is_prefix">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">is_prefix</code><span class="sig-paren">(</span><em class="sig-param">x: List[int], pref: List[int]</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#is_prefix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.is_prefix" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if pref is a prefix of x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Label ID sequence.</p></li>
<li><p><strong>pref</strong> – Prefix label ID sequence.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Whether pref is a prefix of x.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.pad_sequence">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">pad_sequence</code><span class="sig-paren">(</span><em class="sig-param">labels: List[int], pad_id: int</em><span class="sig-paren">)</span> &#x2192; List[int]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#pad_sequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.pad_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>Left pad label ID sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – Label ID sequence.</p></li>
<li><p><strong>pad_id</strong> – Padding symbol ID.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Padded label ID sequences.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>final</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.recombine_hyps">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">recombine_hyps</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet.nets.transducer_decoder_interface.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.Hypothesis]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#recombine_hyps"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.recombine_hyps" title="Permalink to this definition">¶</a></dt>
<dd><p>Recombine hypotheses with same label ID sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Recombined hypotheses.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>final</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.select_k_expansions">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">select_k_expansions</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis], logps: torch.Tensor, beam_size: int, gamma: float, beta: float</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#select_k_expansions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.select_k_expansions" title="Permalink to this definition">¶</a></dt>
<dd><p>Return K hypotheses candidates for expansion from a list of hypothesis.</p>
<p>K candidates are selected according to the extended hypotheses probabilities
and a prune-by-value method. Where K is equal to beam_size + beta.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses.</p></li>
<li><p><strong>beam_logp</strong> – Log-probabilities for hypotheses expansions.</p></li>
<li><p><strong>beam_size</strong> – Beam size.</p></li>
<li><p><strong>gamma</strong> – Allowed logp difference for prune-by-value method.</p></li>
<li><p><strong>beta</strong> – Number of additional candidates to store.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Best K expansion hypotheses candidates.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>k_expansions</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.select_lm_state">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">select_lm_state</code><span class="sig-paren">(</span><em class="sig-param">lm_states: Union[List[Any], Dict[str, Any]], idx: int, lm_layers: int, is_wordlm: bool</em><span class="sig-paren">)</span> &#x2192; Union[List[Any], Dict[str, Any]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#select_lm_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.select_lm_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get ID state from LM hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lm_states</strong> – LM hidden states.</p></li>
<li><p><strong>idx</strong> – LM state ID to extract.</p></li>
<li><p><strong>lm_layers</strong> – Number of LM layers.</p></li>
<li><p><strong>is_wordlm</strong> – Whether provided LM is a word-level LM.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>LM hidden state for given ID.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>idx_state</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.subtract">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">subtract</code><span class="sig-paren">(</span><em class="sig-param">x: List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis], subset: List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#subtract"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.subtract" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove elements of subset if corresponding label ID sequence already exist in x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Set of hypotheses.</p></li>
<li><p><strong>subset</strong> – Subset of x.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>New set of hypotheses.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>final</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.utils.valid_aux_encoder_output_layers">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.utils.</code><code class="sig-name descname">valid_aux_encoder_output_layers</code><span class="sig-paren">(</span><em class="sig-param">aux_layer_id: List[int], enc_num_layers: int, use_symm_kl_div_loss: bool, subsample: List[int]</em><span class="sig-paren">)</span> &#x2192; List[int]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/utils.html#valid_aux_encoder_output_layers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.utils.valid_aux_encoder_output_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Check whether provided auxiliary encoder layer IDs are valid.</p>
<p>Return the valid list sorted with duplicates removed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>aux_layer_id</strong> – Auxiliary encoder layer IDs.</p></li>
<li><p><strong>enc_num_layers</strong> – Number of encoder layers.</p></li>
<li><p><strong>use_symm_kl_div_loss</strong> – Whether symmetric KL divergence loss is used.</p></li>
<li><p><strong>subsample</strong> – Subsampling rate per layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Valid list of auxiliary encoder layers.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>valid</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-custom-decoder">
<span id="id153"></span><h2>espnet.nets.pytorch_backend.transducer.custom_decoder<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-custom-decoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.custom_decoder"></span><p>Custom decoder definition for Transducer model.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.custom_decoder.</code><code class="sig-name descname">CustomDecoder</code><span class="sig-paren">(</span><em class="sig-param">odim: int</em>, <em class="sig-param">dec_arch: List</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">repeat_block: int = 0</em>, <em class="sig-param">joint_activation_type: str = 'tanh'</em>, <em class="sig-param">positional_encoding_type: str = 'abs_pos'</em>, <em class="sig-param">positionwise_layer_type: str = 'linear'</em>, <em class="sig-param">positionwise_activation_type: str = 'relu'</em>, <em class="sig-param">input_layer_dropout_rate: float = 0.0</em>, <em class="sig-param">blank_id: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_decoder.html#CustomDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.transducer_decoder_interface.TransducerDecoderInterface" title="espnet.nets.transducer_decoder_interface.TransducerDecoderInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.transducer_decoder_interface.TransducerDecoderInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Custom decoder module for Transducer model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> – Output dimension.</p></li>
<li><p><strong>dec_arch</strong> – Decoder block architecture (type and parameters).</p></li>
<li><p><strong>input_layer</strong> – Input layer type.</p></li>
<li><p><strong>repeat_block</strong> – Number of times dec_arch is repeated.</p></li>
<li><p><strong>joint_activation_type</strong> – Type of activation for joint network.</p></li>
<li><p><strong>positional_encoding_type</strong> – Positional encoding type.</p></li>
<li><p><strong>positionwise_layer_type</strong> – Positionwise layer type.</p></li>
<li><p><strong>positionwise_activation_type</strong> – Positionwise activation type.</p></li>
<li><p><strong>input_layer_dropout_rate</strong> – Dropout rate for input layer.</p></li>
<li><p><strong>blank_id</strong> – Blank symbol ID.</p></li>
</ul>
</dd>
</dl>
<p>Construct a CustomDecoder object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: Union[List[espnet.nets.transducer_decoder_interface.Hypothesis], List[espnet.nets.transducer_decoder_interface.ExtendedHypothesis]], dec_states: List[Optional[torch.Tensor]], cache: Dict[str, Any], use_lm: bool</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Optional[torch.Tensor]], torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_decoder.html#CustomDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses.</p></li>
<li><p><strong>dec_states</strong> – Decoder hidden states. [N x (B, U, D_dec)]</p></li>
<li><p><strong>cache</strong> – Pairs of (h_dec, dec_states) for each label sequences. (keys)</p></li>
<li><p><strong>use_lm</strong> – Whether to compute label ID sequences for LM.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences. (B, D_dec)
dec_states: Decoder hidden states. [N x (B, U, D_dec)]
lm_labels: Label ID sequences for LM. (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.create_batch_states">
<code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">states: List[Optional[torch.Tensor]], new_states: List[Optional[torch.Tensor]], check_list: List[List[int]]</em><span class="sig-paren">)</span> &#x2192; List[Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_decoder.html#CustomDecoder.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create decoder hidden states sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. [N x (B, U, D_dec)]</p></li>
<li><p><strong>new_states</strong> – Decoder hidden states. [B x [N x (1, U, D_dec)]]</p></li>
<li><p><strong>check_list</strong> – Label ID sequences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>New decoder hidden states. [N x (B, U, D_dec)]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>states</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">dec_input: torch.Tensor</em>, <em class="sig-param">dec_mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_decoder.html#CustomDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode label ID sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dec_input</strong> – Label ID sequences. (B, U)</p></li>
<li><p><strong>dec_mask</strong> – Label mask sequences.  (B, U)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequences. (B, U, D_dec)
dec_output_mask: Mask of decoder output sequences. (B, U)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_output</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: Optional[int] = None</em><span class="sig-paren">)</span> &#x2192; List[Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_decoder.html#CustomDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Initial decoder hidden states. [N x None]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>state</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">hyp: espnet.nets.transducer_decoder_interface.Hypothesis, cache: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Optional[torch.Tensor]], torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_decoder.html#CustomDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyp</strong> – Hypothesis.</p></li>
<li><p><strong>cache</strong> – Pairs of (dec_out, dec_state) for each label sequence. (key)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder output sequence. (1, D_dec)
dec_state: Decoder hidden states. [N x (1, U, D_dec)]
lm_label: Label ID for LM. (1,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: List[Optional[torch.Tensor]], idx: int</em><span class="sig-paren">)</span> &#x2192; List[Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_decoder.html#CustomDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. [N x (B, U, D_dec)]</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Decoder hidden state for given ID. [N x (1, U, D_dec)]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>state_idx</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.set_device">
<code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.device</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/custom_decoder.html#CustomDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.custom_decoder.CustomDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-conv1d-nets">
<span id="id154"></span><h2>espnet.nets.pytorch_backend.transducer.conv1d_nets<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-conv1d-nets" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.conv1d_nets"></span><p>Convolution networks definition for custom archictecture.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.conv1d_nets.CausalConv1d">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.conv1d_nets.</code><code class="sig-name descname">CausalConv1d</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">odim: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">stride: int = 1</em>, <em class="sig-param">dilation: int = 1</em>, <em class="sig-param">groups: int = 1</em>, <em class="sig-param">bias: bool = True</em>, <em class="sig-param">batch_norm: bool = False</em>, <em class="sig-param">relu: bool = True</em>, <em class="sig-param">dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/conv1d_nets.html#CausalConv1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.conv1d_nets.CausalConv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>1D causal convolution module for custom decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> – Input dimension.</p></li>
<li><p><strong>odim</strong> – Output dimension.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolving kernel.</p></li>
<li><p><strong>stride</strong> – Stride of the convolution.</p></li>
<li><p><strong>dilation</strong> – Spacing between the kernel points.</p></li>
<li><p><strong>groups</strong> – Number of blocked connections from input channels to output channels.</p></li>
<li><p><strong>bias</strong> – Whether to add a learnable bias to the output.</p></li>
<li><p><strong>batch_norm</strong> – Whether to apply batch normalization.</p></li>
<li><p><strong>relu</strong> – Whether to pass final output through ReLU activation.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a CausalConv1d object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.conv1d_nets.CausalConv1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">sequence: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">cache: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/conv1d_nets.html#CausalConv1d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.conv1d_nets.CausalConv1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward CausalConv1d for custom decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence</strong> – CausalConv1d input sequences. (B, U, D_in)</p></li>
<li><p><strong>mask</strong> – Mask of CausalConv1d input sequences. (B, 1, U)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>CausalConv1d output sequences. (B, sub(U), D_out)
mask: Mask of CausalConv1d output sequences. (B, 1, sub(U))</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sequence</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.conv1d_nets.Conv1d">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.conv1d_nets.</code><code class="sig-name descname">Conv1d</code><span class="sig-paren">(</span><em class="sig-param">idim: int, odim: int, kernel_size: Union[int, Tuple], stride: Union[int, Tuple] = 1, dilation: Union[int, Tuple] = 1, groups: Union[int, Tuple] = 1, bias: bool = True, batch_norm: bool = False, relu: bool = True, dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/conv1d_nets.html#Conv1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.conv1d_nets.Conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>1D convolution module for custom encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> – Input dimension.</p></li>
<li><p><strong>odim</strong> – Output dimension.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolving kernel.</p></li>
<li><p><strong>stride</strong> – Stride of the convolution.</p></li>
<li><p><strong>dilation</strong> – Spacing between the kernel points.</p></li>
<li><p><strong>groups</strong> – Number of blocked connections from input channels to output channels.</p></li>
<li><p><strong>bias</strong> – Whether to add a learnable bias to the output.</p></li>
<li><p><strong>batch_norm</strong> – Whether to use batch normalization after convolution.</p></li>
<li><p><strong>relu</strong> – Whether to use a ReLU activation after convolution.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a Conv1d module object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.conv1d_nets.Conv1d.create_new_mask">
<code class="sig-name descname">create_new_mask</code><span class="sig-paren">(</span><em class="sig-param">mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/conv1d_nets.html#Conv1d.create_new_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.conv1d_nets.Conv1d.create_new_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create new mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mask</strong> – Mask of input sequences. (B, 1, T)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mask of output sequences. (B, 1, sub(T))</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.conv1d_nets.Conv1d.create_new_pos_embed">
<code class="sig-name descname">create_new_pos_embed</code><span class="sig-paren">(</span><em class="sig-param">pos_embed: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/conv1d_nets.html#Conv1d.create_new_pos_embed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.conv1d_nets.Conv1d.create_new_pos_embed" title="Permalink to this definition">¶</a></dt>
<dd><p>Create new positional embedding vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>pos_embed</strong> – Input sequences positional embedding.
(B, 2 * (T - 1), D_att)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Output sequences positional embedding.</dt><dd><p>(B, 2 * (sub(T) - 1), D_att)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pos_embed</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.conv1d_nets.Conv1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">sequence: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]], mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]], torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/conv1d_nets.html#Conv1d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.conv1d_nets.Conv1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward ConvEncoderLayer module object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence</strong> – <p>Input sequences.
(B, T, D_in)</p>
<blockquote>
<div><p>or (B, T, D_in),  (B, 2 * (T - 1), D_att)</p>
</div></blockquote>
</p></li>
<li><p><strong>mask</strong> – Mask of input sequences. (B, 1, T)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Output sequences.</dt><dd><dl class="simple">
<dt>(B, sub(T), D_out)</dt><dd><p>or (B, sub(T), D_out),  (B, 2 * (sub(T) - 1), D_att)</p>
</dd>
</dl>
</dd>
</dl>
<p>mask: Mask of output sequences. (B, 1, sub(T))</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sequence</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-blocks">
<span id="id155"></span><h2>espnet.nets.pytorch_backend.transducer.blocks<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-blocks" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.blocks"></span><p>Set of methods to create custom architecture.</p>
<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.blocks.build_blocks">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.blocks.</code><code class="sig-name descname">build_blocks</code><span class="sig-paren">(</span><em class="sig-param">net_part: str, idim: int, input_layer_type: str, blocks: List[Dict[str, Any]], repeat_block: int = 0, self_attn_type: str = 'self_attn', positional_encoding_type: str = 'abs_pos', positionwise_layer_type: str = 'linear', positionwise_activation_type: str = 'relu', conv_mod_activation_type: str = 'relu', input_layer_dropout_rate: float = 0.0, input_layer_pos_enc_dropout_rate: float = 0.0, padding_idx: int = -1</em><span class="sig-paren">)</span> &#x2192; Tuple[Union[espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling, espnet.nets.pytorch_backend.transducer.vgg2l.VGG2L, torch.nn.modules.container.Sequential], espnet.nets.pytorch_backend.transformer.repeat.MultiSequential, int, int]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/blocks.html#build_blocks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.blocks.build_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Build custom model blocks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net_part</strong> – Network part, either ‘encoder’ or ‘decoder’.</p></li>
<li><p><strong>idim</strong> – Input dimension.</p></li>
<li><p><strong>input_layer</strong> – Input layer type.</p></li>
<li><p><strong>blocks</strong> – Blocks parameters for network part.</p></li>
<li><p><strong>repeat_block</strong> – Number of times provided blocks are repeated.</p></li>
<li><p><strong>positional_encoding_type</strong> – Positional encoding layer type.</p></li>
<li><p><strong>positionwise_layer_type</strong> – Positionwise layer type.</p></li>
<li><p><strong>positionwise_activation_type</strong> – Positionwise activation type.</p></li>
<li><p><strong>conv_mod_activation_type</strong> – Convolutional module activation type.</p></li>
<li><p><strong>input_layer_dropout_rate</strong> – Dropout rate for input layer.</p></li>
<li><p><strong>input_layer_pos_enc_dropout_rate</strong> – Dropout rate for input layer pos. enc.</p></li>
<li><p><strong>padding_idx</strong> – Padding symbol ID for embedding layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Input layer
all_blocks: Encoder/Decoder network.
out_dim: Network output dimension.
conv_subsampling_factor: Subsampling factor in frontend CNN.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>in_layer</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.blocks.build_conformer_block">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.blocks.</code><code class="sig-name descname">build_conformer_block</code><span class="sig-paren">(</span><em class="sig-param">block: Dict[str, Any], self_attn_class: str, pw_layer_type: str, pw_activation_type: str, conv_mod_activation_type: str</em><span class="sig-paren">)</span> &#x2192; espnet.nets.pytorch_backend.conformer.encoder_layer.EncoderLayer<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/blocks.html#build_conformer_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.blocks.build_conformer_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build function for conformer block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block</strong> – Conformer block parameters.</p></li>
<li><p><strong>self_attn_type</strong> – Self-attention module type.</p></li>
<li><p><strong>pw_layer_type</strong> – Positionwise layer type.</p></li>
<li><p><strong>pw_activation_type</strong> – Positionwise activation type.</p></li>
<li><p><strong>conv_mod_activation_type</strong> – Convolutional module activation type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Function to create conformer (encoder) block.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.blocks.build_conv1d_block">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.blocks.</code><code class="sig-name descname">build_conv1d_block</code><span class="sig-paren">(</span><em class="sig-param">block: Dict[str, Any], block_type: str</em><span class="sig-paren">)</span> &#x2192; espnet.nets.pytorch_backend.transducer.conv1d_nets.CausalConv1d<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/blocks.html#build_conv1d_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.blocks.build_conv1d_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build function for causal conv1d block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>block</strong> – CausalConv1d or Conv1D block parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Function to create conv1d (encoder) or causal conv1d (decoder) block.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.blocks.build_input_layer">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.blocks.</code><code class="sig-name descname">build_input_layer</code><span class="sig-paren">(</span><em class="sig-param">block: Dict[str, Any], pos_enc_class: torch.nn.modules.module.Module, padding_idx: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Union[espnet.nets.pytorch_backend.transformer.subsampling.Conv2dSubsampling, espnet.nets.pytorch_backend.transducer.vgg2l.VGG2L, torch.nn.modules.container.Sequential], int]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/blocks.html#build_input_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.blocks.build_input_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Build input layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block</strong> – Architecture definition of input layer.</p></li>
<li><p><strong>pos_enc_class</strong> – Positional encoding class.</p></li>
<li><p><strong>padding_idx</strong> – Padding symbol ID for embedding layer (if provided).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Input layer module.
subsampling_factor: Subsampling factor.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.blocks.build_transformer_block">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.blocks.</code><code class="sig-name descname">build_transformer_block</code><span class="sig-paren">(</span><em class="sig-param">net_part: str, block: Dict[str, Any], pw_layer_type: str, pw_activation_type: str</em><span class="sig-paren">)</span> &#x2192; Union[espnet.nets.pytorch_backend.transformer.encoder_layer.EncoderLayer, espnet.nets.pytorch_backend.transducer.transformer_decoder_layer.TransformerDecoderLayer]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/blocks.html#build_transformer_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.blocks.build_transformer_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build function for transformer block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net_part</strong> – Network part, either ‘encoder’ or ‘decoder’.</p></li>
<li><p><strong>block</strong> – Transformer block parameters.</p></li>
<li><p><strong>pw_layer_type</strong> – Positionwise layer type.</p></li>
<li><p><strong>pw_activation_type</strong> – Positionwise activation type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Function to create transformer (encoder or decoder) block.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.blocks.get_pos_enc_and_att_class">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.blocks.</code><code class="sig-name descname">get_pos_enc_and_att_class</code><span class="sig-paren">(</span><em class="sig-param">net_part: str</em>, <em class="sig-param">pos_enc_type: str</em>, <em class="sig-param">self_attn_type: str</em><span class="sig-paren">)</span> &#x2192; Tuple[Union[espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding, espnet.nets.pytorch_backend.transformer.embedding.ScaledPositionalEncoding, espnet.nets.pytorch_backend.transformer.embedding.RelPositionalEncoding], Union[espnet.nets.pytorch_backend.transformer.attention.MultiHeadedAttention, espnet.nets.pytorch_backend.transformer.attention.RelPositionMultiHeadedAttention]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/blocks.html#get_pos_enc_and_att_class"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.blocks.get_pos_enc_and_att_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Get positional encoding and self attention module class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net_part</strong> – Network part, either ‘encoder’ or ‘decoder’.</p></li>
<li><p><strong>pos_enc_type</strong> – Positional encoding type.</p></li>
<li><p><strong>self_attn_type</strong> – Self-attention type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Positional encoding class.
self_attn_class: Self-attention class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pos_enc_class</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.blocks.prepare_body_model">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.blocks.</code><code class="sig-name descname">prepare_body_model</code><span class="sig-paren">(</span><em class="sig-param">net_part: str, blocks: List[Dict[str, Any]]</em><span class="sig-paren">)</span> &#x2192; Tuple[int]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/blocks.html#prepare_body_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.blocks.prepare_body_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare model body blocks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net_part</strong> – Network part, either ‘encoder’ or ‘decoder’.</p></li>
<li><p><strong>blocks</strong> – Blocks parameters for network part.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Network output dimension.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.blocks.prepare_input_layer">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.blocks.</code><code class="sig-name descname">prepare_input_layer</code><span class="sig-paren">(</span><em class="sig-param">input_layer_type: str, feats_dim: int, blocks: List[Dict[str, Any]], dropout_rate: float, pos_enc_dropout_rate: float</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/blocks.html#prepare_input_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.blocks.prepare_input_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare input layer arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_layer_type</strong> – Input layer type.</p></li>
<li><p><strong>feats_dim</strong> – Dimension of input features.</p></li>
<li><p><strong>blocks</strong> – Blocks parameters for network part.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate for input layer.</p></li>
<li><p><strong>pos_enc_dropout_rate</strong> – Dropout rate for input layer pos. enc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Input block parameters.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>input_block</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.blocks.verify_block_arguments">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.blocks.</code><code class="sig-name descname">verify_block_arguments</code><span class="sig-paren">(</span><em class="sig-param">net_part: str, block: Dict[str, Any], num_block: int</em><span class="sig-paren">)</span> &#x2192; Tuple[int, int]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/blocks.html#verify_block_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.blocks.verify_block_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Verify block arguments are valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net_part</strong> – Network part, either ‘encoder’ or ‘decoder’.</p></li>
<li><p><strong>block</strong> – Block parameters.</p></li>
<li><p><strong>num_block</strong> – Block ID.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Input and output dimension of the block.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>block_io</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-rnn-encoder">
<span id="id156"></span><h2>espnet.nets.pytorch_backend.transducer.rnn_encoder<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-rnn-encoder" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.rnn_encoder"></span><p>RNN encoder implementation for Transducer model.</p>
<p>These classes are based on the ones in espnet.nets.pytorch_backend.rnn.encoders,
and modified to output intermediate representation based given list of layers as input.
To do so, RNN class rely on a stack of 1-layer LSTM instead of a multi-layer LSTM.
The additional outputs are intended to be used with Transducer auxiliary tasks.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.rnn_encoder.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">etype: str</em>, <em class="sig-param">elayers: int</em>, <em class="sig-param">eunits: int</em>, <em class="sig-param">eprojs: int</em>, <em class="sig-param">subsample: numpy.ndarray</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">aux_enc_output_layers: List = []</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> – Input dimension.</p></li>
<li><p><strong>etype</strong> – Encoder units type.</p></li>
<li><p><strong>elayers</strong> – Number of encoder layers.</p></li>
<li><p><strong>eunits</strong> – Number of encoder units per layer.</p></li>
<li><p><strong>eprojs</strong> – Number of projection units per layer.</p></li>
<li><p><strong>subsample</strong> – Subsampling rate per layer.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate for encoder layers.</p></li>
<li><p><strong>intermediate_encoder_layers</strong> – Layer IDs for auxiliary encoder output sequences.</p></li>
</ul>
</dd>
</dl>
<p>Initialize Encoder module.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_len: torch.Tensor</em>, <em class="sig-param">prev_states: Optional[List[torch.Tensor]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats</strong> – Feature sequences. (B, F, D_feats)</p></li>
<li><p><strong>feats_len</strong> – Feature sequences lengths. (B,)</p></li>
<li><p><strong>prev_states</strong> – Previous encoder hidden states. [N x (B, T, D_enc)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Encoder output sequences. (B, T, D_enc)</dt><dd><p>with or without encoder intermediate output sequences.
((B, T, D_enc), [N x (B, T, D_enc)])</p>
</dd>
</dl>
<p>enc_out_len: Encoder output sequences lengths. (B,)
current_states: Encoder hidden states. [N x (B, T, D_enc)]</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>enc_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.RNN">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.rnn_encoder.</code><code class="sig-name descname">RNN</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">rnn_type: str</em>, <em class="sig-param">elayers: int</em>, <em class="sig-param">eunits: int</em>, <em class="sig-param">eprojs: int</em>, <em class="sig-param">dropout_rate: float</em>, <em class="sig-param">aux_output_layers: List = []</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#RNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RNN module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> – Input dimension.</p></li>
<li><p><strong>rnn_type</strong> – RNN units type.</p></li>
<li><p><strong>elayers</strong> – Number of RNN layers.</p></li>
<li><p><strong>eunits</strong> – Number of units ((2 * eunits) if bidirectional)</p></li>
<li><p><strong>eprojs</strong> – Number of final projection units.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate for RNN layers.</p></li>
<li><p><strong>aux_output_layers</strong> – List of layer IDs for auxiliary RNN output sequences.</p></li>
</ul>
</dd>
</dl>
<p>Initialize RNN module.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.RNN.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">rnn_input: torch.Tensor</em>, <em class="sig-param">rnn_len: torch.Tensor</em>, <em class="sig-param">prev_states: Optional[List[torch.Tensor]] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#RNN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.RNN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>RNN forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rnn_input</strong> – RNN input sequences. (B, T, D_in)</p></li>
<li><p><strong>rnn_len</strong> – RNN input sequences lengths. (B,)</p></li>
<li><p><strong>prev_states</strong> – RNN hidden states. [N x (B, T, D_proj)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>RNN output sequences. (B, T, D_proj)</dt><dd><p>with or without intermediate RNN output sequences.
((B, T, D_proj), [N x (B, T, D_proj)])</p>
</dd>
</dl>
<p>rnn_len: RNN output sequences lengths. (B,)
current_states: RNN hidden states. [N x (B, T, D_proj)]</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>rnn_output</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.RNNP">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.rnn_encoder.</code><code class="sig-name descname">RNNP</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">rnn_type: str</em>, <em class="sig-param">elayers: int</em>, <em class="sig-param">eunits: int</em>, <em class="sig-param">eprojs: int</em>, <em class="sig-param">subsample: numpy.ndarray</em>, <em class="sig-param">dropout_rate: float</em>, <em class="sig-param">aux_output_layers: List = []</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#RNNP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.RNNP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RNN with projection layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> – Input dimension.</p></li>
<li><p><strong>rnn_type</strong> – RNNP units type.</p></li>
<li><p><strong>elayers</strong> – Number of RNNP layers.</p></li>
<li><p><strong>eunits</strong> – Number of units ((2 * eunits) if bidirectional).</p></li>
<li><p><strong>eprojs</strong> – Number of projection units.</p></li>
<li><p><strong>subsample</strong> – Subsampling rate per layer.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate for RNNP layers.</p></li>
<li><p><strong>aux_output_layers</strong> – Layer IDs for auxiliary RNNP output sequences.</p></li>
</ul>
</dd>
</dl>
<p>Initialize RNNP module.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.RNNP.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">rnn_input: torch.Tensor</em>, <em class="sig-param">rnn_len: torch.Tensor</em>, <em class="sig-param">prev_states: Optional[List[torch.Tensor]] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#RNNP.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.RNNP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>RNNP forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rnn_input</strong> – RNN input sequences. (B, T, D_in)</p></li>
<li><p><strong>rnn_len</strong> – RNN input sequences lengths. (B,)</p></li>
<li><p><strong>prev_states</strong> – RNN hidden states. [N x (B, T, D_proj)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>RNN output sequences. (B, T, D_proj)</dt><dd><p>with or without intermediate RNN output sequences.
((B, T, D_proj), [N x (B, T, D_proj)])</p>
</dd>
</dl>
<p>rnn_len: RNN output sequences lengths. (B,)
current_states: RNN hidden states. [N x (B, T, D_proj)]</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>rnn_output</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.VGG2L">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.rnn_encoder.</code><code class="sig-name descname">VGG2L</code><span class="sig-paren">(</span><em class="sig-param">in_channel: int = 1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#VGG2L"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.VGG2L" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>VGG-like module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>in_channel</strong> – number of input channels</p>
</dd>
</dl>
<p>Initialize VGG-like module.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.VGG2L.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_len: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#VGG2L.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.VGG2L.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG2L forward.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats</strong> – Feature sequences. (B, F, D_feats)</p></li>
<li><p><strong>feats_len</strong> – Feature sequences lengths. (B, )</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>VGG2L output sequences. (B, F // 4, 128 * D_feats // 4)
vgg_out_len: VGG2L output sequences lengths. (B,)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>vgg_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.encoder_for">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.rnn_encoder.</code><code class="sig-name descname">encoder_for</code><span class="sig-paren">(</span><em class="sig-param">args: argparse.Namespace</em>, <em class="sig-param">idim: int</em>, <em class="sig-param">subsample: numpy.ndarray</em>, <em class="sig-param">aux_enc_output_layers: List = []</em><span class="sig-paren">)</span> &#x2192; torch.nn.modules.module.Module<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#encoder_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.encoder_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate a RNN encoder with specified arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> – The model arguments.</p></li>
<li><p><strong>idim</strong> – Input dimension.</p></li>
<li><p><strong>subsample</strong> – Subsampling rate per layer.</p></li>
<li><p><strong>aux_enc_output_layers</strong> – Layer IDs for auxiliary encoder output sequences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoder module.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.transducer.rnn_encoder.reset_backward_rnn_state">
<code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.rnn_encoder.</code><code class="sig-name descname">reset_backward_rnn_state</code><span class="sig-paren">(</span><em class="sig-param">states: Union[torch.Tensor, List[Optional[torch.Tensor]]]</em><span class="sig-paren">)</span> &#x2192; Union[torch.Tensor, List[Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/rnn_encoder.html#reset_backward_rnn_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.rnn_encoder.reset_backward_rnn_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Set backward BRNN states to zeroes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>states</strong> – Encoder hidden states.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Encoder hidden states with backward set to zero.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>states</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet-nets-pytorch-backend-transducer-vgg2l">
<span id="id157"></span><h2>espnet.nets.pytorch_backend.transducer.vgg2l<a class="headerlink" href="#espnet-nets-pytorch-backend-transducer-vgg2l" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transducer.vgg2l"></span><p>VGG2L module definition for custom encoder.</p>
<dl class="class">
<dt id="espnet.nets.pytorch_backend.transducer.vgg2l.VGG2L">
<em class="property">class </em><code class="sig-prename descclassname">espnet.nets.pytorch_backend.transducer.vgg2l.</code><code class="sig-name descname">VGG2L</code><span class="sig-paren">(</span><em class="sig-param">idim: int</em>, <em class="sig-param">odim: int</em>, <em class="sig-param">pos_enc: torch.nn.modules.module.Module = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/vgg2l.html#VGG2L"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.vgg2l.VGG2L" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>VGG2L module for custom encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idim</strong> – Input dimension.</p></li>
<li><p><strong>odim</strong> – Output dimension.</p></li>
<li><p><strong>pos_enc</strong> – Positional encoding class.</p></li>
</ul>
</dd>
</dl>
<p>Construct a VGG2L object.</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.vgg2l.VGG2L.create_new_mask">
<code class="sig-name descname">create_new_mask</code><span class="sig-paren">(</span><em class="sig-param">feats_mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/vgg2l.html#VGG2L.create_new_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.vgg2l.VGG2L.create_new_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a subsampled mask of feature sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>feats_mask</strong> – Mask of feature sequences. (B, 1, F)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mask of VGG2L output sequences. (B, 1, sub(F))</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>vgg_mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.transducer.vgg2l.VGG2L.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Union[Tuple[torch.Tensor, torch.Tensor], Tuple[Tuple[torch.Tensor, torch.Tensor], torch.Tensor]]<a class="reference internal" href="../_modules/espnet/nets/pytorch_backend/transducer/vgg2l.html#VGG2L.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet.nets.pytorch_backend.transducer.vgg2l.VGG2L.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward VGG2L bottleneck.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats</strong> – Feature sequences. (B, F, D_feats)</p></li>
<li><p><strong>feats_mask</strong> – Mask of feature sequences. (B, 1, F)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>VGG output sequences.</dt><dd><p>(B, sub(F), D_out) or ((B, sub(F), D_out), (B, sub(F), D_att))</p>
</dd>
</dl>
<p>vgg_mask: Mask of VGG output sequences. (B, 1, sub(F))</p>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>vgg_output</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="espnet.bin.html" class="btn btn-neutral float-left" title="espnet.bin package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="espnet.mt.html" class="btn btn-neutral float-right" title="espnet.mt package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>